{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zinni98/Sentiment-analysis-project/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NBg5KtW5AMy"
      },
      "source": [
        "## Polarity Classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\")"
      ],
      "metadata": {
        "id": "8msH_nw3rf39",
        "outputId": "0fabe714-c13d-4fca-9e3f-a4af5cc9d974",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/gdrive/My Drive/nlu-project\")"
      ],
      "metadata": {
        "id": "vdSs1gS1rgh_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oGXvFNN46OT"
      },
      "source": [
        "### Get the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvHgFZJe4_Xq",
        "outputId": "cf07ab12-ede4-42f9-d390-2d04090ef698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package subjectivity to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "import torch\n",
        "from nltk.corpus import movie_reviews\n",
        "import numpy as np\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"movie_reviews\")\n",
        "nltk.download(\"subjectivity\")\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fglEQLVLtc9C"
      },
      "source": [
        "## Exploratory analysis\n",
        "\n",
        "Firstly let's explore the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dKetqTKrZFE",
        "outputId": "8016aa09-4a5f-4a15-c1dc-b14a517ddeb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of each part of the dataset:\n",
            " - pos: 1000 \n",
            " - neg: 1000\n",
            "[[['films', 'adapted', 'from', 'comic', 'books', 'have', 'had', 'plenty', 'of', 'success', ',', 'whether', 'they', \"'\", 're', 'about', 'superheroes', '(', 'batman', ',', 'superman', ',', 'spawn', ')', ',', 'or', 'geared', 'toward', 'kids', '(', 'casper', ')', 'or', 'the', 'arthouse', 'crowd', '(', 'ghost', 'world', ')', ',', 'but', 'there', \"'\", 's', 'never', 'really', 'been', 'a', 'comic', 'book', 'like', 'from', 'hell', 'before', '.'], ['for', 'starters', ',', 'it', 'was', 'created', 'by', 'alan', 'moore', '(', 'and', 'eddie', 'campbell', ')', ',', 'who', 'brought', 'the', 'medium', 'to', 'a', 'whole', 'new', 'level', 'in', 'the', 'mid', \"'\", '80s', 'with', 'a', '12', '-', 'part', 'series', 'called', 'the', 'watchmen', '.'], ['to', 'say', 'moore', 'and', 'campbell', 'thoroughly', 'researched', 'the', 'subject', 'of', 'jack', 'the', 'ripper', 'would', 'be', 'like', 'saying', 'michael', 'jackson', 'is', 'starting', 'to', 'look', 'a', 'little', 'odd', '.'], ['the', 'book', '(', 'or', '\"', 'graphic', 'novel', ',', '\"', 'if', 'you', 'will', ')', 'is', 'over', '500', 'pages', 'long', 'and', 'includes', 'nearly', '30', 'more', 'that', 'consist', 'of', 'nothing', 'but', 'footnotes', '.'], ['in', 'other', 'words', ',', 'don', \"'\", 't', 'dismiss', 'this', 'film', 'because', 'of', 'its', 'source', '.'], ['if', 'you', 'can', 'get', 'past', 'the', 'whole', 'comic', 'book', 'thing', ',', 'you', 'might', 'find', 'another', 'stumbling', 'block', 'in', 'from', 'hell', \"'\", 's', 'directors', ',', 'albert', 'and', 'allen', 'hughes', '.'], ['getting', 'the', 'hughes', 'brothers', 'to', 'direct', 'this', 'seems', 'almost', 'as', 'ludicrous', 'as', 'casting', 'carrot', 'top', 'in', ',', 'well', ',', 'anything', ',', 'but', 'riddle', 'me', 'this', ':', 'who', 'better', 'to', 'direct', 'a', 'film', 'that', \"'\", 's', 'set', 'in', 'the', 'ghetto', 'and', 'features', 'really', 'violent', 'street', 'crime', 'than', 'the', 'mad', 'geniuses', 'behind', 'menace', 'ii', 'society', '?'], ['the', 'ghetto', 'in', 'question', 'is', ',', 'of', 'course', ',', 'whitechapel', 'in', '1888', 'london', \"'\", 's', 'east', 'end', '.'], ['it', \"'\", 's', 'a', 'filthy', ',', 'sooty', 'place', 'where', 'the', 'whores', '(', 'called', '\"', 'unfortunates', '\"', ')', 'are', 'starting', 'to', 'get', 'a', 'little', 'nervous', 'about', 'this', 'mysterious', 'psychopath', 'who', 'has', 'been', 'carving', 'through', 'their', 'profession', 'with', 'surgical', 'precision', '.'], ['when', 'the', 'first', 'stiff', 'turns', 'up', ',', 'copper', 'peter', 'godley', '(', 'robbie', 'coltrane', ',', 'the', 'world', 'is', 'not', 'enough', ')', 'calls', 'in', 'inspector', 'frederick', 'abberline', '(', 'johnny', 'depp', ',', 'blow', ')', 'to', 'crack', 'the', 'case', '.'], ['abberline', ',', 'a', 'widower', ',', 'has', 'prophetic', 'dreams', 'he', 'unsuccessfully', 'tries', 'to', 'quell', 'with', 'copious', 'amounts', 'of', 'absinthe', 'and', 'opium', '.'], ['upon', 'arriving', 'in', 'whitechapel', ',', 'he', 'befriends', 'an', 'unfortunate', 'named', 'mary', 'kelly', '(', 'heather', 'graham', ',', 'say', 'it', 'isn', \"'\", 't', 'so', ')', 'and', 'proceeds', 'to', 'investigate', 'the', 'horribly', 'gruesome', 'crimes', 'that', 'even', 'the', 'police', 'surgeon', 'can', \"'\", 't', 'stomach', '.'], ['i', 'don', \"'\", 't', 'think', 'anyone', 'needs', 'to', 'be', 'briefed', 'on', 'jack', 'the', 'ripper', ',', 'so', 'i', 'won', \"'\", 't', 'go', 'into', 'the', 'particulars', 'here', ',', 'other', 'than', 'to', 'say', 'moore', 'and', 'campbell', 'have', 'a', 'unique', 'and', 'interesting', 'theory', 'about', 'both', 'the', 'identity', 'of', 'the', 'killer', 'and', 'the', 'reasons', 'he', 'chooses', 'to', 'slay', '.'], ['in', 'the', 'comic', ',', 'they', 'don', \"'\", 't', 'bother', 'cloaking', 'the', 'identity', 'of', 'the', 'ripper', ',', 'but', 'screenwriters', 'terry', 'hayes', '(', 'vertical', 'limit', ')', 'and', 'rafael', 'yglesias', '(', 'les', 'mis', '?'], ['rables', ')', 'do', 'a', 'good', 'job', 'of', 'keeping', 'him', 'hidden', 'from', 'viewers', 'until', 'the', 'very', 'end', '.'], ['it', \"'\", 's', 'funny', 'to', 'watch', 'the', 'locals', 'blindly', 'point', 'the', 'finger', 'of', 'blame', 'at', 'jews', 'and', 'indians', 'because', ',', 'after', 'all', ',', 'an', 'englishman', 'could', 'never', 'be', 'capable', 'of', 'committing', 'such', 'ghastly', 'acts', '.'], ['and', 'from', 'hell', \"'\", 's', 'ending', 'had', 'me', 'whistling', 'the', 'stonecutters', 'song', 'from', 'the', 'simpsons', 'for', 'days', '(', '\"', 'who', 'holds', 'back', 'the', 'electric', 'car', '/', 'who', 'made', 'steve', 'guttenberg', 'a', 'star', '?', '\"'], [')', '.'], ['don', \"'\", 't', 'worry', '-', 'it', \"'\", 'll', 'all', 'make', 'sense', 'when', 'you', 'see', 'it', '.'], ['now', 'onto', 'from', 'hell', \"'\", 's', 'appearance', ':', 'it', \"'\", 's', 'certainly', 'dark', 'and', 'bleak', 'enough', ',', 'and', 'it', \"'\", 's', 'surprising', 'to', 'see', 'how', 'much', 'more', 'it', 'looks', 'like', 'a', 'tim', 'burton', 'film', 'than', 'planet', 'of', 'the', 'apes', 'did', '(', 'at', 'times', ',', 'it', 'seems', 'like', 'sleepy', 'hollow', '2', ')', '.'], ['the', 'print', 'i', 'saw', 'wasn', \"'\", 't', 'completely', 'finished', '(', 'both', 'color', 'and', 'music', 'had', 'not', 'been', 'finalized', ',', 'so', 'no', 'comments', 'about', 'marilyn', 'manson', ')', ',', 'but', 'cinematographer', 'peter', 'deming', '(', 'don', \"'\", 't', 'say', 'a', 'word', ')', 'ably', 'captures', 'the', 'dreariness', 'of', 'victorian', '-', 'era', 'london', 'and', 'helped', 'make', 'the', 'flashy', 'killing', 'scenes', 'remind', 'me', 'of', 'the', 'crazy', 'flashbacks', 'in', 'twin', 'peaks', ',', 'even', 'though', 'the', 'violence', 'in', 'the', 'film', 'pales', 'in', 'comparison', 'to', 'that', 'in', 'the', 'black', '-', 'and', '-', 'white', 'comic', '.'], ['oscar', 'winner', 'martin', 'childs', \"'\", '(', 'shakespeare', 'in', 'love', ')', 'production', 'design', 'turns', 'the', 'original', 'prague', 'surroundings', 'into', 'one', 'creepy', 'place', '.'], ['even', 'the', 'acting', 'in', 'from', 'hell', 'is', 'solid', ',', 'with', 'the', 'dreamy', 'depp', 'turning', 'in', 'a', 'typically', 'strong', 'performance', 'and', 'deftly', 'handling', 'a', 'british', 'accent', '.'], ['ians', 'holm', '(', 'joe', 'gould', \"'\", 's', 'secret', ')', 'and', 'richardson', '(', '102', 'dalmatians', ')', 'log', 'in', 'great', 'supporting', 'roles', ',', 'but', 'the', 'big', 'surprise', 'here', 'is', 'graham', '.'], ['i', 'cringed', 'the', 'first', 'time', 'she', 'opened', 'her', 'mouth', ',', 'imagining', 'her', 'attempt', 'at', 'an', 'irish', 'accent', ',', 'but', 'it', 'actually', 'wasn', \"'\", 't', 'half', 'bad', '.'], ['the', 'film', ',', 'however', ',', 'is', 'all', 'good', '.'], ['2', ':', '00', '-', 'r', 'for', 'strong', 'violence', '/', 'gore', ',', 'sexuality', ',', 'language', 'and', 'drug', 'content']], [['every', 'now', 'and', 'then', 'a', 'movie', 'comes', 'along', 'from', 'a', 'suspect', 'studio', ',', 'with', 'every', 'indication', 'that', 'it', 'will', 'be', 'a', 'stinker', ',', 'and', 'to', 'everybody', \"'\", 's', 'surprise', '(', 'perhaps', 'even', 'the', 'studio', ')', 'the', 'film', 'becomes', 'a', 'critical', 'darling', '.'], ['mtv', 'films', \"'\", '_election', ',', 'a', 'high', 'school', 'comedy', 'starring', 'matthew', 'broderick', 'and', 'reese', 'witherspoon', ',', 'is', 'a', 'current', 'example', '.'], ['did', 'anybody', 'know', 'this', 'film', 'existed', 'a', 'week', 'before', 'it', 'opened', '?'], ['the', 'plot', 'is', 'deceptively', 'simple', '.'], ['george', 'washington', 'carver', 'high', 'school', 'is', 'having', 'student', 'elections', '.'], ['tracy', 'flick', '(', 'reese', 'witherspoon', ')', 'is', 'an', 'over', '-', 'achiever', 'with', 'her', 'hand', 'raised', 'at', 'nearly', 'every', 'question', ',', 'way', ',', 'way', ',', 'high', '.'], ['mr', '.', '\"', 'm', '\"', '(', 'matthew', 'broderick', ')', ',', 'sick', 'of', 'the', 'megalomaniac', 'student', ',', 'encourages', 'paul', ',', 'a', 'popular', '-', 'but', '-', 'slow', 'jock', 'to', 'run', '.'], ['and', 'paul', \"'\", 's', 'nihilistic', 'sister', 'jumps', 'in', 'the', 'race', 'as', 'well', ',', 'for', 'personal', 'reasons', '.'], ['the', 'dark', 'side', 'of', 'such', 'sleeper', 'success', 'is', 'that', ',', 'because', 'expectations', 'were', 'so', 'low', 'going', 'in', ',', 'the', 'fact', 'that', 'this', 'was', 'quality', 'stuff', 'made', 'the', 'reviews', 'even', 'more', 'enthusiastic', 'than', 'they', 'have', 'any', 'right', 'to', 'be', '.'], ['you', 'can', \"'\", 't', 'help', 'going', 'in', 'with', 'the', 'baggage', 'of', 'glowing', 'reviews', ',', 'which', 'is', 'in', 'contrast', 'to', 'the', 'negative', 'baggage', 'that', 'the', 'reviewers', 'were', 'likely', 'to', 'have', '.'], ['_election', ',', 'a', 'good', 'film', ',', 'does', 'not', 'live', 'up', 'to', 'its', 'hype', '.'], ['what', 'makes', '_election_', 'so', 'disappointing', 'is', 'that', 'it', 'contains', 'significant', 'plot', 'details', 'lifted', 'directly', 'from', '_rushmore_', ',', 'released', 'a', 'few', 'months', 'earlier', '.'], ['the', 'similarities', 'are', 'staggering', ':', 'tracy', 'flick', '(', '_election_', ')', 'is', 'the', 'president', 'of', 'an', 'extraordinary', 'number', 'of', 'clubs', ',', 'and', 'is', 'involved', 'with', 'the', 'school', 'play', '.'], ['max', 'fischer', '(', '_rushmore_', ')', 'is', 'the', 'president', 'of', 'an', 'extraordinary', 'number', 'of', 'clubs', ',', 'and', 'is', 'involved', 'with', 'the', 'school', 'play', '.'], ['the', 'most', 'significant', 'tension', 'of', '_election_', 'is', 'the', 'potential', 'relationship', 'between', 'a', 'teacher', 'and', 'his', 'student', '.'], ['the', 'most', 'significant', 'tension', 'of', '_rushmore_', 'is', 'the', 'potential', 'relationship', 'between', 'a', 'teacher', 'and', 'his', 'student', '.'], ['tracy', 'flick', 'is', 'from', 'a', 'single', 'parent', 'home', ',', 'which', 'has', 'contributed', 'to', 'her', 'drive', '.'], ['max', 'fischer', 'is', 'from', 'a', 'single', 'parent', 'home', ',', 'which', 'has', 'contributed', 'to', 'his', 'drive', '.'], ['the', 'male', 'bumbling', 'adult', 'in', '_election_', '(', 'matthew', 'broderick', ')', 'pursues', 'an', 'extramarital', 'affair', ',', 'gets', 'caught', ',', 'and', 'his', 'whole', 'life', 'is', 'ruined', '.'], ['he', 'even', 'gets', 'a', 'bee', 'sting', '.'], ['the', 'male', 'bumbling', 'adult', 'in', '_rushmore_', '(', 'bill', 'murray', ')', 'pursues', 'an', 'extramarital', 'affair', ',', 'gets', 'caught', ',', 'and', 'his', 'whole', 'life', 'is', 'ruined', '.'], ['he', 'gets', 'several', 'bee', 'stings', '.'], ['and', 'so', 'on', '.'], ['what', 'happened', '?'], ['how', 'is', 'it', 'that', 'an', 'individual', 'screenplay', '(', '_rushmore_', ')', 'and', 'a', 'novel', '(', '_election_', ')', 'contain', 'so', 'many', 'significant', 'plot', 'points', ',', 'and', 'yet', 'both', 'films', 'were', 'probably', 'not', 'even', 'aware', 'of', 'each', 'other', ',', 'made', 'from', 'two', 'different', 'studios', ',', 'from', 'a', 'genre', '(', 'the', 'high', 'school', 'geeks', 'revenge', 'movie', ')', 'that', 'hadn', \"'\", 't', 'been', 'fully', 'formed', 'yet', '?'], ['even', 'so', ',', 'the', 'strengths', 'of', '_election_', 'rely', 'upon', 'its', 'fantastic', 'performances', 'from', 'broderick', ',', 'witherspoon', ',', 'and', 'newcomer', 'jessica', 'campbell', ',', 'as', 'paul', \"'\", 's', 'anti', '-', 'social', 'sister', ',', 'tammy', '.'], ['broderick', 'here', 'is', 'playing', 'the', 'mr', '.', 'rooney', 'role', 'from', '_ferris', 'bueller_', ',', 'and', 'he', 'seems', 'to', 'be', 'having', 'the', 'most', 'fun', 'he', \"'\", 's', 'had', 'since', 'then', '.'], ['witherspoon', 'is', 'a', 'revelation', '.'], ['it', \"'\", 's', 'early', 'in', 'the', 'year', ',', 'it', \"'\", 's', 'a', 'comedy', ',', 'and', 'teenagers', 'have', 'little', 'clout', ',', 'but', 'for', 'my', 'money', ',', 'witherspoon', 'deserves', 'an', 'oscar', 'nomination', '.'], ['and', 'once', 'campbell', \"'\", 's', 'character', 'gets', 'going', ',', 'like', 'in', 'her', 'fantastic', 'speech', 'in', 'the', 'gymnasium', ',', 'then', 'you', \"'\", 're', 'won', 'over', '.'], ['one', 'thing', 'that', \"'\", 's', 'been', 'bothering', 'me', 'since', 'i', \"'\", 've', 'seen', 'it', '.'], ['there', 'is', 'an', 'extraordinary', 'amount', 'of', 'sexuality', 'in', 'this', 'film', '.'], ['i', 'suppose', 'that', ',', 'coming', 'from', 'mtv', 'films', ',', 'i', 'should', 'expect', 'no', 'less', '.'], ['.', '.', 'but', 'the', 'film', 'starts', 'off', 'light', 'and', 'airy', ',', 'like', 'a', 'sitcom', '.'], ['as', 'the', 'screws', 'tighten', ',', 'and', 'the', 'tensions', 'mount', ',', 'alexander', 'payne', 'decides', 'to', 'add', 'elements', 'that', ',', 'frankly', ',', 'distract', 'from', 'the', 'story', '.'], ['it', 'is', 'bad', 'enough', 'that', 'mr', '.', 'm', 'doesn', \"'\", 't', 'like', 'tracy', \"'\", 's', 'determination', 'to', 'win', 'at', 'all', 'costs', ',', 'but', 'did', 'they', 'have', 'to', 'throw', 'in', 'the', 'student', '/', 'teacher', 'relationship', '?'], ['even', 'so', ',', 'there', \"'\", 's', 'no', 'logical', 'reason', 'why', 'mr', '.', 'm', 'has', 'an', 'affair', 'when', 'he', 'does', '.'], ['there', \"'\", 's', 'a', 'lot', 'to', 'like', 'in', '_election_', ',', 'but', 'the', 'plot', 'similarities', 'to', '_rushmore_', ',', 'and', 'the', 'tonal', 'nosedive', 'it', 'takes', 'as', 'it', 'gets', 'explicitly', 'sex', '-', 'driven', ',', 'mark', 'this', 'as', 'a', 'disappointment', '.']], ...]\n"
          ]
        }
      ],
      "source": [
        "mr = movie_reviews\n",
        "neg = mr.paras(categories = \"neg\")\n",
        "pos = mr.paras(categories = \"pos\")\n",
        "print(f\"length of each part of the dataset:\\n - pos: {len(pos)} \\n - neg: {len(neg)}\")\n",
        "print(pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-Y4wuDNt7XW"
      },
      "source": [
        "It's easy to see that data comes in the following format:\n",
        "\n",
        "- pos = [doc1, doc2, ..., doc1000] (the same applies for negative sentiment examples)\n",
        "\n",
        "Where each doc has the following structure:\n",
        "\n",
        "- doc1 = [sentence_1, sentence_2, ..., sentence_k]\n",
        "\n",
        "Each sentence is a list of tokens, so the dataset is already tokenized.\n",
        "\n",
        "### Word embedding\n",
        "Since I'm going to use deep learning models, I'm going to choose a word embedding to transform the text into vectors.\n",
        "I'm going to start with a pretrained version of GloVe word embedding.\n",
        "Since is a pre-trained word embedding (hence basically a lookup table), I'm going to check how many words of the vocabulary are covered by the pretrained word embedding model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_SEn4EFxKTd"
      },
      "outputs": [],
      "source": [
        "def create_vocab(corpus_words):\n",
        "    vocab = dict()\n",
        "    for word in corpus_words:\n",
        "      try:\n",
        "        vocab[word] += 1\n",
        "      except:\n",
        "        vocab[word] = 1\n",
        "    return vocab\n",
        "\n",
        "def get_corpus_words(corpus) -> list:\n",
        "    return [w for doc in corpus for sent in doc for w in sent]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdofBhKWxQHx",
        "outputId": "11f33a8a-0e37-4949-eb78-3ab35ce43387"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.840B.300d.zip: 2.18GB [06:50, 5.31MB/s]                            \n",
            "100%|█████████▉| 2196016/2196017 [04:24<00:00, 8308.59it/s]\n",
            "100%|██████████| 39768/39768 [00:01<00:00, 22744.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Found embeddings for 91.93% of vocab\n",
            "Found embeddings for  99.58% of all text\n"
          ]
        }
      ],
      "source": [
        "import operator\n",
        "from tqdm import tqdm\n",
        "from torchtext.vocab import GloVe\n",
        "import torch\n",
        "\n",
        "global_vectors = GloVe(name='840B', dim=300)\n",
        "\n",
        "# function inspired by https://www.kaggle.com/code/christofhenkel/how-to-preprocessing-when-using-embeddings/notebook\n",
        "def check_coverage(vocab,embeddings_index):\n",
        "    a = {}\n",
        "    oov = {}\n",
        "    k = 0\n",
        "    i = 0\n",
        "    null_embedding = torch.tensor([0.0]*300)\n",
        "    for word in tqdm(vocab):\n",
        "        try:\n",
        "          if torch.equal(embeddings_index.get_vecs_by_tokens(word), null_embedding):\n",
        "            raise KeyError\n",
        "          a[word] = embeddings_index.get_vecs_by_tokens(word)\n",
        "          k += vocab[word]\n",
        "        except:\n",
        "\n",
        "            oov[word] = vocab[word]\n",
        "            i += vocab[word]\n",
        "            pass\n",
        "\n",
        "    print()\n",
        "    print(f'Found embeddings for {len(a) / len(vocab):.2%} of vocab')\n",
        "    print(f'Found embeddings for  {k / (k + i):.2%} of all text')\n",
        "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
        "\n",
        "    return sorted_x\n",
        "\n",
        "vocab = create_vocab(get_corpus_words(pos + neg))\n",
        "oov = check_coverage(vocab, global_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K0HUOB2-E1V"
      },
      "outputs": [],
      "source": [
        "oov"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEjIRmuG-Quz"
      },
      "source": [
        "I'm going to see which are the words that are not covered by the embedding (Out Of Vocabulary words), so I can try to see if there are some tenchniques that can be applied in order to improve coverage.\n",
        "The majority of OOV words aren't related with a praticular sentiment (they are basically nouns or some type punctuation), so they can be safely removed. That happens because unknown words are encoded as $[0] * embedding.length$, so no useful information is added.\n",
        "Others OOV words are regular words surrounded by underscores, so they are not recognized by the fixed word embedding. To avoid this problem I implemented a procedure in order to clean these words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgvlBpnMB8EO"
      },
      "outputs": [],
      "source": [
        "def remove_underscores(corpus):\n",
        "  for doc in corpus:\n",
        "    for sent in doc:\n",
        "      for idx, word in enumerate(sent):\n",
        "        if \"_\" in word:\n",
        "          cleaned_word = _clean_word(word)\n",
        "          sent[idx] = cleaned_word\n",
        "  return corpus\n",
        "\n",
        "\n",
        "def _clean_word(word: str):\n",
        "  word = word.replace(\"_\", \" \")\n",
        "  word = word.split()\n",
        "  word = \" \".join(word)\n",
        "  return word\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUphYnDOa785",
        "outputId": "e0b314d1-9afc-4056-bcd1-d731c2fb907a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 39519/39519 [00:01<00:00, 28083.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Found embeddings for 92.48% of vocab\n",
            "Found embeddings for  99.61% of all text\n"
          ]
        }
      ],
      "source": [
        "corpus = pos + neg\n",
        "clean_corpus = remove_underscores(corpus), oov\n",
        "vocab = create_vocab(get_corpus_words(clean_corpus))\n",
        "oov = check_coverage(vocab, global_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cmath import phase\n",
        "from dis import findlabels\n",
        "from unicodedata import name\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "\n",
        "CONTRACTION_MAP =  {\"ain't\": \"is not\",\n",
        "                        \"aren't\": \"are not\",\n",
        "                        \"can't\": \"cannot\",\n",
        "                        \"can't've\": \"cannot have\",\n",
        "                        \"'cause\": \"because\",\n",
        "                        \"could've\": \"could have\",\n",
        "                        \"couldn't\": \"could not\",\n",
        "                        \"couldn't've\": \"could not have\",\n",
        "                        \"didn't\": \"did not\",\n",
        "                        \"doesn't\": \"does not\",\n",
        "                        \"don't\": \"do not\",\n",
        "                        \"hadn't\": \"had not\",\n",
        "                        \"hadn't've\": \"had not have\",\n",
        "                        \"hasn't\": \"has not\",\n",
        "                        \"haven't\": \"have not\",\n",
        "                        \"he'd\": \"he would\",\n",
        "                        \"he'd've\": \"he would have\",\n",
        "                        \"he'll\": \"he will\",\n",
        "                        \"he'll've\": \"he he will have\",\n",
        "                        \"he's\": \"he is\",\n",
        "                        \"how'd\": \"how did\",\n",
        "                        \"how'd'y\": \"how do you\",\n",
        "                        \"how'll\": \"how will\",\n",
        "                        \"how's\": \"how is\",\n",
        "                        \"i'd\": \"i would\",\n",
        "                        \"i'd've\": \"i would have\",\n",
        "                        \"i'll\": \"i will\",\n",
        "                        \"i'll've\": \"i will have\",\n",
        "                        \"i'm\": \"i am\",\n",
        "                        \"i've\": \"i have\",\n",
        "                        \"isn't\": \"is not\",\n",
        "                        \"it'd\": \"it would\",\n",
        "                        \"it'd've\": \"it would have\",\n",
        "                        \"it'll\": \"it will\",\n",
        "                        \"it'll've\": \"it will have\",\n",
        "                        \"it's\": \"it is\",\n",
        "                        \"let's\": \"let us\",\n",
        "                        \"ma'am\": \"madam\",\n",
        "                        \"mayn't\": \"may not\",\n",
        "                        \"might've\": \"might have\",\n",
        "                        \"mightn't\": \"might not\",\n",
        "                        \"mightn't've\": \"might not have\",\n",
        "                        \"must've\": \"must have\",\n",
        "                        \"mustn't\": \"must not\",\n",
        "                        \"mustn't've\": \"must not have\",\n",
        "                        \"needn't\": \"need not\",\n",
        "                        \"needn't've\": \"need not have\",\n",
        "                        \"o'clock\": \"of the clock\",\n",
        "                        \"oughtn't\": \"ought not\",\n",
        "                        \"oughtn't've\": \"ought not have\",\n",
        "                        \"shan't\": \"shall not\",\n",
        "                        \"sha'n't\": \"shall not\",\n",
        "                        \"shan't've\": \"shall not have\",\n",
        "                        \"she'd\": \"she would\",\n",
        "                        \"she'd've\": \"she would have\",\n",
        "                        \"she'll\": \"she will\",\n",
        "                        \"she'll've\": \"she will have\",\n",
        "                        \"she's\": \"she is\",\n",
        "                        \"should've\": \"should have\",\n",
        "                        \"shouldn't\": \"should not\",\n",
        "                        \"shouldn't've\": \"should not have\",\n",
        "                        \"so've\": \"so have\",\n",
        "                        \"so's\": \"so as\",\n",
        "                        \"that'd\": \"that would\",\n",
        "                        \"that'd've\": \"that would have\",\n",
        "                        \"that's\": \"that is\",\n",
        "                        \"there'd\": \"there would\",\n",
        "                        \"there'd've\": \"there would have\",\n",
        "                        \"there's\": \"there is\",\n",
        "                        \"they'd\": \"they would\",\n",
        "                        \"they'd've\": \"they would have\",\n",
        "                        \"they'll\": \"they will\",\n",
        "                        \"they'll've\": \"they will have\",\n",
        "                        \"they're\": \"they are\",\n",
        "                        \"they've\": \"they have\",\n",
        "                        \"to've\": \"to have\",\n",
        "                        \"wasn't\": \"was not\",\n",
        "                        \"we'd\": \"we would\",\n",
        "                        \"we'd've\": \"we would have\",\n",
        "                        \"we'll\": \"we will\",\n",
        "                        \"we'll've\": \"we will have\",\n",
        "                        \"we're\": \"we are\",\n",
        "                        \"we've\": \"we have\",\n",
        "                        \"weren't\": \"were not\",\n",
        "                        \"what'll\": \"what will\",\n",
        "                        \"what'll've\": \"what will have\",\n",
        "                        \"what're\": \"what are\",\n",
        "                        \"what's\": \"what is\",\n",
        "                        \"what've\": \"what have\",\n",
        "                        \"when's\": \"when is\",\n",
        "                        \"when've\": \"when have\",\n",
        "                        \"where'd\": \"where did\",\n",
        "                        \"where's\": \"where is\",\n",
        "                        \"where've\": \"where have\",\n",
        "                        \"who'll\": \"who will\",\n",
        "                        \"who'll've\": \"who will have\",\n",
        "                        \"who's\": \"who is\",\n",
        "                        \"who've\": \"who have\",\n",
        "                        \"why's\": \"why is\",\n",
        "                        \"why've\": \"why have\",\n",
        "                        \"will've\": \"will have\",\n",
        "                        \"won't\": \"will not\",\n",
        "                        \"won't've\": \"will not have\",\n",
        "                        \"would've\": \"would have\",\n",
        "                        \"wouldn't\": \"would not\",\n",
        "                        \"wouldn't've\": \"would not have\",\n",
        "                        \"y'all\": \"you all\",\n",
        "                        \"y'all'd\": \"you all would\",\n",
        "                        \"y'all'd've\": \"you all would have\",\n",
        "                        \"y'all're\": \"you all are\",\n",
        "                        \"y'all've\": \"you all have\",\n",
        "                        \"you'd\": \"you would\",\n",
        "                        \"you'd've\": \"you would have\",\n",
        "                        \"you'll\": \"you will\",\n",
        "                        \"you'll've\": \"you will have\",\n",
        "                        \"you're\": \"you are\",\n",
        "                        \"you've\": \"you have\",\n",
        "                    }\n",
        "class MRAbstractPipeline():\n",
        "    def __init__(self):\n",
        "        self.pipeline = []\n",
        "    \n",
        "    def pipe(self, corpus):\n",
        "        for el in self.pipeline:\n",
        "            corpus = el(corpus)\n",
        "        return corpus\n",
        "    \n",
        "    def __call__(self, *args, **kwds):\n",
        "        if args[0] == None:\n",
        "            raise ValueError(\"Need a corpus as argument\")\n",
        "        corpus = args[0]\n",
        "        return self.pipe(corpus)\n",
        "        \n",
        "\n",
        "class MRPipelineTokens(MRAbstractPipeline):\n",
        "    \"\"\"\n",
        "    Pipeline for documents represented as list of tokens\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(MRPipelineTokens, self).__init__()\n",
        "        self.pipeline = [self.remove_underscores, \n",
        "                         self.reducing_character_repetitions,\n",
        "                         self.clean_contractions,\n",
        "                         self.clean_special_chars,\n",
        "                         self.remove_stop_words]\n",
        "\n",
        "    def remove_underscores(self, corpus):\n",
        "        \"\"\"\n",
        "        Solves the problem where some of the words are surrounded by underscores\n",
        "        (e.g. \"_hello_\")\n",
        "        \"\"\"\n",
        "        for doc in corpus:\n",
        "            for idx, word in enumerate(doc):\n",
        "                if \"_\" in word:\n",
        "                    cleaned_word = self._clean_word(word)\n",
        "                    doc[idx] = cleaned_word\n",
        "        return corpus\n",
        "\n",
        "\n",
        "    def _clean_word(self, word: str):\n",
        "        word = word.replace(\"_\", \" \")\n",
        "        # remove spaces before and after the word\n",
        "        word = word.split()\n",
        "        word = \" \".join(word)\n",
        "        return word\n",
        "    \n",
        "    def reducing_character_repetitions(self, corpus):\n",
        "        \n",
        "        new_corpus = []\n",
        "        for doc in corpus:\n",
        "            new_doc = [self._clean_repetitions(w) for w in doc]\n",
        "            new_corpus.append(new_doc)\n",
        "        return new_corpus\n",
        "\n",
        "    # inspired by https://towardsdatascience.com/cleaning-preprocessing-text-data-by-building-nlp-pipeline-853148add68a\n",
        "    def _clean_repetitions(self, word):\n",
        "        \"\"\"\n",
        "        This Function will reduce repetition to two characters \n",
        "        for alphabets and to one character for punctuations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "            word: str                \n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            Finally formatted text with alphabets repeating to \n",
        "            one characters & punctuations limited to one repetition \n",
        "            \n",
        "        Example:\n",
        "        Input : Realllllllllyyyyy,        Greeeeaaaatttt   !!!!?....;;;;:)\n",
        "        Output : Really, Great !?.;:)\n",
        "\n",
        "        \"\"\"\n",
        "        # Pattern matching for all case alphabets\n",
        "        pattern_alpha = re.compile(r\"([A-Za-z])\\1{1,}\", re.DOTALL)\n",
        "\n",
        "        # Limiting all the repetitions to two characters.\n",
        "        # MODIFIED: keep only one repetition of the character\n",
        "        formatted_text = pattern_alpha.sub(r\"\\1\\1\", word) \n",
        "\n",
        "        # Pattern matching for all the punctuations that can occur\n",
        "        pattern_punct = re.compile(r'([.,/#!$%^&*?;:{}=_`~()+-])\\1{1,}')\n",
        "\n",
        "        # Limiting punctuations in previously formatted string to only one.\n",
        "        combined_formatted = pattern_punct.sub(r'\\1', formatted_text)\n",
        "\n",
        "        # The below statement is replacing repetitions of spaces that occur more than two times with that of one occurrence.\n",
        "        final_formatted = re.sub(' {2,}',' ', combined_formatted)\n",
        "        return final_formatted\n",
        "    \n",
        "    def clean_contractions(self, corpus):\n",
        "        new_corpus = []\n",
        "        for doc in corpus:\n",
        "            new_doc = []\n",
        "            for word in doc:\n",
        "                try:\n",
        "                    correct = CONTRACTION_MAP[word]\n",
        "                    correct = correct.split()\n",
        "                    new_doc += correct\n",
        "                except:\n",
        "                    new_doc.append(word)\n",
        "            new_corpus.append(new_doc)\n",
        "        return new_corpus\n",
        "\n",
        "    def clean_special_chars(self, corpus):\n",
        "        new_corpus = [[self._clean_special_word(w) for w in doc] for doc in corpus] \n",
        "        return new_corpus\n",
        "    \n",
        "    def _clean_special_word(self, word):\n",
        "        # The formatted text after removing not necessary punctuations.\n",
        "        formatted_text = re.sub(r\"[^a-zA-Z0-9:€$-,%.?!]+\", '', word) \n",
        "        # In the above regex expression,I am providing necessary set of punctuations that are frequent in this particular dataset.\n",
        "        return formatted_text\n",
        "    \n",
        "    def remove_stop_words(self, corpus):\n",
        "        stops = stopwords.words(\"english\")\n",
        "        stops = [word for word in stops if \"'t\" not in word or \"not\" not in word]\n",
        "        return [[word for word in doc if word not in stops] for doc in corpus]\n",
        "    \n",
        "\n",
        "class MRPipelinePhrases(MRAbstractPipeline):\n",
        "    \"\"\"\n",
        "    Pipeline for documents represented as list of phrases\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(MRPipelinePhrases, self).__init__()\n",
        "        self.pipeline = [self.remove_underscores, \n",
        "                         self.clean_special_chars,\n",
        "                         self.reducing_character_repetitions,\n",
        "                         self.lemmatize]\n",
        "\n",
        "    def remove_underscores(self, corpus):\n",
        "        \"\"\"\n",
        "        Solves the problem where some of the words are surrounded by underscores\n",
        "        (e.g. \"_hello_\")\n",
        "        \"\"\"\n",
        "        new_corpus = [self._clean_word(doc) for doc in corpus]\n",
        "        return new_corpus\n",
        "\n",
        "\n",
        "    def _clean_word(self, doc: str):\n",
        "        doc = doc.replace(\"_\", \" \")\n",
        "        return doc\n",
        "    \n",
        "    def reducing_character_repetitions(self, corpus):\n",
        "        new_corpus = [self._clean_repetitions(doc) for doc in corpus]\n",
        "        return new_corpus\n",
        "    \n",
        "    # inspired by https://towardsdatascience.com/cleaning-preprocessing-text-data-by-building-nlp-pipeline-853148add68a\n",
        "    def _clean_repetitions(self, word):\n",
        "        \"\"\"\n",
        "        This Function will reduce repetition to two characters \n",
        "        for alphabets and to one character for punctuations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "            word: str                \n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            Finally formatted text with alphabets repeating to \n",
        "            one characters & punctuations limited to one repetition \n",
        "            \n",
        "        Example:\n",
        "        Input : Realllllllllyyyyy,        Greeeeaaaatttt   !!!!?....;;;;:)\n",
        "        Output : Realy, Great !?.;:)\n",
        "\n",
        "        \"\"\"\n",
        "        # Pattern matching for all case alphabets\n",
        "        pattern_alpha = re.compile(r\"([A-Za-z])\\1{1,}\", re.DOTALL)\n",
        "\n",
        "        # Limiting all the repetitions to two characters.\n",
        "        # MODIFIED: keep only one repetition of the character\n",
        "        formatted_text = pattern_alpha.sub(r\"\\1\\1\", word) \n",
        "\n",
        "        # Pattern matching for all the punctuations that can occur\n",
        "        pattern_punct = re.compile(r'([., /#!$%^&*?;:{}=_`~()+-])\\1{1,}')\n",
        "\n",
        "        # Limiting punctuations in previously formatted string to only one.\n",
        "        combined_formatted = pattern_punct.sub(r'\\1', formatted_text)\n",
        "\n",
        "        # The below statement is replacing repetitions of spaces that occur more than two times with that of one occurrence.\n",
        "        final_formatted = re.sub(' {2,}',' ', combined_formatted)\n",
        "        return final_formatted\n",
        "\n",
        "    def clean_special_chars(self, corpus):\n",
        "        new_corpus = [self._clean_special_word(doc)  for doc in corpus]\n",
        "        return new_corpus\n",
        "    \n",
        "    def _clean_special_word(self, word):\n",
        "        # The formatted text after removing not necessary punctuations.\n",
        "        formatted_text = re.sub(r\"[^a-zA-Z0-9:€$-,%.?!]+\", ' ', word) \n",
        "        # In the above regex expression,I am providing necessary set of punctuations that are frequent in this particular dataset.\n",
        "        return formatted_text\n",
        "    \n",
        "\n",
        "    def lemmatize(self, corpus):\n",
        "        nlp = spacy.load('en_core_web_sm')\n",
        "        return [[token.lemma_ for token in nlp(doc)] for doc in corpus]\n"
      ],
      "metadata": {
        "id": "spYv4QqyqJ0H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skv2-rEQwMtR"
      },
      "source": [
        "### Corpus class\n",
        "I'm going to create a class for the representation of the corpus in order to have a self contained way to have all the functions that may be useful for the processing of the corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C3PyvlOV60V7"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "import numpy as np\n",
        "import torch\n",
        "import spacy\n",
        "\n",
        "\n",
        "class MovieReviewsCorpusPhrases():\n",
        "    def __init__(self, preprocess_pipeline = None):\n",
        "        \"\"\"\n",
        "        If non preprocess_pipeline is given, the text gets tokenized by default\n",
        "        using spacy tokenizer\n",
        "        \"\"\"\n",
        "        self.mr = movie_reviews\n",
        "        if preprocess_pipeline != None and not isinstance(preprocess_pipeline, MRPipelinePhrases):\n",
        "            raise ValueError(f\"preprocess_pipeline is not valid, you should pass \\\n",
        "                                a MRPipelinePhrases object or None\")\n",
        "        self.pipeline = preprocess_pipeline\n",
        "        self.raw_corpus, self.labels = self._get_raw_corpus()\n",
        "        if self.pipeline == None:\n",
        "            self.processed_corpus = self.raw_corpus\n",
        "        else:\n",
        "            # Flattened and preprocessed corpus\n",
        "            self.processed_corpus = self._preprocess()\n",
        "        \n",
        "        self.vocab = self._create_vocab()\n",
        "        \n",
        "\n",
        "    def _get_raw_corpus(self):\n",
        "        neg = [self.mr.raw(doc) for doc in self.mr.fileids()[:1000]]\n",
        "        pos = [self.mr.raw(doc) for doc in self.mr.fileids()[1000:]]\n",
        "        labels = [0]*len(neg) + [1]*len(pos)\n",
        "        return neg + pos, labels\n",
        "    \n",
        "    def _preprocess(self):\n",
        "        if self.pipeline != None:\n",
        "            return self.pipeline(self.raw_corpus)\n",
        "        else:\n",
        "            nlp = spacy.load('en_core_web_sm')\n",
        "            return [[token.lemma_ for token in nlp(doc)] for doc in self.raw_corpus]\n",
        "        \n",
        "    def _create_vocab(self):\n",
        "        vocab = dict()\n",
        "        corpus_words = [w for doc in self.processed_corpus for w in doc]\n",
        "        for word in corpus_words:\n",
        "            try:\n",
        "                vocab[word] += 1\n",
        "            except:\n",
        "                vocab[word] = 1\n",
        "        return vocab\n",
        "\n",
        "    def get_embedding_matrix(self, embedding, embedding_dim):\n",
        "        \"\"\"\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            A 2D which each row has the corresponding embedding from the vocabulary\n",
        "        \"\"\"\n",
        "        matrix_length = len(self.vocab)\n",
        "        embedding_matrix = np.zeros((matrix_length, embedding_dim))\n",
        "        # If I use torch.zeros directly it crashes (don't know why)\n",
        "        embedding_matrix = torch.from_numpy(embedding_matrix.copy())\n",
        "        null_embedding = torch.tensor([0.0]*embedding_dim)\n",
        "        for idx, key in enumerate(self.vocab.keys()):\n",
        "            if torch.equal(embedding[key], null_embedding):\n",
        "                embedding_matrix[idx] = torch.randn(embedding_dim)\n",
        "            else:\n",
        "                embedding_matrix[idx] = embedding[key]\n",
        "                \n",
        "        return embedding_matrix\n",
        "    \n",
        "    def get_indexed_corpus(self):\n",
        "        \"\"\"\n",
        "        Returns\n",
        "        -------\n",
        "        Dictionary\n",
        "            Containing correspondences word -> index\n",
        "        \n",
        "        list(list(torch.tensor))\n",
        "            The corpus represented as indexes corresponding to each word\n",
        "        \"\"\"\n",
        "        vocab = {}\n",
        "        for idx, key in enumerate(self.vocab.keys()):\n",
        "            vocab[key] = idx\n",
        "        \n",
        "        indexed_corpus = [torch.tensor([torch.tensor(vocab[w], dtype=torch.int32) for w in doc]) for doc in self.processed_corpus]\n",
        "        return indexed_corpus, self.labels\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.processed_corpus)\n",
        "\n",
        "\n",
        "class MovieReviewsCorpus():\n",
        "    def __init__(self, preprocess_pipeline = None):\n",
        "        # list of documents, each document is a list containing words of that document\n",
        "        self.mr = movie_reviews\n",
        "        self.pipeline = preprocess_pipeline\n",
        "        # Corpus as list of documents. Documents as list of sentences. Sentences as list of tokens\n",
        "        self.unprocessed_corpus, self.labels = self._get_corpus()\n",
        "        # Corpus as list of documents. Documents as list of tokens\n",
        "        self.flattened_corpus = self._flatten()\n",
        "        if preprocess_pipeline == None:\n",
        "            self.processed_corpus = self.flattened_corpus\n",
        "        else:\n",
        "            # Flattened and preprocessed corpus\n",
        "            self.processed_corpus = self._preprocess()\n",
        "\n",
        "        self.corpus_words = self.get_corpus_words()\n",
        "        self.vocab = self._create_vocab()\n",
        "\n",
        "\n",
        "\n",
        "    def _list_to_str(self, doc) -> str:\n",
        "        \"\"\"\n",
        "        Put all elements of the list into a single string, separating each element with a space.\n",
        "        \"\"\"\n",
        "        return \" \".join([w for sent in doc for w in sent])\n",
        "\n",
        "    def _preprocess(self):\n",
        "        return self.pipeline(self.flattened_corpus)\n",
        "\n",
        "    def _flatten(self):\n",
        "        \"\"\"\n",
        "        Returns\n",
        "        -------\n",
        "        list[list[str]]\n",
        "            Each inner list represents a document. Each document is a list of tokens.\n",
        "        \"\"\"\n",
        "\n",
        "        # 3 nested list: each list contain a document, each inner list contains a phrase (until fullstop), each phrase contains words.\n",
        "\n",
        "        corpus = [[w for w in self._list_to_str(d).split(\" \")] for d in self.unprocessed_corpus]\n",
        "        return corpus\n",
        "\n",
        "    def _get_corpus(self):\n",
        "        neg = self.mr.paras(categories = \"neg\")\n",
        "        pos = self.mr.paras(categories = \"pos\")\n",
        "        labels = [0] * len(pos) + [1] * len(neg)\n",
        "        return neg + pos, labels\n",
        "\n",
        "    def movie_reviews_dataset_raw(self):\n",
        "        \"\"\"\n",
        "        Returns the dataset containing:\n",
        "\n",
        "        - A list of all the documents\n",
        "        - The corresponding label for each document\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tuple(list, list)\n",
        "            The dataset: first element is the list of the document, the second element of the tuple is the associated label (positive or negative) for each document\n",
        "        \"\"\"\n",
        "\n",
        "        return self.flattened_corpus, self.labels\n",
        "\n",
        "    def get_sentence_ds(self):\n",
        "        neg = self.mr.paras(categories = \"neg\")\n",
        "        pos = self.mr.paras(categories = \"pos\")\n",
        "\n",
        "        pos = [phrase for doc in pos for phrase in doc]\n",
        "        neg = [phrase for doc in neg for phrase in doc]\n",
        "\n",
        "        labels = np.array([0] * len(pos) + [1] * len(neg))\n",
        "        corpus = neg+pos\n",
        "        return corpus, labels\n",
        "\n",
        "\n",
        "    def get_corpus_words(self) -> list:\n",
        "        return [w for doc in self.processed_corpus for w in doc]\n",
        "    \n",
        "    def get_embedding_matrix(self, embedding, embedding_dim):\n",
        "        \"\"\"\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            A 2D which each row has the corresponding embedding from the vocabulary\n",
        "        \"\"\"\n",
        "        matrix_length = len(self.vocab)\n",
        "        embedding_matrix = np.zeros((matrix_length, embedding_dim))\n",
        "        # If I use torch.zeros directly it crashes (don't know why)\n",
        "        embedding_matrix = torch.from_numpy(embedding_matrix.copy())\n",
        "        null_embedding = torch.tensor([0.0]*embedding_dim)\n",
        "        for idx, key in enumerate(self.vocab.keys()):\n",
        "            if torch.equal(embedding[key], null_embedding):\n",
        "                embedding_matrix[idx] = torch.randn(embedding_dim)\n",
        "            else:\n",
        "                embedding_matrix[idx] = embedding[key]\n",
        "                \n",
        "        return embedding_matrix\n",
        "    \n",
        "    def get_fasttext_embedding_matrix(self, embedding, embedding_dim):\n",
        "        matrix_length = len(self.vocab)\n",
        "        embedding_matrix = np.zeros((matrix_length, embedding_dim))\n",
        "        # If I use torch.zeros directly it crashes (don't know why)\n",
        "        embedding_matrix = torch.from_numpy(embedding_matrix.copy())\n",
        "        null_embedding = torch.tensor([0.0]*embedding_dim)\n",
        "        for idx, key in enumerate(self.vocab.keys()):\n",
        "            tensor_embedding = torch.from_numpy(embedding[key].copy())\n",
        "            if torch.equal(tensor_embedding, null_embedding):\n",
        "                embedding_matrix[idx] = torch.randn(embedding_dim)\n",
        "            else:\n",
        "                embedding_matrix[idx] = tensor_embedding\n",
        "                \n",
        "        return embedding_matrix\n",
        "    \n",
        "    def get_indexed_corpus(self):\n",
        "        \"\"\"\n",
        "        Returns\n",
        "        -------\n",
        "        Dictionary\n",
        "            Containing correspondences word -> index\n",
        "        \n",
        "        list(list(torch.tensor))\n",
        "            The corpus represented as indexes corresponding to each word\n",
        "        \"\"\"\n",
        "        vocab = {}\n",
        "        for idx, key in enumerate(self.vocab.keys()):\n",
        "            vocab[key] = idx\n",
        "        \n",
        "        indexed_corpus = [torch.tensor([torch.tensor(vocab[w], dtype=torch.int32) for w in doc]) for doc in self.processed_corpus]\n",
        "        return indexed_corpus, self.labels\n",
        "\n",
        "\n",
        "    def _create_vocab(self):\n",
        "        vocab = dict()\n",
        "        for word in self.corpus_words:\n",
        "            try:\n",
        "                vocab[word] += 1\n",
        "            except:\n",
        "                vocab[word] = 1\n",
        "        return vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.flattened_corpus)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zZaF5yV9rlo-"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "class MovieReviewsDataset(Dataset):\n",
        "  def __init__(self, raw_dataset):\n",
        "    super(MovieReviewsDataset, self).__init__()\n",
        "    self.corpus = np.array(raw_dataset[0], dtype = object)\n",
        "    self.targets = np.array(raw_dataset[1], dtype = np.int32)\n",
        "    self.max_element = len(max(self.corpus, key=lambda x: len(x)))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.corpus)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    item = self.corpus[index]\n",
        "    label = self.targets[index]\n",
        "    return (item, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr7PPG1k4gFq"
      },
      "source": [
        "### Create the model class\n",
        "Let's first try with a simple BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bCvqaJ8-hKmT"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.utils.rnn import pad_packed_sequence\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, embedding_matrix, device = \"cuda\", input_size = 300, hidden_size = 128, output_size = 2):\n",
        "        super(BiLSTM, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.device = device\n",
        "        self.embedding = self.create_embedding_layer(embedding_matrix)\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first = True, bidirectional=True)\n",
        "        self.fc = nn.Sequential(nn.ReLU(),\n",
        "                                nn.BatchNorm1d(hidden_size*2, eps = 1e-08),\n",
        "                                nn.Dropout(0.3),\n",
        "                                nn.Linear(hidden_size*2, output_size)\n",
        "                                )\n",
        "\n",
        "    def create_embedding_layer(self, embedding_matrix):\n",
        "        num_embeddings, embedding_dim = embedding_matrix.shape\n",
        "        emb_layer = nn.Embedding(num_embeddings, embedding_dim, -1)\n",
        "        emb_layer.load_state_dict({\"weight\": embedding_matrix})\n",
        "        return emb_layer\n",
        "\n",
        "    # function taken from https://discuss.pytorch.org/t/how-to-use-pack-sequence-if-we-are-going-to-use-word-embedding-and-bilstm/28184/4\n",
        "    def simple_elementwise_apply(self, fn, packed_sequence):\n",
        "        \"\"\"applies a pointwise function fn to each element in packed_sequence\"\"\"\n",
        "        return torch.nn.utils.rnn.PackedSequence(fn(packed_sequence.data), packed_sequence.batch_sizes)\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        if self.cuda:\n",
        "            return (torch.zeros(2, batch_size, self.hidden_size).to(self.device),\n",
        "                    torch.zeros(2, batch_size, self.hidden_size).to(self.device),)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.batch_sizes[0].item()\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        x = self.simple_elementwise_apply(self.embedding, x)\n",
        "\n",
        "        # output: batch_size, sequence_length, hidden_size * 2 (since is bilstm)\n",
        "        out, _ = self.lstm(x, hidden)\n",
        "        out, input_sizes = pad_packed_sequence(out, batch_first=True)\n",
        "        # Interested only in the last layer\n",
        "        out = out[list(range(batch_size)), input_sizes - 1, :]\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class BiLSTMAttention(BiLSTM):\n",
        "    # BiLSTM with attention inspired by the following paper: https://aclanthology.org/S18-1040.pdf\n",
        "    def __init__(self, embedding_matrix, device=\"cuda\", input_size=300, hidden_size=128, output_size=2):\n",
        "        super(BiLSTMAttention, self).__init__(embedding_matrix, device, input_size, hidden_size, output_size)\n",
        "        # Not self attention :)\n",
        "        self.attention = nn.Linear(self.hidden_size * 2, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        batch_size = x.batch_sizes[0].item()\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        x = self.simple_elementwise_apply(self.embedding, x)\n",
        "\n",
        "        # output: batch_size, sequence_length, hidden_size * 2 (since is bilstm)\n",
        "        out, _ = self.lstm(x, hidden)\n",
        "        out, input_sizes = pad_packed_sequence(out, batch_first=True)\n",
        "\n",
        "        # reshape to (batch_size * seq_length, hidden)\n",
        "        attention_values = torch.tanh(self.attention(out)).squeeze()\n",
        "        attention_weights = torch.softmax(attention_values, dim = 1).unsqueeze(1)\n",
        "        out = torch.sum(attention_weights.matmul(out), dim = 1)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yZFg9BvQdZHB"
      },
      "outputs": [],
      "source": [
        "def training_step(net, data_loader, optimizer, cost_function, device = 'cuda'):\n",
        "  cumulative_loss = 0\n",
        "  cumulative_accuracy = 0\n",
        "  samples = 0\n",
        "\n",
        "  net.train()\n",
        "\n",
        "  for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "    in_size = targets.size(dim=0)\n",
        "\n",
        "    outputs = net(inputs)\n",
        "\n",
        "    loss = cost_function(outputs, targets)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    samples += in_size\n",
        "    cumulative_loss += loss.item()\n",
        "    _, predicted = outputs.max(dim=1)\n",
        "\n",
        "    cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, (cumulative_accuracy/samples)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LJef4h1cfWym"
      },
      "outputs": [],
      "source": [
        "def test_step(net, data_loader, cost_function, device = 'cuda'):\n",
        "  cumulative_loss = 0\n",
        "  cumulative_accuracy = 0\n",
        "  samples = 0\n",
        "\n",
        "  net.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      in_size = targets.size(dim=0)\n",
        "\n",
        "      outputs = net(inputs)\n",
        "\n",
        "      loss = cost_function(outputs, targets)\n",
        "\n",
        "      samples += in_size\n",
        "      cumulative_loss += loss.item()\n",
        "      _, predicted = outputs.max(dim=1)\n",
        "\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "    return cumulative_loss/samples, (cumulative_accuracy/samples)*100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OOeUmEHZNBvw"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "import torch.nn as nn\n",
        "\n",
        "def main(train_loader, test_loader, embedding_matrix, device = \"cuda\", epochs = 10):\n",
        "\n",
        "  net = BiLSTMAttention(embedding_matrix, device = device, input_size=300).to(device)\n",
        "\n",
        "  optimizer = Adam(net.parameters(), 0.001, betas = (0.9, 0.999), amsgrad=True)\n",
        "\n",
        "  cost_function = nn.CrossEntropyLoss()\n",
        "\n",
        "  for e in range(epochs):\n",
        "    print(f\"epoch {e}:\")\n",
        "    train_loss, train_accuracy = training_step(net, train_loader, optimizer, cost_function, device)\n",
        "    print(f\"Training loss: {train_loss} \\n Training accuracy: {train_accuracy}\")\n",
        "    test_loss, test_accuracy = test_step(net, test_loader, cost_function, device)\n",
        "    print(f\"Test loss: {test_loss} \\n Test accuracy: {test_accuracy}\")\n",
        "    print(\"------------------------------------------------------------------\")\n",
        "  \n",
        "  _, test_accuracy = test_step(net, test_loader, cost_function, device)\n",
        "\n",
        "\n",
        "  return test_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "GfNtrS8jmATx"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def pad(batch, max_size):\n",
        "    pad = torch.tensor([-1])\n",
        "    for idx in range(len(batch)):\n",
        "        remaining = max_size - batch[idx].size(dim = 0)\n",
        "        batch[idx] = torch.cat((batch[idx], pad.repeat(remaining)), dim = 0)\n",
        "    return batch\n",
        "\n",
        "def batch_to_tensor(X: List[torch.tensor], max_size):\n",
        "    X_tensor = torch.zeros(len(X), max_size, dtype=torch.int32)\n",
        "    for i, embed in enumerate(X):\n",
        "        X_tensor[i] = embed\n",
        "    return X_tensor\n",
        "\n",
        "def sort_ds(X, Y):\n",
        "    \"\"\"\n",
        "    Sort inputs by document lengths\n",
        "    \"\"\"\n",
        "    document_lengths = np.array([tens.size(dim = 0) for tens in X])\n",
        "    indexes = np.argsort(document_lengths)\n",
        "\n",
        "    X_sorted = X[indexes][::-1]\n",
        "    Y_sorted = Y[indexes][::-1]\n",
        "    document_lengths = torch.from_numpy(document_lengths[indexes][::-1].copy())\n",
        "\n",
        "    return X_sorted, Y_sorted, document_lengths\n",
        "\n",
        "\n",
        "\n",
        "def collate(batch):\n",
        "    X, Y = list(zip(*batch))\n",
        "    Y = np.array(list(Y))\n",
        "    X = np.array(list(X))\n",
        "\n",
        "    # Sort dataset\n",
        "    X, Y, document_lengths = sort_ds(X, Y)\n",
        "\n",
        "    # Get tensor sizes\n",
        "    max_size = torch.max(document_lengths).item()\n",
        "\n",
        "    # Pad tensor each element\n",
        "    X = pad(X, max_size)\n",
        "\n",
        "    # Transform the batch to a tensor\n",
        "    X_tensor = batch_to_tensor(X, max_size)\n",
        "    Y_tensor = torch.from_numpy(Y.copy())\n",
        "    # Return the padded sequence object\n",
        "    X_final = pack_padded_sequence(X_tensor, document_lengths, batch_first=True)\n",
        "    return X_final, Y_tensor\n",
        "\n",
        "\n",
        "def get_data(batch_size: int, dataset, collate_fn, random_state = 42):\n",
        "\n",
        "  max_element = dataset.max_element\n",
        "\n",
        "  # Random Split\n",
        "  train_indexes, test_indexes = train_test_split(list(range(len(dataset.targets))), test_size = 0.2,\n",
        "                                                  stratify = dataset.targets, random_state = random_state)\n",
        "\n",
        "  train_ds = Subset(dataset, train_indexes)\n",
        "  test_ds = Subset(dataset, test_indexes)\n",
        "\n",
        "  train_loader = DataLoader(train_ds, batch_size = batch_size, collate_fn = collate_fn, pin_memory=True)\n",
        "  test_loader = DataLoader(test_ds, batch_size = batch_size, collate_fn = collate_fn, pin_memory=True)\n",
        "\n",
        "  return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "# Workaround in order to use .targets to access labels of the subset (doesn't work with Subset pytorch class)\n",
        "# https://discuss.pytorch.org/t/attributeerror-subset-object-has-no-attribute-targets/66564\n",
        "class CustomSubset(Dataset):\n",
        "    \"\"\"\n",
        "    Subset of a dataset at specified indices.\n",
        "\n",
        "    Arguments:\n",
        "        dataset (Dataset): The whole Dataset\n",
        "        indices (sequence): Indices in the whole set selected for subset\n",
        "        labels(sequence) : targets as required for the indices. will be the same length as indices\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, indices, labels):\n",
        "        self.dataset = torch.utils.data.Subset(dataset, indices)\n",
        "        self.targets = labels\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx][0]\n",
        "        target = self.targets[idx]\n",
        "        return (item, target)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "def to_categorical(y, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    return np.eye(num_classes, dtype='uint8')[y]\n",
        "\n",
        "def main_cross_validation(dataset, embedding_matrix, collate_fn,\n",
        "                          device = \"cuda\", epochs = 20, random_state = 42, batch_size = 128):\n",
        "\n",
        "\n",
        "  train_indexes, test_indexes = train_test_split(list(range(len(dataset.targets))), test_size = 0.2,\n",
        "                                                  stratify = dataset.targets, random_state = random_state)\n",
        "\n",
        "  train_targets = np.asarray(dataset.targets[train_indexes], dtype=np.int64)\n",
        "  test_targets = np.asarray(dataset.targets[test_indexes], dtype=np.int64)\n",
        "\n",
        "  # I use ds and set because the first means that the dataset should be splitted again (train + val),\n",
        "  # the latter means that it is ready to use\n",
        "  train_ds = CustomSubset(dataset, train_indexes, train_targets)\n",
        "  test_set = CustomSubset(dataset, test_indexes, test_targets)\n",
        "  test_loader = DataLoader(test_set, batch_size = batch_size, collate_fn = collate_fn, pin_memory=True)\n",
        "\n",
        "  skf = StratifiedKFold(5, shuffle = True, random_state=random_state)\n",
        "\n",
        "  fold_accuracies = []\n",
        "  \n",
        "  for fold, (train_indexes, val_indexes) in enumerate(skf.split(np.zeros(len(train_ds)),\n",
        "                                                      train_targets)):\n",
        "    \n",
        "    net = BiLSTMAttention(embedding_matrix, device = device, input_size=300).to(device)\n",
        "    optimizer = Adam(net.parameters(), 0.001, betas = (0.9, 0.999), amsgrad=True)\n",
        "    cost_function = nn.CrossEntropyLoss()\n",
        "    \n",
        "    train_set = Subset(train_ds, train_indexes)\n",
        "    val_set = Subset(train_ds, val_indexes)\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size = batch_size, collate_fn = collate_fn, pin_memory=True)\n",
        "    val_loader = DataLoader(val_set, batch_size = batch_size, collate_fn = collate_fn, pin_memory = True)\n",
        "\n",
        "\n",
        "    for e in range(epochs):\n",
        "      print(f\"epoch {e}:\")\n",
        "      train_loss, train_accuracy = training_step(net, train_loader, optimizer, cost_function, device)\n",
        "      print(f\"Training loss: {train_loss} \\n Training accuracy: {train_accuracy}\")\n",
        "      val_loss, val_accuracy = test_step(net, val_loader, cost_function, device)\n",
        "      print(f\"Val loss: {val_loss} \\n Val accuracy: {val_accuracy}\")\n",
        "      print(\"------------------------------------------------------------------\")\n",
        "    \n",
        "    fold_accuracies.append(val_accuracy)\n",
        "\n",
        "  _, test_accuracy = test_step(net, test_loader, cost_function, device)\n",
        "\n",
        "  fold_accuracies = np.array(fold_accuracies)\n",
        "\n",
        "  return test_accuracy, fold_accuracies.mean(), fold_accuracies.std()\n",
        "\n"
      ],
      "metadata": {
        "id": "FkRBKES24_0v"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_vectors = GloVe(name='840B', dim=300, cache = \"/content/gdrive/My Drive/nlu-project/.vector_cache\")"
      ],
      "metadata": {
        "id": "hgNE3lxXrW4M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mr_pipeline = MRPipelineTokens()\n",
        "corpus = MovieReviewsCorpus(mr_pipeline)"
      ],
      "metadata": {
        "id": "Xu7rZw-mrqke"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = corpus.get_embedding_matrix(global_vectors, 300)\n",
        "ds = corpus.get_indexed_corpus()"
      ],
      "metadata": {
        "id": "0TtoFzYDsGHk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MovieReviewsDataset(ds)\n",
        "train_loader, test_loader = get_data(128, dataset, collate_fn=collate)"
      ],
      "metadata": {
        "id": "QQf9eKAqsIfr",
        "outputId": "ab560dec-d5bf-49b0-ccc2-0bcdac09f0c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDrwHvOIEsl2",
        "outputId": "a4949fb3-a263-4d6b-f801-a797877d5844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.004654649458825588 \n",
            " Training accuracy: 68.125\n",
            "Val loss: 0.006450016424059868 \n",
            " Val accuracy: 55.625\n",
            "------------------------------------------------------------------\n",
            "epoch 1:\n",
            "Training loss: 0.0034772778395563363 \n",
            " Training accuracy: 78.28125\n",
            "Val loss: 0.006337409093976021 \n",
            " Val accuracy: 64.0625\n",
            "------------------------------------------------------------------\n",
            "epoch 2:\n",
            "Training loss: 0.0026527715381234884 \n",
            " Training accuracy: 85.546875\n",
            "Val loss: 0.00611200537532568 \n",
            " Val accuracy: 65.9375\n",
            "------------------------------------------------------------------\n",
            "epoch 3:\n",
            "Training loss: 0.00165311589371413 \n",
            " Training accuracy: 91.640625\n",
            "Val loss: 0.005584266781806946 \n",
            " Val accuracy: 77.1875\n",
            "------------------------------------------------------------------\n",
            "epoch 4:\n",
            "Training loss: 0.0008723171544261277 \n",
            " Training accuracy: 96.71875\n",
            "Val loss: 0.004520142637193203 \n",
            " Val accuracy: 79.6875\n",
            "------------------------------------------------------------------\n",
            "epoch 5:\n",
            "Training loss: 0.0003918644229997881 \n",
            " Training accuracy: 98.90625\n",
            "Val loss: 0.0032958485186100005 \n",
            " Val accuracy: 85.0\n",
            "------------------------------------------------------------------\n",
            "epoch 6:\n",
            "Training loss: 0.00015951825553202071 \n",
            " Training accuracy: 99.765625\n",
            "Val loss: 0.002457397943362594 \n",
            " Val accuracy: 90.625\n",
            "------------------------------------------------------------------\n",
            "epoch 7:\n",
            "Training loss: 0.00011213052603125107 \n",
            " Training accuracy: 99.84375\n",
            "Val loss: 0.004110716376453638 \n",
            " Val accuracy: 81.5625\n",
            "------------------------------------------------------------------\n",
            "epoch 8:\n",
            "Training loss: 6.005495888530277e-05 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004195085633546114 \n",
            " Val accuracy: 83.4375\n",
            "------------------------------------------------------------------\n",
            "epoch 9:\n",
            "Training loss: 4.4408455869415776e-05 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004059920646250248 \n",
            " Val accuracy: 85.0\n",
            "------------------------------------------------------------------\n",
            "epoch 10:\n",
            "Training loss: 2.4586018844274805e-05 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.0032437704503536224 \n",
            " Val accuracy: 89.375\n",
            "------------------------------------------------------------------\n",
            "epoch 11:\n",
            "Training loss: 1.310636666858045e-05 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004075351916253567 \n",
            " Val accuracy: 85.625\n",
            "------------------------------------------------------------------\n",
            "epoch 12:\n",
            "Training loss: 8.965122697190964e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.0032577147707343102 \n",
            " Val accuracy: 89.6875\n",
            "------------------------------------------------------------------\n",
            "epoch 13:\n",
            "Training loss: 8.125397698677261e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.003604656923562288 \n",
            " Val accuracy: 89.0625\n",
            "------------------------------------------------------------------\n",
            "epoch 14:\n",
            "Training loss: 5.537791662391101e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.003492913208901882 \n",
            " Val accuracy: 89.6875\n",
            "------------------------------------------------------------------\n",
            "epoch 15:\n",
            "Training loss: 4.217825767227623e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.003645337373018265 \n",
            " Val accuracy: 89.6875\n",
            "------------------------------------------------------------------\n",
            "epoch 16:\n",
            "Training loss: 3.6880091101920697e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.0035691045224666594 \n",
            " Val accuracy: 90.0\n",
            "------------------------------------------------------------------\n",
            "epoch 17:\n",
            "Training loss: 3.673536321002757e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.0035273946821689607 \n",
            " Val accuracy: 89.375\n",
            "------------------------------------------------------------------\n",
            "epoch 18:\n",
            "Training loss: 2.7334092465025606e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.003569299075752497 \n",
            " Val accuracy: 89.6875\n",
            "------------------------------------------------------------------\n",
            "epoch 19:\n",
            "Training loss: 2.7703697469405597e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.003614472318440676 \n",
            " Val accuracy: 89.6875\n",
            "------------------------------------------------------------------\n",
            "epoch 0:\n",
            "Training loss: 0.004700763756409288 \n",
            " Training accuracy: 67.34375\n",
            "Val loss: 0.006449101865291596 \n",
            " Val accuracy: 56.875\n",
            "------------------------------------------------------------------\n",
            "epoch 1:\n",
            "Training loss: 0.0034953634487465022 \n",
            " Training accuracy: 78.4375\n",
            "Val loss: 0.006358909234404564 \n",
            " Val accuracy: 73.125\n",
            "------------------------------------------------------------------\n",
            "epoch 2:\n",
            "Training loss: 0.002360839210450649 \n",
            " Training accuracy: 88.828125\n",
            "Val loss: 0.006158985383808613 \n",
            " Val accuracy: 69.375\n",
            "------------------------------------------------------------------\n",
            "epoch 3:\n",
            "Training loss: 0.0014029632206074894 \n",
            " Training accuracy: 93.828125\n",
            "Val loss: 0.005608663521707058 \n",
            " Val accuracy: 74.375\n",
            "------------------------------------------------------------------\n",
            "epoch 4:\n",
            "Training loss: 0.0006706042506266386 \n",
            " Training accuracy: 98.046875\n",
            "Val loss: 0.004455311968922615 \n",
            " Val accuracy: 78.75\n",
            "------------------------------------------------------------------\n",
            "epoch 5:\n",
            "Training loss: 0.00025036064253072257 \n",
            " Training accuracy: 99.53125\n",
            "Val loss: 0.006179050169885158 \n",
            " Val accuracy: 71.25\n",
            "------------------------------------------------------------------\n",
            "epoch 6:\n",
            "Training loss: 0.00013001456209167374 \n",
            " Training accuracy: 99.84375\n",
            "Val loss: 0.007058887369930744 \n",
            " Val accuracy: 73.75\n",
            "------------------------------------------------------------------\n",
            "epoch 7:\n",
            "Training loss: 0.00015950231027090923 \n",
            " Training accuracy: 99.375\n",
            "Val loss: 0.003458548430353403 \n",
            " Val accuracy: 86.875\n",
            "------------------------------------------------------------------\n",
            "epoch 8:\n",
            "Training loss: 0.00018899765600508545 \n",
            " Training accuracy: 99.609375\n",
            "Val loss: 0.00853877905756235 \n",
            " Val accuracy: 69.375\n",
            "------------------------------------------------------------------\n",
            "epoch 9:\n",
            "Training loss: 7.044142948871013e-05 \n",
            " Training accuracy: 99.921875\n",
            "Val loss: 0.0048860196024179455 \n",
            " Val accuracy: 84.6875\n",
            "------------------------------------------------------------------\n",
            "epoch 10:\n",
            "Training loss: 2.853047917596996e-05 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.01204387955367565 \n",
            " Val accuracy: 73.125\n",
            "------------------------------------------------------------------\n",
            "epoch 11:\n",
            "Training loss: 1.4959052441554377e-05 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.005068717338144779 \n",
            " Val accuracy: 85.9375\n",
            "------------------------------------------------------------------\n",
            "epoch 12:\n",
            "Training loss: 4.8678122311685005e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.005723954550921917 \n",
            " Val accuracy: 86.25\n",
            "------------------------------------------------------------------\n",
            "epoch 13:\n",
            "Training loss: 3.818736058747163e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.005261828377842903 \n",
            " Val accuracy: 87.1875\n",
            "------------------------------------------------------------------\n",
            "epoch 14:\n",
            "Training loss: 3.5765024904321764e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.005020896717905998 \n",
            " Val accuracy: 86.5625\n",
            "------------------------------------------------------------------\n",
            "epoch 15:\n",
            "Training loss: 3.0861626100886495e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.005027804151177406 \n",
            " Val accuracy: 87.8125\n",
            "------------------------------------------------------------------\n",
            "epoch 16:\n",
            "Training loss: 2.4831212044773567e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.005084553267806768 \n",
            " Val accuracy: 87.5\n",
            "------------------------------------------------------------------\n",
            "epoch 17:\n",
            "Training loss: 2.110651951170439e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.00510518979281187 \n",
            " Val accuracy: 88.125\n",
            "------------------------------------------------------------------\n",
            "epoch 18:\n",
            "Training loss: 2.1289858068485045e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.005135636776685715 \n",
            " Val accuracy: 88.125\n",
            "------------------------------------------------------------------\n",
            "epoch 19:\n",
            "Training loss: 1.8156498981625191e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.005159340798854828 \n",
            " Val accuracy: 87.8125\n",
            "------------------------------------------------------------------\n",
            "epoch 0:\n",
            "Training loss: 0.004747673403471708 \n",
            " Training accuracy: 67.1875\n",
            "Val loss: 0.006451339460909367 \n",
            " Val accuracy: 57.1875\n",
            "------------------------------------------------------------------\n",
            "epoch 1:\n",
            "Training loss: 0.0035211117705330254 \n",
            " Training accuracy: 79.140625\n",
            "Val loss: 0.0063594462350010875 \n",
            " Val accuracy: 65.3125\n",
            "------------------------------------------------------------------\n",
            "epoch 2:\n",
            "Training loss: 0.002410251647233963 \n",
            " Training accuracy: 87.578125\n",
            "Val loss: 0.00616057775914669 \n",
            " Val accuracy: 68.125\n",
            "------------------------------------------------------------------\n",
            "epoch 3:\n",
            "Training loss: 0.0014340314664877951 \n",
            " Training accuracy: 94.375\n",
            "Val loss: 0.005558286421000957 \n",
            " Val accuracy: 77.8125\n",
            "------------------------------------------------------------------\n",
            "epoch 4:\n",
            "Training loss: 0.0006550568563397974 \n",
            " Training accuracy: 98.125\n",
            "Val loss: 0.004134815558791161 \n",
            " Val accuracy: 84.0625\n",
            "------------------------------------------------------------------\n",
            "epoch 5:\n",
            "Training loss: 0.00020286224244046026 \n",
            " Training accuracy: 99.84375\n",
            "Val loss: 0.003973062988370657 \n",
            " Val accuracy: 81.5625\n",
            "------------------------------------------------------------------\n",
            "epoch 6:\n",
            "Training loss: 0.00010050969503936358 \n",
            " Training accuracy: 99.84375\n",
            "Val loss: 0.0031842715106904507 \n",
            " Val accuracy: 86.5625\n",
            "------------------------------------------------------------------\n",
            "epoch 7:\n",
            "Training loss: 4.237081266182941e-05 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.0034208569675683977 \n",
            " Val accuracy: 87.8125\n",
            "------------------------------------------------------------------\n",
            "epoch 8:\n",
            "Training loss: 2.3821269496693277e-05 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004141690395772457 \n",
            " Val accuracy: 85.0\n",
            "------------------------------------------------------------------\n",
            "epoch 9:\n",
            "Training loss: 1.4423764969251352e-05 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004325108043849469 \n",
            " Val accuracy: 87.1875\n",
            "------------------------------------------------------------------\n",
            "epoch 10:\n",
            "Training loss: 1.0705637851060602e-05 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.0043453105725348 \n",
            " Val accuracy: 87.5\n",
            "------------------------------------------------------------------\n",
            "epoch 11:\n",
            "Training loss: 8.4108807186567e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004190187249332666 \n",
            " Val accuracy: 86.25\n",
            "------------------------------------------------------------------\n",
            "epoch 12:\n",
            "Training loss: 6.577772956006811e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.00420383783057332 \n",
            " Val accuracy: 87.5\n",
            "------------------------------------------------------------------\n",
            "epoch 13:\n",
            "Training loss: 5.915368637943174e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.0042322642169892784 \n",
            " Val accuracy: 87.8125\n",
            "------------------------------------------------------------------\n",
            "epoch 14:\n",
            "Training loss: 5.403994418884395e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004275976587086916 \n",
            " Val accuracy: 87.8125\n",
            "------------------------------------------------------------------\n",
            "epoch 15:\n",
            "Training loss: 5.050384606875013e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004295556712895632 \n",
            " Val accuracy: 87.1875\n",
            "------------------------------------------------------------------\n",
            "epoch 16:\n",
            "Training loss: 4.2339426954640654e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004311798885464668 \n",
            " Val accuracy: 87.5\n",
            "------------------------------------------------------------------\n",
            "epoch 17:\n",
            "Training loss: 4.11528881159029e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.0043494485318660734 \n",
            " Val accuracy: 87.8125\n",
            "------------------------------------------------------------------\n",
            "epoch 18:\n",
            "Training loss: 3.575995538085408e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004359516408294439 \n",
            " Val accuracy: 87.8125\n",
            "------------------------------------------------------------------\n",
            "epoch 19:\n",
            "Training loss: 3.2886793405850765e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004393737483769655 \n",
            " Val accuracy: 87.5\n",
            "------------------------------------------------------------------\n",
            "epoch 0:\n",
            "Training loss: 0.004810127848759294 \n",
            " Training accuracy: 65.46875\n",
            "Val loss: 0.006434017047286034 \n",
            " Val accuracy: 69.375\n",
            "------------------------------------------------------------------\n",
            "epoch 1:\n",
            "Training loss: 0.0035900532733649016 \n",
            " Training accuracy: 79.21875\n",
            "Val loss: 0.006317201256752014 \n",
            " Val accuracy: 61.875\n",
            "------------------------------------------------------------------\n",
            "epoch 2:\n",
            "Training loss: 0.0026685846969485283 \n",
            " Training accuracy: 86.5625\n",
            "Val loss: 0.006082676537334919 \n",
            " Val accuracy: 68.75\n",
            "------------------------------------------------------------------\n",
            "epoch 3:\n",
            "Training loss: 0.0015687664854340255 \n",
            " Training accuracy: 93.046875\n",
            "Val loss: 0.005530165135860443 \n",
            " Val accuracy: 80.3125\n",
            "------------------------------------------------------------------\n",
            "epoch 4:\n",
            "Training loss: 0.0007770352356601506 \n",
            " Training accuracy: 97.34375\n",
            "Val loss: 0.004283598531037569 \n",
            " Val accuracy: 84.6875\n",
            "------------------------------------------------------------------\n",
            "epoch 5:\n",
            "Training loss: 0.00028492561250459403 \n",
            " Training accuracy: 99.21875\n",
            "Val loss: 0.003699171636253595 \n",
            " Val accuracy: 82.8125\n",
            "------------------------------------------------------------------\n",
            "epoch 6:\n",
            "Training loss: 9.485359369136859e-05 \n",
            " Training accuracy: 99.84375\n",
            "Val loss: 0.005321816354990005 \n",
            " Val accuracy: 82.1875\n",
            "------------------------------------------------------------------\n",
            "epoch 7:\n",
            "Training loss: 3.764628490898758e-05 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.006492535024881363 \n",
            " Val accuracy: 82.5\n",
            "------------------------------------------------------------------\n",
            "epoch 8:\n",
            "Training loss: 3.4979267002199774e-05 \n",
            " Training accuracy: 99.921875\n",
            "Val loss: 0.005831973534077406 \n",
            " Val accuracy: 83.125\n",
            "------------------------------------------------------------------\n",
            "epoch 9:\n",
            "Training loss: 7.060352163534844e-05 \n",
            " Training accuracy: 99.765625\n",
            "Val loss: 0.004954824410378933 \n",
            " Val accuracy: 84.0625\n",
            "------------------------------------------------------------------\n",
            "epoch 10:\n",
            "Training loss: 8.399510770686902e-05 \n",
            " Training accuracy: 99.84375\n",
            "Val loss: 0.023174648731946947 \n",
            " Val accuracy: 55.93749999999999\n",
            "------------------------------------------------------------------\n",
            "epoch 11:\n",
            "Training loss: 8.739375061850296e-05 \n",
            " Training accuracy: 99.921875\n",
            "Val loss: 0.009098087251186372 \n",
            " Val accuracy: 77.5\n",
            "------------------------------------------------------------------\n",
            "epoch 12:\n",
            "Training loss: 3.639577826106688e-05 \n",
            " Training accuracy: 99.921875\n",
            "Val loss: 0.009769798256456852 \n",
            " Val accuracy: 77.1875\n",
            "------------------------------------------------------------------\n",
            "epoch 13:\n",
            "Training loss: 1.710005462882691e-05 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.0059010302647948265 \n",
            " Val accuracy: 83.4375\n",
            "------------------------------------------------------------------\n",
            "epoch 14:\n",
            "Training loss: 1.1159806126670446e-05 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.006640502996742725 \n",
            " Val accuracy: 83.125\n",
            "------------------------------------------------------------------\n",
            "epoch 15:\n",
            "Training loss: 7.331695223911084e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.006268145330250263 \n",
            " Val accuracy: 83.75\n",
            "------------------------------------------------------------------\n",
            "epoch 16:\n",
            "Training loss: 5.395797893470445e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.006697005964815617 \n",
            " Val accuracy: 82.8125\n",
            "------------------------------------------------------------------\n",
            "epoch 17:\n",
            "Training loss: 5.170881377125625e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.006458247825503349 \n",
            " Val accuracy: 83.75\n",
            "------------------------------------------------------------------\n",
            "epoch 18:\n",
            "Training loss: 4.9150648692375395e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.0064898615702986715 \n",
            " Val accuracy: 84.0625\n",
            "------------------------------------------------------------------\n",
            "epoch 19:\n",
            "Training loss: 3.535410473887168e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.006577137298882008 \n",
            " Val accuracy: 83.75\n",
            "------------------------------------------------------------------\n",
            "epoch 0:\n",
            "Training loss: 0.004964859504252672 \n",
            " Training accuracy: 63.35937499999999\n",
            "Val loss: 0.006439260765910148 \n",
            " Val accuracy: 64.375\n",
            "------------------------------------------------------------------\n",
            "epoch 1:\n",
            "Training loss: 0.0034501397283747794 \n",
            " Training accuracy: 80.234375\n",
            "Val loss: 0.006331653892993927 \n",
            " Val accuracy: 66.5625\n",
            "------------------------------------------------------------------\n",
            "epoch 2:\n",
            "Training loss: 0.0025620785309001803 \n",
            " Training accuracy: 86.640625\n",
            "Val loss: 0.0061567723751068115 \n",
            " Val accuracy: 54.37499999999999\n",
            "------------------------------------------------------------------\n",
            "epoch 3:\n",
            "Training loss: 0.0015443035401403904 \n",
            " Training accuracy: 93.671875\n",
            "Val loss: 0.005634056217968464 \n",
            " Val accuracy: 66.875\n",
            "------------------------------------------------------------------\n",
            "epoch 4:\n",
            "Training loss: 0.0008384780026972294 \n",
            " Training accuracy: 97.03125\n",
            "Val loss: 0.004694389179348946 \n",
            " Val accuracy: 75.3125\n",
            "------------------------------------------------------------------\n",
            "epoch 5:\n",
            "Training loss: 0.00037840200384380295 \n",
            " Training accuracy: 98.90625\n",
            "Val loss: 0.0033116621896624567 \n",
            " Val accuracy: 87.1875\n",
            "------------------------------------------------------------------\n",
            "epoch 6:\n",
            "Training loss: 0.00013165924174245446 \n",
            " Training accuracy: 99.84375\n",
            "Val loss: 0.002729708235710859 \n",
            " Val accuracy: 87.5\n",
            "------------------------------------------------------------------\n",
            "epoch 7:\n",
            "Training loss: 6.893364879942965e-05 \n",
            " Training accuracy: 99.921875\n",
            "Val loss: 0.0075528940185904505 \n",
            " Val accuracy: 77.8125\n",
            "------------------------------------------------------------------\n",
            "epoch 8:\n",
            "Training loss: 4.887808390776627e-05 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.00461402116343379 \n",
            " Val accuracy: 83.75\n",
            "------------------------------------------------------------------\n",
            "epoch 9:\n",
            "Training loss: 1.740010684443405e-05 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.00512139881029725 \n",
            " Val accuracy: 85.0\n",
            "------------------------------------------------------------------\n",
            "epoch 10:\n",
            "Training loss: 1.2883059480373048e-05 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.003984577115625143 \n",
            " Val accuracy: 88.125\n",
            "------------------------------------------------------------------\n",
            "epoch 11:\n",
            "Training loss: 8.627426814200589e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.003982870373874903 \n",
            " Val accuracy: 88.75\n",
            "------------------------------------------------------------------\n",
            "epoch 12:\n",
            "Training loss: 6.99522847753542e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004319007508456707 \n",
            " Val accuracy: 87.8125\n",
            "------------------------------------------------------------------\n",
            "epoch 13:\n",
            "Training loss: 6.5236763475695625e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004150565527379513 \n",
            " Val accuracy: 88.4375\n",
            "------------------------------------------------------------------\n",
            "epoch 14:\n",
            "Training loss: 5.16339960086043e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004181030672043562 \n",
            " Val accuracy: 87.8125\n",
            "------------------------------------------------------------------\n",
            "epoch 15:\n",
            "Training loss: 5.250690946922987e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004246179107576608 \n",
            " Val accuracy: 87.8125\n",
            "------------------------------------------------------------------\n",
            "epoch 16:\n",
            "Training loss: 3.8978333122940965e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004429266881197691 \n",
            " Val accuracy: 87.8125\n",
            "------------------------------------------------------------------\n",
            "epoch 17:\n",
            "Training loss: 3.567491921785404e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.0044566989876329895 \n",
            " Val accuracy: 87.8125\n",
            "------------------------------------------------------------------\n",
            "epoch 18:\n",
            "Training loss: 3.555843227331934e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004479378927499056 \n",
            " Val accuracy: 87.8125\n",
            "------------------------------------------------------------------\n",
            "epoch 19:\n",
            "Training loss: 2.8439088964660185e-06 \n",
            " Training accuracy: 100.0\n",
            "Val loss: 0.004547054041177034 \n",
            " Val accuracy: 87.8125\n",
            "------------------------------------------------------------------\n",
            "Overall accuracy: 86.25\n",
            "Folds statistics:\n",
            "        ---------------- \n",
            "        - mean: 87.3125 \n",
            "        - standard deviation: 1.9425337834900067\n"
          ]
        }
      ],
      "source": [
        "accuracy, mean, std = main_cross_validation(dataset, embedding_matrix, collate, device = \"cuda\", epochs = 20)\n",
        "print(f\"Overall accuracy: {accuracy}\")\n",
        "print(f\"Folds statistics:\\n----------------\\n - mean: {mean} \\n - standard deviation: {std}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pBBa_vvYSnL"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "tensor([1315, 1222, 1011, 1010,  936,  862,  814,  807,  807,  764,  718,  515,\n",
        "         495,  388,  344,  323])\n",
        "tensor([1617, 1361, 1311, 1178, 1081, 1068,  958,  941,  925,  768,  688,  619,\n",
        "         604,  573,  484,  405])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Af9ORg9pFKe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P67fhfYpSZA"
      },
      "source": [
        "# First try to parse phrases documet-wise, then try to parse each phrase of a document separately, and then aggregate the result (if there are more positive phrases then positive, otherwise negative). (Try also to give a weight depending on the number of sentiment lexemes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8-04GhL4p89"
      },
      "source": [
        "### Training procedure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBD3vt1v4r65"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM_dyKuc4sww"
      },
      "source": [
        "### Main function containing also cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mK4Rmfr4ziT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA1Jgp7d_MgC"
      },
      "source": [
        "### (Possible improvement, apply UDA to GLOVE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8toXOrs_T2C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "bMm0vFo00oLS",
        "outputId": "0c6e196d-48e3-4c2b-b5b1-3e1337ae226d"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-253956998aac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandford\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandfordTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtokenization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandfordTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk.tokenize.standford'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize.stanford import StanfordTokenizer\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "class VectorizerPipeline():\n",
        "\n",
        "  def __init__(self, corpus, pipe= {\"tokenizer\": \"stanford\", \"embedding\": \"glove\"}, embedding_size: int = 300):\n",
        "    self.corpus = corpus\n",
        "    if embedding_size:\n",
        "      self.embedding_size = embedding_size\n",
        "    else:\n",
        "      self.embedding_size = 300\n",
        "    \n",
        "    self._allowed = {\n",
        "        \"tokenizer\": [\"stanford\"],\n",
        "        \"embedding\": [\"glove\"],\n",
        "        \"lemmatizer\": [],\n",
        "        \"stop-word-removal\": [],\n",
        "    }\n",
        "    self.pipe = {\n",
        "        \"tokenizer\": None,\n",
        "        \"embedding\": None,\n",
        "        \"lemmatizer\": None,\n",
        "        \"stop-word-removal\": None,\n",
        "    }\n",
        "    if pipe:\n",
        "      for key, value in pipe.items():\n",
        "        try:\n",
        "          if pipe[key] in self._allowed[key]:\n",
        "            self.pipe[key] = value\n",
        "          else:\n",
        "            raise ValueError(f\"Invalid type of {key}. \\n Valid {key}s are {self._allowed[key]}\")\n",
        "        except KeyError:\n",
        "          raise KeyError(f\"Invalid step in the pipeline: {key}. \\n valid steps are {list(self._allowed.keys())}\")\n",
        "\n",
        "\n",
        "  def tokenization(self, batch):\n",
        "    tok = StanfordTokenizer()\n",
        "    X = [tok(x) for x in batch]\n",
        "    return X\n",
        "  \n",
        "  def embedding(self, batch):\n",
        "    max_length = max(batch, key=len)\n",
        "\n",
        "  def vectorize(self, batch):\n",
        "    Y, X = list(zip(*batch))\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "RqmjnrCt_U2K",
        "outputId": "c176b223-e9f6-4af2-9a1c-541577ccb9ad"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4cce880bcee9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMovieReviewsCorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMovieReviewsDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_reviews_dataset_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-c6998c471427>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# list of documents, each document is a list containing words of that document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovie_reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munprocessed_corpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_corpus_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-c6998c471427>\u001b[0m in \u001b[0;36m_flatten\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"pos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-c6998c471427>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"pos\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_to_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/util.py\u001b[0m in \u001b[0;36miterate_from\u001b[0;34m(self, start_tok)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# Get everything we can from this piece.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpiece\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_tok\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# Update the offset table.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/util.py\u001b[0m in \u001b[0;36miterate_from\u001b[0;34m(self, start_tok)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_toknum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoknum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_blocknum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             assert isinstance(tokens, (tuple, list, AbstractLazySequence)), (\n\u001b[1;32m    308\u001b[0m                 \u001b[0;34m\"block reader %s() should return list or tuple.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/reader/plaintext.py\u001b[0m in \u001b[0;36m_read_para_block\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 [\n\u001b[1;32m    136\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sent_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpara\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 ]\n\u001b[1;32m    139\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m         \"\"\"\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1330\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m         \"\"\"\n\u001b[0;32m-> 1332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_match_potential_end_contexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1330\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m         \"\"\"\n\u001b[0;32m-> 1332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_match_potential_end_contexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m             \u001b[0mslices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \"\"\"\n\u001b[1;32m   1420\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msentence1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m             \u001b[0msentence1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msentence2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_match_potential_end_contexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_break\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"next_tok\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mtext_contains_sentbreak\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \"\"\"\n\u001b[1;32m   1441\u001b[0m         \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# used to ignore last token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_annotate_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "corpus = MovieReviewsCorpus()\n",
        "\n",
        "dataset = MovieReviewsDataset(corpus.movie_reviews_dataset_raw())\n",
        "\n",
        "pipeline = VectorizerPipeline(corpus)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size = 64, collate_fn = pipeline.vectorize())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hO3lxc0l3sxI"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from tqdm import tqdm\n",
        "from torchtext.vocab import GloVe\n",
        "import torch\n",
        "\n",
        "corpus = MovieReviewsCorpus()\n",
        "\n",
        "global_vectors = GloVe(name='840B', dim=300)\n",
        "\n",
        "def check_coverage(vocab,embeddings_index):\n",
        "    a = {}\n",
        "    oov = {}\n",
        "    k = 0\n",
        "    i = 0\n",
        "    null_embedding = torch.tensor([0.0]*300)\n",
        "    for word in tqdm(vocab):\n",
        "        try:\n",
        "          if torch.equal(embeddings_index.get_vecs_by_tokens(word), null_embedding):\n",
        "            raise KeyError\n",
        "          a[word] = embeddings_index.get_vecs_by_tokens(word)\n",
        "          k += vocab[word]\n",
        "        except:\n",
        "\n",
        "            oov[word] = vocab[word]\n",
        "            i += vocab[word]\n",
        "            pass\n",
        "\n",
        "    print()\n",
        "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
        "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
        "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
        "\n",
        "    return sorted_x\n",
        "\n",
        "\n",
        "oov = check_coverage(corpus.vocab, global_vectors)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('nlu')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "e0262c2e7a08424d65c968f8ecfc5afb6b5a99089f86fd0fa27478ea619b0ef2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}