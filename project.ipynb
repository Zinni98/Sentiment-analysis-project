{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zinni98/Sentiment-analysis-project/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NBg5KtW5AMy"
      },
      "source": [
        "## Polarity Classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8msH_nw3rf39",
        "outputId": "2b24b3db-27c4-48bc-aa4b-6311468c58b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/gdrive/My Drive/nlu-project\")"
      ],
      "metadata": {
        "id": "vdSs1gS1rgh_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvHgFZJe4_Xq",
        "outputId": "97df4ff8-cf29-4553-8084-a0029c400061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package subjectivity to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "import torch\n",
        "from nltk.corpus import movie_reviews\n",
        "import numpy as np\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"movie_reviews\")\n",
        "nltk.download(\"subjectivity\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"sentiwordnet\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fglEQLVLtc9C"
      },
      "source": [
        "## Exploratory analysis\n",
        "\n",
        "Firstly let's explore the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dKetqTKrZFE",
        "outputId": "941258c3-fb5d-48a9-b796-7e7b2866d87e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of each part of the dataset:\n",
            " - pos: 1000 \n",
            " - neg: 1000\n",
            "[[['films', 'adapted', 'from', 'comic', 'books', 'have', 'had', 'plenty', 'of', 'success', ',', 'whether', 'they', \"'\", 're', 'about', 'superheroes', '(', 'batman', ',', 'superman', ',', 'spawn', ')', ',', 'or', 'geared', 'toward', 'kids', '(', 'casper', ')', 'or', 'the', 'arthouse', 'crowd', '(', 'ghost', 'world', ')', ',', 'but', 'there', \"'\", 's', 'never', 'really', 'been', 'a', 'comic', 'book', 'like', 'from', 'hell', 'before', '.'], ['for', 'starters', ',', 'it', 'was', 'created', 'by', 'alan', 'moore', '(', 'and', 'eddie', 'campbell', ')', ',', 'who', 'brought', 'the', 'medium', 'to', 'a', 'whole', 'new', 'level', 'in', 'the', 'mid', \"'\", '80s', 'with', 'a', '12', '-', 'part', 'series', 'called', 'the', 'watchmen', '.'], ['to', 'say', 'moore', 'and', 'campbell', 'thoroughly', 'researched', 'the', 'subject', 'of', 'jack', 'the', 'ripper', 'would', 'be', 'like', 'saying', 'michael', 'jackson', 'is', 'starting', 'to', 'look', 'a', 'little', 'odd', '.'], ['the', 'book', '(', 'or', '\"', 'graphic', 'novel', ',', '\"', 'if', 'you', 'will', ')', 'is', 'over', '500', 'pages', 'long', 'and', 'includes', 'nearly', '30', 'more', 'that', 'consist', 'of', 'nothing', 'but', 'footnotes', '.'], ['in', 'other', 'words', ',', 'don', \"'\", 't', 'dismiss', 'this', 'film', 'because', 'of', 'its', 'source', '.'], ['if', 'you', 'can', 'get', 'past', 'the', 'whole', 'comic', 'book', 'thing', ',', 'you', 'might', 'find', 'another', 'stumbling', 'block', 'in', 'from', 'hell', \"'\", 's', 'directors', ',', 'albert', 'and', 'allen', 'hughes', '.'], ['getting', 'the', 'hughes', 'brothers', 'to', 'direct', 'this', 'seems', 'almost', 'as', 'ludicrous', 'as', 'casting', 'carrot', 'top', 'in', ',', 'well', ',', 'anything', ',', 'but', 'riddle', 'me', 'this', ':', 'who', 'better', 'to', 'direct', 'a', 'film', 'that', \"'\", 's', 'set', 'in', 'the', 'ghetto', 'and', 'features', 'really', 'violent', 'street', 'crime', 'than', 'the', 'mad', 'geniuses', 'behind', 'menace', 'ii', 'society', '?'], ['the', 'ghetto', 'in', 'question', 'is', ',', 'of', 'course', ',', 'whitechapel', 'in', '1888', 'london', \"'\", 's', 'east', 'end', '.'], ['it', \"'\", 's', 'a', 'filthy', ',', 'sooty', 'place', 'where', 'the', 'whores', '(', 'called', '\"', 'unfortunates', '\"', ')', 'are', 'starting', 'to', 'get', 'a', 'little', 'nervous', 'about', 'this', 'mysterious', 'psychopath', 'who', 'has', 'been', 'carving', 'through', 'their', 'profession', 'with', 'surgical', 'precision', '.'], ['when', 'the', 'first', 'stiff', 'turns', 'up', ',', 'copper', 'peter', 'godley', '(', 'robbie', 'coltrane', ',', 'the', 'world', 'is', 'not', 'enough', ')', 'calls', 'in', 'inspector', 'frederick', 'abberline', '(', 'johnny', 'depp', ',', 'blow', ')', 'to', 'crack', 'the', 'case', '.'], ['abberline', ',', 'a', 'widower', ',', 'has', 'prophetic', 'dreams', 'he', 'unsuccessfully', 'tries', 'to', 'quell', 'with', 'copious', 'amounts', 'of', 'absinthe', 'and', 'opium', '.'], ['upon', 'arriving', 'in', 'whitechapel', ',', 'he', 'befriends', 'an', 'unfortunate', 'named', 'mary', 'kelly', '(', 'heather', 'graham', ',', 'say', 'it', 'isn', \"'\", 't', 'so', ')', 'and', 'proceeds', 'to', 'investigate', 'the', 'horribly', 'gruesome', 'crimes', 'that', 'even', 'the', 'police', 'surgeon', 'can', \"'\", 't', 'stomach', '.'], ['i', 'don', \"'\", 't', 'think', 'anyone', 'needs', 'to', 'be', 'briefed', 'on', 'jack', 'the', 'ripper', ',', 'so', 'i', 'won', \"'\", 't', 'go', 'into', 'the', 'particulars', 'here', ',', 'other', 'than', 'to', 'say', 'moore', 'and', 'campbell', 'have', 'a', 'unique', 'and', 'interesting', 'theory', 'about', 'both', 'the', 'identity', 'of', 'the', 'killer', 'and', 'the', 'reasons', 'he', 'chooses', 'to', 'slay', '.'], ['in', 'the', 'comic', ',', 'they', 'don', \"'\", 't', 'bother', 'cloaking', 'the', 'identity', 'of', 'the', 'ripper', ',', 'but', 'screenwriters', 'terry', 'hayes', '(', 'vertical', 'limit', ')', 'and', 'rafael', 'yglesias', '(', 'les', 'mis', '?'], ['rables', ')', 'do', 'a', 'good', 'job', 'of', 'keeping', 'him', 'hidden', 'from', 'viewers', 'until', 'the', 'very', 'end', '.'], ['it', \"'\", 's', 'funny', 'to', 'watch', 'the', 'locals', 'blindly', 'point', 'the', 'finger', 'of', 'blame', 'at', 'jews', 'and', 'indians', 'because', ',', 'after', 'all', ',', 'an', 'englishman', 'could', 'never', 'be', 'capable', 'of', 'committing', 'such', 'ghastly', 'acts', '.'], ['and', 'from', 'hell', \"'\", 's', 'ending', 'had', 'me', 'whistling', 'the', 'stonecutters', 'song', 'from', 'the', 'simpsons', 'for', 'days', '(', '\"', 'who', 'holds', 'back', 'the', 'electric', 'car', '/', 'who', 'made', 'steve', 'guttenberg', 'a', 'star', '?', '\"'], [')', '.'], ['don', \"'\", 't', 'worry', '-', 'it', \"'\", 'll', 'all', 'make', 'sense', 'when', 'you', 'see', 'it', '.'], ['now', 'onto', 'from', 'hell', \"'\", 's', 'appearance', ':', 'it', \"'\", 's', 'certainly', 'dark', 'and', 'bleak', 'enough', ',', 'and', 'it', \"'\", 's', 'surprising', 'to', 'see', 'how', 'much', 'more', 'it', 'looks', 'like', 'a', 'tim', 'burton', 'film', 'than', 'planet', 'of', 'the', 'apes', 'did', '(', 'at', 'times', ',', 'it', 'seems', 'like', 'sleepy', 'hollow', '2', ')', '.'], ['the', 'print', 'i', 'saw', 'wasn', \"'\", 't', 'completely', 'finished', '(', 'both', 'color', 'and', 'music', 'had', 'not', 'been', 'finalized', ',', 'so', 'no', 'comments', 'about', 'marilyn', 'manson', ')', ',', 'but', 'cinematographer', 'peter', 'deming', '(', 'don', \"'\", 't', 'say', 'a', 'word', ')', 'ably', 'captures', 'the', 'dreariness', 'of', 'victorian', '-', 'era', 'london', 'and', 'helped', 'make', 'the', 'flashy', 'killing', 'scenes', 'remind', 'me', 'of', 'the', 'crazy', 'flashbacks', 'in', 'twin', 'peaks', ',', 'even', 'though', 'the', 'violence', 'in', 'the', 'film', 'pales', 'in', 'comparison', 'to', 'that', 'in', 'the', 'black', '-', 'and', '-', 'white', 'comic', '.'], ['oscar', 'winner', 'martin', 'childs', \"'\", '(', 'shakespeare', 'in', 'love', ')', 'production', 'design', 'turns', 'the', 'original', 'prague', 'surroundings', 'into', 'one', 'creepy', 'place', '.'], ['even', 'the', 'acting', 'in', 'from', 'hell', 'is', 'solid', ',', 'with', 'the', 'dreamy', 'depp', 'turning', 'in', 'a', 'typically', 'strong', 'performance', 'and', 'deftly', 'handling', 'a', 'british', 'accent', '.'], ['ians', 'holm', '(', 'joe', 'gould', \"'\", 's', 'secret', ')', 'and', 'richardson', '(', '102', 'dalmatians', ')', 'log', 'in', 'great', 'supporting', 'roles', ',', 'but', 'the', 'big', 'surprise', 'here', 'is', 'graham', '.'], ['i', 'cringed', 'the', 'first', 'time', 'she', 'opened', 'her', 'mouth', ',', 'imagining', 'her', 'attempt', 'at', 'an', 'irish', 'accent', ',', 'but', 'it', 'actually', 'wasn', \"'\", 't', 'half', 'bad', '.'], ['the', 'film', ',', 'however', ',', 'is', 'all', 'good', '.'], ['2', ':', '00', '-', 'r', 'for', 'strong', 'violence', '/', 'gore', ',', 'sexuality', ',', 'language', 'and', 'drug', 'content']], [['every', 'now', 'and', 'then', 'a', 'movie', 'comes', 'along', 'from', 'a', 'suspect', 'studio', ',', 'with', 'every', 'indication', 'that', 'it', 'will', 'be', 'a', 'stinker', ',', 'and', 'to', 'everybody', \"'\", 's', 'surprise', '(', 'perhaps', 'even', 'the', 'studio', ')', 'the', 'film', 'becomes', 'a', 'critical', 'darling', '.'], ['mtv', 'films', \"'\", '_election', ',', 'a', 'high', 'school', 'comedy', 'starring', 'matthew', 'broderick', 'and', 'reese', 'witherspoon', ',', 'is', 'a', 'current', 'example', '.'], ['did', 'anybody', 'know', 'this', 'film', 'existed', 'a', 'week', 'before', 'it', 'opened', '?'], ['the', 'plot', 'is', 'deceptively', 'simple', '.'], ['george', 'washington', 'carver', 'high', 'school', 'is', 'having', 'student', 'elections', '.'], ['tracy', 'flick', '(', 'reese', 'witherspoon', ')', 'is', 'an', 'over', '-', 'achiever', 'with', 'her', 'hand', 'raised', 'at', 'nearly', 'every', 'question', ',', 'way', ',', 'way', ',', 'high', '.'], ['mr', '.', '\"', 'm', '\"', '(', 'matthew', 'broderick', ')', ',', 'sick', 'of', 'the', 'megalomaniac', 'student', ',', 'encourages', 'paul', ',', 'a', 'popular', '-', 'but', '-', 'slow', 'jock', 'to', 'run', '.'], ['and', 'paul', \"'\", 's', 'nihilistic', 'sister', 'jumps', 'in', 'the', 'race', 'as', 'well', ',', 'for', 'personal', 'reasons', '.'], ['the', 'dark', 'side', 'of', 'such', 'sleeper', 'success', 'is', 'that', ',', 'because', 'expectations', 'were', 'so', 'low', 'going', 'in', ',', 'the', 'fact', 'that', 'this', 'was', 'quality', 'stuff', 'made', 'the', 'reviews', 'even', 'more', 'enthusiastic', 'than', 'they', 'have', 'any', 'right', 'to', 'be', '.'], ['you', 'can', \"'\", 't', 'help', 'going', 'in', 'with', 'the', 'baggage', 'of', 'glowing', 'reviews', ',', 'which', 'is', 'in', 'contrast', 'to', 'the', 'negative', 'baggage', 'that', 'the', 'reviewers', 'were', 'likely', 'to', 'have', '.'], ['_election', ',', 'a', 'good', 'film', ',', 'does', 'not', 'live', 'up', 'to', 'its', 'hype', '.'], ['what', 'makes', '_election_', 'so', 'disappointing', 'is', 'that', 'it', 'contains', 'significant', 'plot', 'details', 'lifted', 'directly', 'from', '_rushmore_', ',', 'released', 'a', 'few', 'months', 'earlier', '.'], ['the', 'similarities', 'are', 'staggering', ':', 'tracy', 'flick', '(', '_election_', ')', 'is', 'the', 'president', 'of', 'an', 'extraordinary', 'number', 'of', 'clubs', ',', 'and', 'is', 'involved', 'with', 'the', 'school', 'play', '.'], ['max', 'fischer', '(', '_rushmore_', ')', 'is', 'the', 'president', 'of', 'an', 'extraordinary', 'number', 'of', 'clubs', ',', 'and', 'is', 'involved', 'with', 'the', 'school', 'play', '.'], ['the', 'most', 'significant', 'tension', 'of', '_election_', 'is', 'the', 'potential', 'relationship', 'between', 'a', 'teacher', 'and', 'his', 'student', '.'], ['the', 'most', 'significant', 'tension', 'of', '_rushmore_', 'is', 'the', 'potential', 'relationship', 'between', 'a', 'teacher', 'and', 'his', 'student', '.'], ['tracy', 'flick', 'is', 'from', 'a', 'single', 'parent', 'home', ',', 'which', 'has', 'contributed', 'to', 'her', 'drive', '.'], ['max', 'fischer', 'is', 'from', 'a', 'single', 'parent', 'home', ',', 'which', 'has', 'contributed', 'to', 'his', 'drive', '.'], ['the', 'male', 'bumbling', 'adult', 'in', '_election_', '(', 'matthew', 'broderick', ')', 'pursues', 'an', 'extramarital', 'affair', ',', 'gets', 'caught', ',', 'and', 'his', 'whole', 'life', 'is', 'ruined', '.'], ['he', 'even', 'gets', 'a', 'bee', 'sting', '.'], ['the', 'male', 'bumbling', 'adult', 'in', '_rushmore_', '(', 'bill', 'murray', ')', 'pursues', 'an', 'extramarital', 'affair', ',', 'gets', 'caught', ',', 'and', 'his', 'whole', 'life', 'is', 'ruined', '.'], ['he', 'gets', 'several', 'bee', 'stings', '.'], ['and', 'so', 'on', '.'], ['what', 'happened', '?'], ['how', 'is', 'it', 'that', 'an', 'individual', 'screenplay', '(', '_rushmore_', ')', 'and', 'a', 'novel', '(', '_election_', ')', 'contain', 'so', 'many', 'significant', 'plot', 'points', ',', 'and', 'yet', 'both', 'films', 'were', 'probably', 'not', 'even', 'aware', 'of', 'each', 'other', ',', 'made', 'from', 'two', 'different', 'studios', ',', 'from', 'a', 'genre', '(', 'the', 'high', 'school', 'geeks', 'revenge', 'movie', ')', 'that', 'hadn', \"'\", 't', 'been', 'fully', 'formed', 'yet', '?'], ['even', 'so', ',', 'the', 'strengths', 'of', '_election_', 'rely', 'upon', 'its', 'fantastic', 'performances', 'from', 'broderick', ',', 'witherspoon', ',', 'and', 'newcomer', 'jessica', 'campbell', ',', 'as', 'paul', \"'\", 's', 'anti', '-', 'social', 'sister', ',', 'tammy', '.'], ['broderick', 'here', 'is', 'playing', 'the', 'mr', '.', 'rooney', 'role', 'from', '_ferris', 'bueller_', ',', 'and', 'he', 'seems', 'to', 'be', 'having', 'the', 'most', 'fun', 'he', \"'\", 's', 'had', 'since', 'then', '.'], ['witherspoon', 'is', 'a', 'revelation', '.'], ['it', \"'\", 's', 'early', 'in', 'the', 'year', ',', 'it', \"'\", 's', 'a', 'comedy', ',', 'and', 'teenagers', 'have', 'little', 'clout', ',', 'but', 'for', 'my', 'money', ',', 'witherspoon', 'deserves', 'an', 'oscar', 'nomination', '.'], ['and', 'once', 'campbell', \"'\", 's', 'character', 'gets', 'going', ',', 'like', 'in', 'her', 'fantastic', 'speech', 'in', 'the', 'gymnasium', ',', 'then', 'you', \"'\", 're', 'won', 'over', '.'], ['one', 'thing', 'that', \"'\", 's', 'been', 'bothering', 'me', 'since', 'i', \"'\", 've', 'seen', 'it', '.'], ['there', 'is', 'an', 'extraordinary', 'amount', 'of', 'sexuality', 'in', 'this', 'film', '.'], ['i', 'suppose', 'that', ',', 'coming', 'from', 'mtv', 'films', ',', 'i', 'should', 'expect', 'no', 'less', '.'], ['.', '.', 'but', 'the', 'film', 'starts', 'off', 'light', 'and', 'airy', ',', 'like', 'a', 'sitcom', '.'], ['as', 'the', 'screws', 'tighten', ',', 'and', 'the', 'tensions', 'mount', ',', 'alexander', 'payne', 'decides', 'to', 'add', 'elements', 'that', ',', 'frankly', ',', 'distract', 'from', 'the', 'story', '.'], ['it', 'is', 'bad', 'enough', 'that', 'mr', '.', 'm', 'doesn', \"'\", 't', 'like', 'tracy', \"'\", 's', 'determination', 'to', 'win', 'at', 'all', 'costs', ',', 'but', 'did', 'they', 'have', 'to', 'throw', 'in', 'the', 'student', '/', 'teacher', 'relationship', '?'], ['even', 'so', ',', 'there', \"'\", 's', 'no', 'logical', 'reason', 'why', 'mr', '.', 'm', 'has', 'an', 'affair', 'when', 'he', 'does', '.'], ['there', \"'\", 's', 'a', 'lot', 'to', 'like', 'in', '_election_', ',', 'but', 'the', 'plot', 'similarities', 'to', '_rushmore_', ',', 'and', 'the', 'tonal', 'nosedive', 'it', 'takes', 'as', 'it', 'gets', 'explicitly', 'sex', '-', 'driven', ',', 'mark', 'this', 'as', 'a', 'disappointment', '.']], ...]\n"
          ]
        }
      ],
      "source": [
        "mr = movie_reviews\n",
        "neg = mr.paras(categories = \"neg\")\n",
        "pos = mr.paras(categories = \"pos\")\n",
        "print(f\"length of each part of the dataset:\\n - pos: {len(pos)} \\n - neg: {len(neg)}\")\n",
        "print(pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-Y4wuDNt7XW"
      },
      "source": [
        "It's easy to see that data comes in the following format:\n",
        "\n",
        "- pos = [doc1, doc2, ..., doc1000] (the same applies for negative sentiment examples)\n",
        "\n",
        "Where each doc has the following structure:\n",
        "\n",
        "- doc1 = [sentence_1, sentence_2, ..., sentence_k]\n",
        "\n",
        "Each sentence is a list of tokens, so the dataset is already tokenized.\n",
        "\n",
        "### Word embedding\n",
        "Since I'm going to use deep learning models, I'm going to choose a word embedding to transform the text into vectors.\n",
        "I'm going to start with a pretrained version of GloVe word embedding.\n",
        "Since is a pre-trained word embedding (hence basically a lookup table), I'm going to check how many words of the vocabulary are covered by the pretrained word embedding model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_SEn4EFxKTd"
      },
      "outputs": [],
      "source": [
        "def create_vocab(corpus_words):\n",
        "    vocab = dict()\n",
        "    for word in corpus_words:\n",
        "      try:\n",
        "        vocab[word] += 1\n",
        "      except:\n",
        "        vocab[word] = 1\n",
        "    return vocab\n",
        "\n",
        "def get_corpus_words(corpus) -> list:\n",
        "    return [w for doc in corpus for sent in doc for w in sent]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "xdofBhKWxQHx",
        "outputId": "bf77c0f1-3122-44a1-841d-5e3ec9a1fdd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.840B.300d.zip:   2%|▏         | 43.0M/2.18G [00:03<03:12, 11.1MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-161cdd5781f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mglobal_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGloVe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'840B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# function inspired by https://www.kaggle.com/code/christofhenkel/how-to-preprocessing-when-using-embeddings/notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/vocab/vectors.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, dim, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"glove.{}.{}d.txt\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGloVe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/vocab/vectors.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/vocab/vectors.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m     96\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# remove the partial zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting vectors into {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchtext/vocab/vectors.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m     93\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                             \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporthook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# remove the partial zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    463\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import operator\n",
        "from tqdm import tqdm\n",
        "from torchtext.vocab import GloVe\n",
        "import torch\n",
        "\n",
        "global_vectors = GloVe(name='840B', dim=300)\n",
        "\n",
        "# function inspired by https://www.kaggle.com/code/christofhenkel/how-to-preprocessing-when-using-embeddings/notebook\n",
        "def check_coverage(vocab,embeddings_index):\n",
        "    a = {}\n",
        "    oov = {}\n",
        "    k = 0\n",
        "    i = 0\n",
        "    null_embedding = torch.tensor([0.0]*300)\n",
        "    for word in tqdm(vocab):\n",
        "        try:\n",
        "          if torch.equal(embeddings_index.get_vecs_by_tokens(word), null_embedding):\n",
        "            raise KeyError\n",
        "          a[word] = embeddings_index.get_vecs_by_tokens(word)\n",
        "          k += vocab[word]\n",
        "        except:\n",
        "\n",
        "            oov[word] = vocab[word]\n",
        "            i += vocab[word]\n",
        "            pass\n",
        "\n",
        "    print()\n",
        "    print(f'Found embeddings for {len(a) / len(vocab):.2%} of vocab')\n",
        "    print(f'Found embeddings for  {k / (k + i):.2%} of all text')\n",
        "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
        "\n",
        "    return sorted_x\n",
        "\n",
        "vocab = create_vocab(get_corpus_words(pos + neg))\n",
        "oov = check_coverage(vocab, global_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K0HUOB2-E1V"
      },
      "outputs": [],
      "source": [
        "oov"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEjIRmuG-Quz"
      },
      "source": [
        "I'm going to see which are the words that are not covered by the embedding (Out Of Vocabulary words), so I can try to see if there are some tenchniques that can be applied in order to improve coverage.\n",
        "The majority of OOV words aren't related with a praticular sentiment (they are basically nouns or some type punctuation), so they can be safely removed. That happens because unknown words are encoded as $[0] * embedding.length$, so no useful information is added.\n",
        "Others OOV words are regular words surrounded by underscores, so they are not recognized by the fixed word embedding. To avoid this problem I implemented a procedure in order to clean these words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgvlBpnMB8EO"
      },
      "outputs": [],
      "source": [
        "def remove_underscores(corpus):\n",
        "  for doc in corpus:\n",
        "    for sent in doc:\n",
        "      for idx, word in enumerate(sent):\n",
        "        if \"_\" in word:\n",
        "          cleaned_word = _clean_word(word)\n",
        "          sent[idx] = cleaned_word\n",
        "  return corpus\n",
        "\n",
        "\n",
        "def _clean_word(word: str):\n",
        "  word = word.replace(\"_\", \" \")\n",
        "  word = word.split()\n",
        "  word = \" \".join(word)\n",
        "  return word\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUphYnDOa785",
        "outputId": "e0b314d1-9afc-4056-bcd1-d731c2fb907a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 39519/39519 [00:01<00:00, 28083.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Found embeddings for 92.48% of vocab\n",
            "Found embeddings for  99.61% of all text\n"
          ]
        }
      ],
      "source": [
        "corpus = pos + neg\n",
        "clean_corpus = remove_underscores(corpus), oov\n",
        "vocab = create_vocab(get_corpus_words(clean_corpus))\n",
        "oov = check_coverage(vocab, global_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cmath import phase\n",
        "from dis import findlabels\n",
        "from unicodedata import name\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "\n",
        "CONTRACTION_MAP =  {\"ain't\": \"is not\",\n",
        "                        \"aren't\": \"are not\",\n",
        "                        \"can't\": \"cannot\",\n",
        "                        \"can't've\": \"cannot have\",\n",
        "                        \"'cause\": \"because\",\n",
        "                        \"could've\": \"could have\",\n",
        "                        \"couldn't\": \"could not\",\n",
        "                        \"couldn't've\": \"could not have\",\n",
        "                        \"didn't\": \"did not\",\n",
        "                        \"doesn't\": \"does not\",\n",
        "                        \"don't\": \"do not\",\n",
        "                        \"hadn't\": \"had not\",\n",
        "                        \"hadn't've\": \"had not have\",\n",
        "                        \"hasn't\": \"has not\",\n",
        "                        \"haven't\": \"have not\",\n",
        "                        \"he'd\": \"he would\",\n",
        "                        \"he'd've\": \"he would have\",\n",
        "                        \"he'll\": \"he will\",\n",
        "                        \"he'll've\": \"he he will have\",\n",
        "                        \"he's\": \"he is\",\n",
        "                        \"how'd\": \"how did\",\n",
        "                        \"how'd'y\": \"how do you\",\n",
        "                        \"how'll\": \"how will\",\n",
        "                        \"how's\": \"how is\",\n",
        "                        \"i'd\": \"i would\",\n",
        "                        \"i'd've\": \"i would have\",\n",
        "                        \"i'll\": \"i will\",\n",
        "                        \"i'll've\": \"i will have\",\n",
        "                        \"i'm\": \"i am\",\n",
        "                        \"i've\": \"i have\",\n",
        "                        \"isn't\": \"is not\",\n",
        "                        \"it'd\": \"it would\",\n",
        "                        \"it'd've\": \"it would have\",\n",
        "                        \"it'll\": \"it will\",\n",
        "                        \"it'll've\": \"it will have\",\n",
        "                        \"it's\": \"it is\",\n",
        "                        \"let's\": \"let us\",\n",
        "                        \"ma'am\": \"madam\",\n",
        "                        \"mayn't\": \"may not\",\n",
        "                        \"might've\": \"might have\",\n",
        "                        \"mightn't\": \"might not\",\n",
        "                        \"mightn't've\": \"might not have\",\n",
        "                        \"must've\": \"must have\",\n",
        "                        \"mustn't\": \"must not\",\n",
        "                        \"mustn't've\": \"must not have\",\n",
        "                        \"needn't\": \"need not\",\n",
        "                        \"needn't've\": \"need not have\",\n",
        "                        \"o'clock\": \"of the clock\",\n",
        "                        \"oughtn't\": \"ought not\",\n",
        "                        \"oughtn't've\": \"ought not have\",\n",
        "                        \"shan't\": \"shall not\",\n",
        "                        \"sha'n't\": \"shall not\",\n",
        "                        \"shan't've\": \"shall not have\",\n",
        "                        \"she'd\": \"she would\",\n",
        "                        \"she'd've\": \"she would have\",\n",
        "                        \"she'll\": \"she will\",\n",
        "                        \"she'll've\": \"she will have\",\n",
        "                        \"she's\": \"she is\",\n",
        "                        \"should've\": \"should have\",\n",
        "                        \"shouldn't\": \"should not\",\n",
        "                        \"shouldn't've\": \"should not have\",\n",
        "                        \"so've\": \"so have\",\n",
        "                        \"so's\": \"so as\",\n",
        "                        \"that'd\": \"that would\",\n",
        "                        \"that'd've\": \"that would have\",\n",
        "                        \"that's\": \"that is\",\n",
        "                        \"there'd\": \"there would\",\n",
        "                        \"there'd've\": \"there would have\",\n",
        "                        \"there's\": \"there is\",\n",
        "                        \"they'd\": \"they would\",\n",
        "                        \"they'd've\": \"they would have\",\n",
        "                        \"they'll\": \"they will\",\n",
        "                        \"they'll've\": \"they will have\",\n",
        "                        \"they're\": \"they are\",\n",
        "                        \"they've\": \"they have\",\n",
        "                        \"to've\": \"to have\",\n",
        "                        \"wasn't\": \"was not\",\n",
        "                        \"we'd\": \"we would\",\n",
        "                        \"we'd've\": \"we would have\",\n",
        "                        \"we'll\": \"we will\",\n",
        "                        \"we'll've\": \"we will have\",\n",
        "                        \"we're\": \"we are\",\n",
        "                        \"we've\": \"we have\",\n",
        "                        \"weren't\": \"were not\",\n",
        "                        \"what'll\": \"what will\",\n",
        "                        \"what'll've\": \"what will have\",\n",
        "                        \"what're\": \"what are\",\n",
        "                        \"what's\": \"what is\",\n",
        "                        \"what've\": \"what have\",\n",
        "                        \"when's\": \"when is\",\n",
        "                        \"when've\": \"when have\",\n",
        "                        \"where'd\": \"where did\",\n",
        "                        \"where's\": \"where is\",\n",
        "                        \"where've\": \"where have\",\n",
        "                        \"who'll\": \"who will\",\n",
        "                        \"who'll've\": \"who will have\",\n",
        "                        \"who's\": \"who is\",\n",
        "                        \"who've\": \"who have\",\n",
        "                        \"why's\": \"why is\",\n",
        "                        \"why've\": \"why have\",\n",
        "                        \"will've\": \"will have\",\n",
        "                        \"won't\": \"will not\",\n",
        "                        \"won't've\": \"will not have\",\n",
        "                        \"would've\": \"would have\",\n",
        "                        \"wouldn't\": \"would not\",\n",
        "                        \"wouldn't've\": \"would not have\",\n",
        "                        \"y'all\": \"you all\",\n",
        "                        \"y'all'd\": \"you all would\",\n",
        "                        \"y'all'd've\": \"you all would have\",\n",
        "                        \"y'all're\": \"you all are\",\n",
        "                        \"y'all've\": \"you all have\",\n",
        "                        \"you'd\": \"you would\",\n",
        "                        \"you'd've\": \"you would have\",\n",
        "                        \"you'll\": \"you will\",\n",
        "                        \"you'll've\": \"you will have\",\n",
        "                        \"you're\": \"you are\",\n",
        "                        \"you've\": \"you have\",\n",
        "                    }\n",
        "\n",
        "class MRAbstractPipeline():\n",
        "    def __init__(self):\n",
        "        self.pipeline = []\n",
        "    \n",
        "    def pipe(self, corpus):\n",
        "        for el in self.pipeline:\n",
        "            corpus = el(corpus)\n",
        "        return corpus\n",
        "    \n",
        "    def __call__(self, *args, **kwds):\n",
        "        if args[0] == None:\n",
        "            raise ValueError(\"Need a corpus as argument\")\n",
        "        corpus = args[0]\n",
        "        return self.pipe(corpus)\n",
        "        \n",
        "\n",
        "class MRPipelineTokens(MRAbstractPipeline):\n",
        "    \"\"\"\n",
        "    Pipeline for documents represented as list of tokens\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(MRPipelineTokens, self).__init__()\n",
        "        self.pipeline = [self.remove_underscores, \n",
        "                         self.reducing_character_repetitions,\n",
        "                         #self.merge_apostrophes,\n",
        "                         self.clean_contractions,\n",
        "                         self.clean_special_chars,\n",
        "                         self.remove_stop_words]\n",
        "\n",
        "    def remove_underscores(self, corpus):\n",
        "        \"\"\"\n",
        "        Solves the problem where some of the words are surrounded by underscores\n",
        "        (e.g. \"_hello_\")\n",
        "        \"\"\"\n",
        "        for doc in corpus:\n",
        "            for idx, word in enumerate(doc):\n",
        "                if \"_\" in word:\n",
        "                    cleaned_word = self._clean_word(word)\n",
        "                    doc[idx] = cleaned_word\n",
        "        return corpus\n",
        "\n",
        "\n",
        "    def _clean_word(self, word: str):\n",
        "        word = word.replace(\"_\", \" \")\n",
        "        # remove spaces before and after the word\n",
        "        word = word.split()\n",
        "        word = \" \".join(word)\n",
        "        return word\n",
        "    \n",
        "    def reducing_character_repetitions(self, corpus):\n",
        "        \n",
        "        new_corpus = []\n",
        "        for doc in corpus:\n",
        "            new_doc = [self._clean_repetitions(w) for w in doc]\n",
        "            new_corpus.append(new_doc)\n",
        "        return new_corpus\n",
        "\n",
        "    # inspired by https://towardsdatascience.com/cleaning-preprocessing-text-data-by-building-nlp-pipeline-853148add68a\n",
        "    def _clean_repetitions(self, word):\n",
        "        \"\"\"\n",
        "        This Function will reduce repetition to two characters \n",
        "        for alphabets and to one character for punctuations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "            word: str                \n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            Finally formatted text with alphabets repeating to \n",
        "            one characters & punctuations limited to one repetition \n",
        "            \n",
        "        Example:\n",
        "        Input : Realllllllllyyyyy,        Greeeeaaaatttt   !!!!?....;;;;:)\n",
        "        Output : Really, Great !?.;:)\n",
        "\n",
        "        \"\"\"\n",
        "        # Pattern matching for all case alphabets\n",
        "        pattern_alpha = re.compile(r\"([A-Za-z])\\1{1,}\", re.DOTALL)\n",
        "\n",
        "        # Limiting all the repetitions to two characters.\n",
        "        # MODIFIED: keep only one repetition of the character\n",
        "        formatted_text = pattern_alpha.sub(r\"\\1\\1\", word) \n",
        "\n",
        "        # Pattern matching for all the punctuations that can occur\n",
        "        pattern_punct = re.compile(r'([.,/#!$%^&*?;:{}=_`~()+-])\\1{1,}')\n",
        "\n",
        "        # Limiting punctuations in previously formatted string to only one.\n",
        "        combined_formatted = pattern_punct.sub(r'\\1', formatted_text)\n",
        "\n",
        "        # The below statement is replacing repetitions of spaces that occur more than two times with that of one occurrence.\n",
        "        final_formatted = re.sub(' {2,}',' ', combined_formatted)\n",
        "        return final_formatted\n",
        "    \n",
        "    def merge_apostrophes(self, corpus):\n",
        "      new_corpus = []\n",
        "      for doc in corpus:\n",
        "        indexes = self._get_neg_indexes(doc)\n",
        "        for el in indexes:\n",
        "          doc[el[0]:el[1]] = [\"\".join(doc[el[0]:el[1]])]\n",
        "        new_corpus.append(doc)\n",
        "      return new_corpus\n",
        "\n",
        "    def _get_neg_indexes(self, sent):\n",
        "      contr = [\"t\", \"ve\", \"re\", \"ll\", \"d\", \"all\", \"y\", \"cause\", \"m\", \"clock\", \"am\", \"s\"]\n",
        "      indexes = []\n",
        "      for idx, word in enumerate(sent):\n",
        "        # Try-except to avoid out of range indexes (there can be some \"'\" a the beginning or end of the phrase)\n",
        "        try:\n",
        "          if word==\"'\" and sent[idx+1] in contr:\n",
        "            indexes.append((idx-1,idx+2))\n",
        "        except:\n",
        "          pass\n",
        "      return indexes\n",
        "    \n",
        "    def clean_contractions(self, corpus):\n",
        "        new_corpus = []\n",
        "        for doc in corpus:\n",
        "            new_doc = []\n",
        "            for word in doc:\n",
        "                try:\n",
        "                    correct = CONTRACTION_MAP[word]\n",
        "                    correct = correct.split()\n",
        "                    new_doc += correct\n",
        "                except:\n",
        "                    new_doc.append(word)\n",
        "            new_corpus.append(new_doc)\n",
        "        return new_corpus\n",
        "\n",
        "    def clean_special_chars(self, corpus):\n",
        "        new_corpus = [[self._clean_special_word(w) for w in doc] for doc in corpus]\n",
        "        new_corpus = [[w for w in doc] for doc in corpus]\n",
        "        return new_corpus\n",
        "    \n",
        "    def _clean_special_word(self, word):\n",
        "        # The formatted text after removing not necessary punctuations.\n",
        "        formatted_text = re.sub(r\"[^a-zA-Z0-9:€$-,%.?!]+\", '', word) \n",
        "        # In the above regex expression,I am providing necessary set of punctuations that are frequent in this particular dataset.\n",
        "        return formatted_text\n",
        "    \n",
        "    def remove_stop_words(self, corpus):\n",
        "        stops = stopwords.words(\"english\")\n",
        "        stops = [word for word in stops if \"'t\" not in word or \"not\" not in word]\n",
        "        return [[word for word in doc if word not in stops] for doc in corpus]\n",
        "    \n",
        "\n",
        "class MRPipelinePhrases(MRAbstractPipeline):\n",
        "    \"\"\"\n",
        "    Pipeline for documents represented as list of phrases\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(MRPipelinePhrases, self).__init__()\n",
        "        self.pipeline = [self.remove_underscores, \n",
        "                         self.clean_special_chars,\n",
        "                         self.reducing_character_repetitions,\n",
        "                         self.lemmatize]\n",
        "\n",
        "    def remove_underscores(self, corpus):\n",
        "        \"\"\"\n",
        "        Solves the problem where some of the words are surrounded by underscores\n",
        "        (e.g. \"_hello_\")\n",
        "        \"\"\"\n",
        "        new_corpus = [self._clean_word(doc) for doc in corpus]\n",
        "        return new_corpus\n",
        "\n",
        "\n",
        "    def _clean_word(self, doc: str):\n",
        "        doc = doc.replace(\"_\", \" \")\n",
        "        return doc\n",
        "    \n",
        "    def reducing_character_repetitions(self, corpus):\n",
        "        new_corpus = [self._clean_repetitions(doc) for doc in corpus]\n",
        "        return new_corpus\n",
        "    \n",
        "    # inspired by https://towardsdatascience.com/cleaning-preprocessing-text-data-by-building-nlp-pipeline-853148add68a\n",
        "    def _clean_repetitions(self, word):\n",
        "        \"\"\"\n",
        "        This Function will reduce repetition to two characters \n",
        "        for alphabets and to one character for punctuations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "            word: str                \n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            Finally formatted text with alphabets repeating to \n",
        "            one characters & punctuations limited to one repetition \n",
        "            \n",
        "        Example:\n",
        "        Input : Realllllllllyyyyy,        Greeeeaaaatttt   !!!!?....;;;;:)\n",
        "        Output : Realy, Great !?.;:)\n",
        "\n",
        "        \"\"\"\n",
        "        # Pattern matching for all case alphabets\n",
        "        pattern_alpha = re.compile(r\"([A-Za-z])\\1{1,}\", re.DOTALL)\n",
        "\n",
        "        # Limiting all the repetitions to two characters.\n",
        "        # MODIFIED: keep only one repetition of the character\n",
        "        formatted_text = pattern_alpha.sub(r\"\\1\\1\", word) \n",
        "\n",
        "        # Pattern matching for all the punctuations that can occur\n",
        "        pattern_punct = re.compile(r'([., /#!$%^&*?;:{}=_`~()+-])\\1{1,}')\n",
        "\n",
        "        # Limiting punctuations in previously formatted string to only one.\n",
        "        combined_formatted = pattern_punct.sub(r'\\1', formatted_text)\n",
        "\n",
        "        # The below statement is replacing repetitions of spaces that occur more than two times with that of one occurrence.\n",
        "        final_formatted = re.sub(' {2,}',' ', combined_formatted)\n",
        "        return final_formatted\n",
        "\n",
        "    def clean_special_chars(self, corpus):\n",
        "        new_corpus = [self._clean_special_word(doc)  for doc in corpus]\n",
        "        return new_corpus\n",
        "    \n",
        "    def _clean_special_word(self, word):\n",
        "        # The formatted text after removing not necessary punctuations.\n",
        "        formatted_text = re.sub(r\"[^a-zA-Z0-9:€$-,%.?!]+\", ' ', word) \n",
        "        # In the above regex expression,I am providing necessary set of punctuations that are frequent in this particular dataset.\n",
        "        return formatted_text\n",
        "    \n",
        "\n",
        "    def lemmatize(self, corpus):\n",
        "        nlp = spacy.load('en_core_web_sm')\n",
        "        return [[token.lemma_ for token in nlp(doc)] for doc in corpus]\n"
      ],
      "metadata": {
        "id": "spYv4QqyqJ0H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skv2-rEQwMtR"
      },
      "source": [
        "### Corpus class\n",
        "I'm going to create a class for the representation of the corpus in order to have a self contained way to have all the functions that may be useful for the processing of the corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C3PyvlOV60V7"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "import numpy as np\n",
        "import torch\n",
        "import spacy\n",
        "\n",
        "\n",
        "class MovieReviewsCorpusPhrases():\n",
        "    def __init__(self, preprocess_pipeline = None):\n",
        "        \"\"\"\n",
        "        If non preprocess_pipeline is given, the text gets tokenized by default\n",
        "        using spacy tokenizer\n",
        "        \"\"\"\n",
        "        self.mr = movie_reviews\n",
        "        if preprocess_pipeline != None and not isinstance(preprocess_pipeline, MRPipelinePhrases):\n",
        "            raise ValueError(f\"preprocess_pipeline is not valid, you should pass \\\n",
        "                                a MRPipelinePhrases object or None\")\n",
        "        self.pipeline = preprocess_pipeline\n",
        "        self.raw_corpus, self.labels = self._get_raw_corpus()\n",
        "        if self.pipeline == None:\n",
        "            self.processed_corpus = self.raw_corpus\n",
        "        else:\n",
        "            # Flattened and preprocessed corpus\n",
        "            self.processed_corpus = self._preprocess()\n",
        "        \n",
        "        self.vocab = self._create_vocab()\n",
        "        \n",
        "\n",
        "    def _get_raw_corpus(self):\n",
        "        neg = [self.mr.raw(doc) for doc in self.mr.fileids()[:1000]]\n",
        "        pos = [self.mr.raw(doc) for doc in self.mr.fileids()[1000:]]\n",
        "        labels = [0]*len(neg) + [1]*len(pos)\n",
        "        return neg + pos, labels\n",
        "    \n",
        "    def _preprocess(self):\n",
        "        if self.pipeline != None:\n",
        "            return self.pipeline(self.raw_corpus)\n",
        "        else:\n",
        "            return self.raw_corpus\n",
        "        \n",
        "    def _create_vocab(self):\n",
        "        vocab = dict()\n",
        "        corpus_words = [w for doc in self.processed_corpus for w in doc]\n",
        "        for word in corpus_words:\n",
        "            try:\n",
        "                vocab[word] += 1\n",
        "            except:\n",
        "                vocab[word] = 1\n",
        "        return vocab\n",
        "\n",
        "    def get_embedding_matrix(self, embedding, embedding_dim):\n",
        "        \"\"\"\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            A 2D which each row has the corresponding embedding from the vocabulary\n",
        "        \"\"\"\n",
        "        matrix_length = len(self.vocab)\n",
        "        embedding_matrix = np.zeros((matrix_length, embedding_dim))\n",
        "        # If I use torch.zeros directly it crashes (don't know why)\n",
        "        embedding_matrix = torch.from_numpy(embedding_matrix.copy())\n",
        "        null_embedding = torch.tensor([0.0]*embedding_dim)\n",
        "        for idx, key in enumerate(self.vocab.keys()):\n",
        "            if torch.equal(embedding[key], null_embedding):\n",
        "                embedding_matrix[idx] = torch.randn(embedding_dim)\n",
        "            else:\n",
        "                embedding_matrix[idx] = embedding[key]\n",
        "                \n",
        "        return embedding_matrix\n",
        "    \n",
        "    def get_indexed_corpus(self):\n",
        "        \"\"\"\n",
        "        Returns\n",
        "        -------\n",
        "        Dictionary\n",
        "            Containing correspondences word -> index\n",
        "        \n",
        "        list(list(torch.tensor))\n",
        "            The corpus represented as indexes corresponding to each word\n",
        "        \"\"\"\n",
        "        vocab = {}\n",
        "        for idx, key in enumerate(self.vocab.keys()):\n",
        "            vocab[key] = idx\n",
        "        \n",
        "        indexed_corpus = [torch.tensor([torch.tensor(vocab[w], dtype=torch.int32) for w in doc]) for doc in self.processed_corpus]\n",
        "        return indexed_corpus, self.labels\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.processed_corpus)\n",
        "\n",
        "\n",
        "class MovieReviewsCorpus():\n",
        "    def __init__(self, preprocess_pipeline = None):\n",
        "        # list of documents, each document is a list containing words of that document\n",
        "        self.mr = movie_reviews\n",
        "        self.pipeline = preprocess_pipeline\n",
        "        # Corpus as list of documents. Documents as list of sentences. Sentences as list of tokens\n",
        "        self.unprocessed_corpus, self.labels = self._get_corpus()\n",
        "        # Corpus as list of documents. Documents as list of tokens\n",
        "        self.flattened_corpus = self._flatten()\n",
        "        if preprocess_pipeline == None:\n",
        "            self.processed_corpus = self.flattened_corpus\n",
        "        else:\n",
        "            # Flattened and preprocessed corpus\n",
        "            self.processed_corpus = self._preprocess()\n",
        "\n",
        "        self.corpus_words = self.get_corpus_words()\n",
        "        self.vocab = self._create_vocab()\n",
        "\n",
        "\n",
        "\n",
        "    def _list_to_str(self, doc) -> str:\n",
        "        \"\"\"\n",
        "        Put all elements of the list into a single string, separating each element with a space.\n",
        "        \"\"\"\n",
        "        return \" \".join([w for sent in doc for w in sent])\n",
        "\n",
        "    def _preprocess(self):\n",
        "        return self.pipeline(self.flattened_corpus)\n",
        "\n",
        "    def _flatten(self):\n",
        "        \"\"\"\n",
        "        Returns\n",
        "        -------\n",
        "        list[list[str]]\n",
        "            Each inner list represents a document. Each document is a list of tokens.\n",
        "        \"\"\"\n",
        "\n",
        "        # 3 nested list: each list contain a document, each inner list contains a phrase (until fullstop), each phrase contains words.\n",
        "\n",
        "        corpus = [[w for w in self._list_to_str(d).split(\" \")] for d in self.unprocessed_corpus]\n",
        "        return corpus\n",
        "\n",
        "    def _get_corpus(self):\n",
        "        neg = self.mr.paras(categories = \"neg\")\n",
        "        pos = self.mr.paras(categories = \"pos\")\n",
        "        labels = [0] * len(pos) + [1] * len(neg)\n",
        "        return neg + pos, labels\n",
        "\n",
        "    def movie_reviews_dataset_raw(self):\n",
        "        \"\"\"\n",
        "        Returns the dataset containing:\n",
        "\n",
        "        - A list of all the documents\n",
        "        - The corresponding label for each document\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tuple(list, list)\n",
        "            The dataset: first element is the list of the document, the second element of the tuple is the associated label (positive or negative) for each document\n",
        "        \"\"\"\n",
        "\n",
        "        return self.flattened_corpus, self.labels\n",
        "\n",
        "    def get_sentence_ds(self):\n",
        "        neg = self.mr.paras(categories = \"neg\")\n",
        "        pos = self.mr.paras(categories = \"pos\")\n",
        "\n",
        "        pos = [phrase for doc in pos for phrase in doc]\n",
        "        neg = [phrase for doc in neg for phrase in doc]\n",
        "\n",
        "        labels = np.array([0] * len(pos) + [1] * len(neg))\n",
        "        corpus = neg+pos\n",
        "        return corpus, labels\n",
        "\n",
        "\n",
        "    def get_corpus_words(self) -> list:\n",
        "        return [w for doc in self.processed_corpus for w in doc]\n",
        "    \n",
        "    def get_embedding_matrix(self, embedding, embedding_dim):\n",
        "        \"\"\"\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            A 2D which each row has the corresponding embedding from the vocabulary\n",
        "        \"\"\"\n",
        "        matrix_length = len(self.vocab)\n",
        "        embedding_matrix = np.zeros((matrix_length, embedding_dim))\n",
        "        # If I use torch.zeros directly it crashes (don't know why)\n",
        "        embedding_matrix = torch.from_numpy(embedding_matrix.copy())\n",
        "        null_embedding = torch.tensor([0.0]*embedding_dim)\n",
        "        for idx, key in enumerate(self.vocab.keys()):\n",
        "            if torch.equal(embedding[key], null_embedding):\n",
        "                embedding_matrix[idx] = torch.randn(embedding_dim)\n",
        "            else:\n",
        "                embedding_matrix[idx] = embedding[key]\n",
        "                \n",
        "        return embedding_matrix\n",
        "    \n",
        "    def get_fasttext_embedding_matrix(self, embedding, embedding_dim):\n",
        "        matrix_length = len(self.vocab)\n",
        "        embedding_matrix = np.zeros((matrix_length, embedding_dim))\n",
        "        # If I use torch.zeros directly it crashes (don't know why)\n",
        "        embedding_matrix = torch.from_numpy(embedding_matrix.copy())\n",
        "        null_embedding = torch.tensor([0.0]*embedding_dim)\n",
        "        for idx, key in enumerate(self.vocab.keys()):\n",
        "            tensor_embedding = torch.from_numpy(embedding[key].copy())\n",
        "            if torch.equal(tensor_embedding, null_embedding):\n",
        "                embedding_matrix[idx] = torch.randn(embedding_dim)\n",
        "            else:\n",
        "                embedding_matrix[idx] = tensor_embedding\n",
        "                \n",
        "        return embedding_matrix\n",
        "    \n",
        "    def get_indexed_corpus(self):\n",
        "        \"\"\"\n",
        "        Returns\n",
        "        -------\n",
        "        Dictionary\n",
        "            Containing correspondences word -> index\n",
        "        \n",
        "        list(list(torch.tensor))\n",
        "            The corpus represented as indexes corresponding to each word\n",
        "        \"\"\"\n",
        "        vocab = {}\n",
        "        for idx, key in enumerate(self.vocab.keys()):\n",
        "            vocab[key] = idx\n",
        "        \n",
        "        indexed_corpus = [torch.tensor([torch.tensor(vocab[w], dtype=torch.int32) for w in doc]) for doc in self.processed_corpus]\n",
        "        return indexed_corpus, self.labels\n",
        "\n",
        "\n",
        "    def _create_vocab(self):\n",
        "        vocab = dict()\n",
        "        for word in self.corpus_words:\n",
        "            try:\n",
        "                vocab[word] += 1\n",
        "            except:\n",
        "                vocab[word] = 1\n",
        "        return vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.flattened_corpus)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zZaF5yV9rlo-"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "class MovieReviewsDataset(Dataset):\n",
        "  def __init__(self, raw_dataset):\n",
        "    super(MovieReviewsDataset, self).__init__()\n",
        "    self.corpus = np.array(raw_dataset[0], dtype = object)\n",
        "    self.targets = np.array(raw_dataset[1], dtype = np.int64)\n",
        "    self.max_element = len(max(self.corpus, key=lambda x: len(x)))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.corpus)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    item = self.corpus[index]\n",
        "    label = self.targets[index]\n",
        "    return (item, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr7PPG1k4gFq"
      },
      "source": [
        "### Create the model class\n",
        "Let's first try with a simple BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bCvqaJ8-hKmT"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.utils.rnn import pad_packed_sequence\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, embedding_matrix = None, device = \"cuda\", input_size = 300, hidden_size = 128, output_size = 2):\n",
        "        super(BiLSTM, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.device = device\n",
        "        if embedding_matrix != None:\n",
        "          self.embedding = self.create_embedding_layer(embedding_matrix)\n",
        "        else:\n",
        "          self.embedding = None\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first = True, bidirectional=True)\n",
        "        self.fc = nn.Sequential(nn.ReLU(),\n",
        "                                nn.BatchNorm1d(hidden_size*2, eps = 1e-08),\n",
        "                                nn.Dropout(0.3),\n",
        "                                nn.Linear(hidden_size*2, output_size)\n",
        "                                )\n",
        "\n",
        "    def create_embedding_layer(self, embedding_matrix):\n",
        "        num_embeddings, embedding_dim = embedding_matrix.shape\n",
        "        emb_layer = nn.Embedding(num_embeddings, embedding_dim, -1)\n",
        "        emb_layer.load_state_dict({\"weight\": embedding_matrix})\n",
        "        return emb_layer\n",
        "\n",
        "    # function taken from https://discuss.pytorch.org/t/how-to-use-pack-sequence-if-we-are-going-to-use-word-embedding-and-bilstm/28184/4\n",
        "    def simple_elementwise_apply(self, fn, packed_sequence):\n",
        "        \"\"\"applies a pointwise function fn to each element in packed_sequence\"\"\"\n",
        "        return torch.nn.utils.rnn.PackedSequence(fn(packed_sequence.data), packed_sequence.batch_sizes)\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        if self.cuda:\n",
        "            return (torch.zeros(2, batch_size, self.hidden_size).to(self.device),\n",
        "                    torch.zeros(2, batch_size, self.hidden_size).to(self.device),)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.batch_sizes[0].item()\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        x = self.simple_elementwise_apply(self.embedding, x)\n",
        "\n",
        "        # output: batch_size, sequence_length, hidden_size * 2 (since is bilstm)\n",
        "        out, _ = self.lstm(x, hidden)\n",
        "        out, input_sizes = pad_packed_sequence(out, batch_first=True)\n",
        "        # Interested only in the last layer\n",
        "        out = out[list(range(batch_size)), input_sizes - 1, :]\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class BiLSTMAttention(BiLSTM):\n",
        "    # BiLSTM with attention inspired by the following paper: https://aclanthology.org/S18-1040.pdf\n",
        "    def __init__(self, embedding_matrix = None, device=\"cuda\", input_size=300,\n",
        "                 hidden_size=128, context_size = None, output_size=2):\n",
        "        super(BiLSTMAttention, self).__init__(embedding_matrix, device, input_size, hidden_size, output_size)\n",
        "        # Not self attention :)\n",
        "        if context_size != None:\n",
        "          self.attention = nn.Linear(self.hidden_size * 2, context_size)\n",
        "          self.history = nn.Parameter(torch.randn(context_size))\n",
        "        else:\n",
        "          self.attention = nn.Linear(self.hidden_size * 2, 1)\n",
        "          self.history = None\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        batch_size = x.batch_sizes[0].item()\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        if self.embedding != None:\n",
        "          x = self.simple_elementwise_apply(self.embedding, x)\n",
        "\n",
        "        # output: batch_size, sequence_length, hidden_size * 2 (since is bilstm)\n",
        "        out, _ = self.lstm(x, hidden)\n",
        "        out, input_sizes = pad_packed_sequence(out, batch_first=True)\n",
        "\n",
        "        if self.history == None:\n",
        "          attention_values = torch.tanh(self.attention(out)).squeeze()\n",
        "          attention_weights = torch.softmax(attention_values, dim = 1).unsqueeze(1)\n",
        "          # n_docs, sequence_length\n",
        "        else:\n",
        "          attention_values = torch.tanh(self.attention(out))\n",
        "          attention_weights = torch.softmax(attention_values.matmul(self.history), dim = 1).unsqueeze(1)\n",
        "          # n_docs, sequence_length\n",
        "\n",
        "        out = torch.sum(attention_weights.matmul(out), dim = 1)\n",
        "\n",
        "        out = self.fc(out)\n",
        "\n",
        "        attention_weights = attention_weights.squeeze()\n",
        "        att = [doc[:input_sizes[idx]] for idx, doc in enumerate(attention_weights)]\n",
        "\n",
        "        return out, att\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yZFg9BvQdZHB"
      },
      "outputs": [],
      "source": [
        "def training_step(net, data_loader, optimizer, cost_function, device = 'cuda'):\n",
        "  cumulative_loss = 0\n",
        "  cumulative_accuracy = 0\n",
        "  samples = 0\n",
        "\n",
        "  net.train()\n",
        "\n",
        "  for batch_idx, (inputs, targets, _) in enumerate(data_loader):\n",
        "\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "    in_size = targets.size(dim=0)\n",
        "\n",
        "    outputs, _ = net(inputs)\n",
        "\n",
        "    loss = cost_function(outputs, targets)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    samples += in_size\n",
        "    cumulative_loss += loss.item()\n",
        "    _, predicted = outputs.max(dim=1)\n",
        "\n",
        "    cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, (cumulative_accuracy/samples)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LJef4h1cfWym"
      },
      "outputs": [],
      "source": [
        "def test_step(net, data_loader, cost_function, device = 'cuda'):\n",
        "  cumulative_loss = 0\n",
        "  cumulative_accuracy = 0\n",
        "  samples = 0\n",
        "\n",
        "  net.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for batch_idx, (inputs, targets, _) in enumerate(data_loader):\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      in_size = targets.size(dim=0)\n",
        "\n",
        "      outputs, _ = net(inputs)\n",
        "\n",
        "      loss = cost_function(outputs, targets)\n",
        "\n",
        "      samples += in_size\n",
        "      cumulative_loss += loss.item()\n",
        "      _, predicted = outputs.max(dim=1)\n",
        "\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "    return cumulative_loss/samples, (cumulative_accuracy/samples)*100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OOeUmEHZNBvw"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "import torch.nn as nn\n",
        "\n",
        "def main(train_loader, test_loader, embedding_matrix, device = \"cuda\", epochs = 10):\n",
        "\n",
        "  net = BiLSTMAttention(embedding_matrix, device = device, input_size=300).to(device)\n",
        "\n",
        "  optimizer = Adam(net.parameters(), 0.001, betas = (0.9, 0.9), amsgrad=True)\n",
        "\n",
        "  cost_function = nn.CrossEntropyLoss()\n",
        "\n",
        "  for e in range(epochs):\n",
        "    print(f\"epoch {e}:\")\n",
        "    train_loss, train_accuracy = training_step(net, train_loader, optimizer, cost_function, device)\n",
        "    print(f\"Training loss: {train_loss} \\n Training accuracy: {train_accuracy}\")\n",
        "    test_loss, test_accuracy = test_step(net, test_loader, cost_function, device)\n",
        "    print(f\"Test loss: {test_loss} \\n Test accuracy: {test_accuracy}\")\n",
        "    print(\"------------------------------------------------------------------\")\n",
        "  \n",
        "  _, test_accuracy = test_step(net, test_loader, cost_function, device)\n",
        "\n",
        "  return test_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GfNtrS8jmATx"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def pad(batch, max_size):\n",
        "    # try:\n",
        "    pad = torch.tensor([-1]*batch[0].size(dim=1), dtype = torch.float).to(\"cuda\")\n",
        "    embedded = 1\n",
        "    # except:\n",
        "    #  pad = torch.tensor([-1])\n",
        "    #  embedded = 0\n",
        "    for idx in range(len(batch)):\n",
        "        remaining = max_size - batch[idx].size(dim = 0)\n",
        "        abc = pad.repeat(remaining)\n",
        "        if embedded:\n",
        "          batch[idx] = torch.cat((batch[idx], pad.repeat(remaining, 1)), dim = 0)\n",
        "        else:\n",
        "          batch[idx] = torch.cat((batch[idx], pad.repeat(remaining)), dim = 0)\n",
        "    return batch\n",
        "\n",
        "def batch_to_tensor(X: List[torch.tensor], max_size):\n",
        "    # try:\n",
        "    X_tensor = torch.zeros((len(X), max_size, X[0].size(dim=1)), dtype=torch.float).to(\"cuda\")\n",
        "    # except:\n",
        "    #  X_tensor = torch.zeros((len(X), max_size), dtype=torch.int32)\n",
        "\n",
        "    for i, embed in enumerate(X):\n",
        "        X_tensor[i] = embed\n",
        "    return X_tensor\n",
        "\n",
        "def sort_ds(X, Y):\n",
        "    \"\"\"\n",
        "    Sort inputs by document lengths\n",
        "    \"\"\"\n",
        "    document_lengths = np.array([tens.size(dim = 0) for tens in X])\n",
        "    indexes = np.argsort(document_lengths)\n",
        "    document_lengths = document_lengths.tolist()\n",
        "\n",
        "    X_sorted = [X[idx] for idx in indexes][::-1]\n",
        "    Y_sorted = [Y[idx] for idx in indexes][::-1]\n",
        "    document_lengths = torch.tensor([document_lengths[idx] for idx in indexes][::-1])\n",
        "\n",
        "    return X_sorted, Y_sorted, document_lengths, indexes\n",
        "\n",
        "\n",
        "\n",
        "def collate(batch):\n",
        "    X, Y = list(zip(*batch))\n",
        "    # Sort dataset\n",
        "    X, Y, document_lengths, indexes = sort_ds(X, Y)\n",
        "\n",
        "    # Get tensor sizes\n",
        "    max_size = torch.max(document_lengths).item()\n",
        "\n",
        "    # Pad tensor each element\n",
        "    X = pad(X, max_size)\n",
        "\n",
        "    # Transform the batch to a tensor\n",
        "    X_tensor = batch_to_tensor(X, max_size)\n",
        "    Y_tensor = torch.tensor(Y)\n",
        "    # Return the padded sequence object\n",
        "    X_final = pack_padded_sequence(X_tensor, document_lengths, batch_first=True)\n",
        "    return X_final, Y_tensor, indexes\n",
        "\n",
        "\n",
        "def get_data(batch_size: int, dataset, collate_fn, random_state = 42):\n",
        "  # Random Split\n",
        "  train_indexes, test_indexes = train_test_split(list(range(len(dataset.targets))), test_size = 0.2,\n",
        "                                                  stratify = dataset.targets, random_state = random_state)\n",
        "\n",
        "  train_ds = Subset(dataset, train_indexes)\n",
        "  test_ds = Subset(dataset, test_indexes)\n",
        "\n",
        "  train_loader = DataLoader(train_ds, batch_size = batch_size, collate_fn = collate_fn, pin_memory=True)\n",
        "  test_loader = DataLoader(test_ds, batch_size = batch_size, collate_fn = collate_fn, pin_memory=True)\n",
        "\n",
        "  return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "\n",
        "def main_cross_validation(main, dataset, embedding_matrix, collate_fn,\n",
        "                          device = \"cuda\", epochs = 20, random_state = 42, batch_size = 128):\n",
        "\n",
        "  targets = np.asarray(dataset.targets, dtype=np.int64)\n",
        "\n",
        "  skf = StratifiedKFold(5, shuffle = True, random_state=random_state)\n",
        "\n",
        "  fold_accuracies = []\n",
        "  \n",
        "  for fold, (train_indexes, val_indexes) in enumerate(skf.split(np.zeros(len(dataset)),\n",
        "                                                      targets)):\n",
        "    \n",
        "    train_sampler = SubsetRandomSampler(train_indexes)\n",
        "    val_sampler = SubsetRandomSampler(val_indexes)\n",
        "\n",
        "    train_loader = DataLoader(dataset, batch_size = batch_size, sampler = train_sampler,\n",
        "                              collate_fn = collate_fn, pin_memory=True)\n",
        "    val_loader = DataLoader(dataset, batch_size = batch_size, sampler = val_sampler,\n",
        "                            collate_fn = collate_fn, pin_memory = True)\n",
        "\n",
        "\n",
        "    val_accuracy = main(train_loader, test_loader, embedding_matrix, device, epochs)\n",
        "    \n",
        "    fold_accuracies.append(val_accuracy)\n",
        "\n",
        "\n",
        "  fold_accuracies = np.array(fold_accuracies)\n",
        "\n",
        "  return fold_accuracies.mean(), fold_accuracies.std()\n",
        "\n"
      ],
      "metadata": {
        "id": "FkRBKES24_0v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lexicon Based Supervised Attention Model"
      ],
      "metadata": {
        "id": "MkeZyHH15r6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MRPipelineLBSA(MRAbstractPipeline):\n",
        "    \"\"\"\n",
        "    Pipeline for documents represented as list of tokens\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(MRPipelineLBSA, self).__init__()\n",
        "        self.pipeline = [self.remove_underscores, \n",
        "                         self.reducing_character_repetitions,\n",
        "                         self.merge_apostrophes,\n",
        "                         self.clean_contractions,\n",
        "                         self.clean_special_chars,\n",
        "                         # self.remove_stop_words\n",
        "                         ]\n",
        "\n",
        "    def remove_underscores(self, corpus):\n",
        "        \"\"\"\n",
        "        Solves the problem where some of the words are surrounded by underscores\n",
        "        (e.g. \"_hello_\")\n",
        "        \"\"\"\n",
        "\n",
        "        for doc in corpus:\n",
        "          for sent in doc:\n",
        "            for idx, word in enumerate(sent):\n",
        "                if \"_\" in word:\n",
        "                    cleaned_word = self._clean_word(word)\n",
        "                    sent[idx] = cleaned_word\n",
        "        return corpus\n",
        "\n",
        "\n",
        "    def _clean_word(self, word: str):\n",
        "        word = word.replace(\"_\", \" \")\n",
        "        # remove spaces before and after the word\n",
        "        word = word.split()\n",
        "        word = \" \".join(word)\n",
        "        return word\n",
        "    \n",
        "    def reducing_character_repetitions(self, corpus):\n",
        "        \n",
        "        new_corpus = [[[self._clean_repetitions(w) for w in sent] for sent in doc] for doc in corpus]\n",
        "        return new_corpus\n",
        "\n",
        "    # inspired by https://towardsdatascience.com/cleaning-preprocessing-text-data-by-building-nlp-pipeline-853148add68a\n",
        "    def _clean_repetitions(self, word):\n",
        "        \"\"\"\n",
        "        This Function will reduce repetition to two characters \n",
        "        for alphabets and to one character for punctuations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "            word: str                \n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            Finally formatted text with alphabets repeating to \n",
        "            one characters & punctuations limited to one repetition \n",
        "            \n",
        "        Example:\n",
        "        Input : Realllllllllyyyyy,        Greeeeaaaatttt   !!!!?....;;;;:)\n",
        "        Output : Really, Great !?.;:)\n",
        "\n",
        "        \"\"\"\n",
        "        # Pattern matching for all case alphabets\n",
        "        pattern_alpha = re.compile(r\"([A-Za-z])\\1{1,}\", re.DOTALL)\n",
        "\n",
        "        # Limiting all the repetitions to two characters.\n",
        "        # MODIFIED: keep only one repetition of the character\n",
        "        formatted_text = pattern_alpha.sub(r\"\\1\\1\", word) \n",
        "\n",
        "        # Pattern matching for all the punctuations that can occur\n",
        "        pattern_punct = re.compile(r'([.,/#!$%^&*?;:{}=_`~()+-])\\1{1,}')\n",
        "\n",
        "        # Limiting punctuations in previously formatted string to only one.\n",
        "        combined_formatted = pattern_punct.sub(r'\\1', formatted_text)\n",
        "\n",
        "        # The below statement is replacing repetitions of spaces that occur more than two times with that of one occurrence.\n",
        "        final_formatted = re.sub(' {2,}',' ', combined_formatted)\n",
        "        return final_formatted\n",
        "    \n",
        "    def merge_apostrophes(self, corpus):\n",
        "      new_corpus = []\n",
        "      for doc in corpus:\n",
        "        new_doc = []\n",
        "        for sent in doc:\n",
        "          indexes = self._get_neg_indexes(sent)\n",
        "          for el in indexes:\n",
        "            sent[el[0]:el[1]] = [\"\".join(sent[el[0]:el[1]])]\n",
        "          new_doc.append(sent)\n",
        "        new_corpus.append(new_doc)\n",
        "      return new_corpus\n",
        "\n",
        "    def _get_neg_indexes(self, sent):\n",
        "      contr = [\"t\", \"ve\", \"re\", \"ll\", \"d\", \"all\", \"y\", \"cause\", \"m\", \"clock\", \"am\", \"s\"]\n",
        "      indexes = []\n",
        "      for idx, word in enumerate(sent):\n",
        "        # Try-except to avoid out of range indexes (there can be some \"'\" a the beginning or end of the phrase)\n",
        "        try:\n",
        "          if word==\"'\" and sent[idx+1] in contr:\n",
        "            indexes.append((idx-1,idx+2))\n",
        "        except:\n",
        "          pass\n",
        "      return indexes\n",
        "    \n",
        "    def clean_contractions(self, corpus):\n",
        "        new_corpus = []\n",
        "        for doc in corpus:\n",
        "          new_doc = []\n",
        "          for sent in doc:\n",
        "            new_sent = []\n",
        "            for word in sent:\n",
        "                try:\n",
        "                    correct = CONTRACTION_MAP[word]\n",
        "                    correct = correct.split()\n",
        "                    new_sent += correct\n",
        "                except:\n",
        "                    new_sent.append(word)\n",
        "            new_doc.append(new_sent)\n",
        "          new_corpus.append(new_doc)\n",
        "        return new_corpus\n",
        "\n",
        "    def clean_special_chars(self, corpus):\n",
        "        new_corpus = [[[self._clean_special_word(w) for w in sent] for sent in doc] for doc in corpus] \n",
        "        return new_corpus\n",
        "    \n",
        "    def _clean_special_word(self, word):\n",
        "        # The formatted text after removing not necessary punctuations.\n",
        "        formatted_text = re.sub(r\"[^a-zA-Z0-9:€$-,%.?!]+\", '', word) \n",
        "        # In the above regex expression,I am providing necessary set of punctuations that are frequent in this particular dataset.\n",
        "        return formatted_text\n",
        "    \n",
        "    def remove_stop_words(self, corpus):\n",
        "      stops = stopwords.words(\"english\")\n",
        "      # We don't want to remove stop words associated with negations\n",
        "      stops = [word for word in stops if \"'t\" not in word or \"not\" not in word]\n",
        "      return [[[word for word in sent if word not in stops] for sent in doc] for doc in corpus]"
      ],
      "metadata": {
        "id": "sJQywSXpD33-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MovieReviewsCorpusLBSA():\n",
        "  def __init__(self, preprocess_pipeline = None):\n",
        "      \"\"\"\n",
        "      If non preprocess_pipeline is given, the text gets tokenized by default\n",
        "      using spacy tokenizer\n",
        "      \"\"\"\n",
        "      self.mr = movie_reviews\n",
        "      if preprocess_pipeline != None and not isinstance(preprocess_pipeline, MRPipelineLBSA):\n",
        "          raise ValueError(f\"preprocess_pipeline is not valid, you should pass \\\n",
        "                              a MRPipelineLBSA object or None\")\n",
        "      self.pipeline = preprocess_pipeline\n",
        "      self.raw_corpus, self.labels = self._get_raw_corpus()\n",
        "      if self.pipeline == None:\n",
        "          self.processed_corpus = self.raw_corpus\n",
        "      else:\n",
        "          # Flattened and preprocessed corpus\n",
        "          self.processed_corpus = self._preprocess()\n",
        "      \n",
        "      self.vocab = self._create_vocab()\n",
        "      \n",
        "\n",
        "  def _get_raw_corpus(self):\n",
        "      neg = self.mr.paras(categories = \"neg\")\n",
        "      pos = self.mr.paras(categories = \"pos\")\n",
        "      labels = [0]*len(neg) + [1]*len(pos)\n",
        "      return neg + pos, labels\n",
        "  \n",
        "  def _preprocess(self):\n",
        "      if self.pipeline != None:\n",
        "          return self.pipeline(self.raw_corpus)\n",
        "      else:\n",
        "          return self.raw_corpus\n",
        "      \n",
        "  def _create_vocab(self):\n",
        "      vocab = dict()\n",
        "      corpus_words = [w for doc in self.processed_corpus for sent in doc for w in sent]\n",
        "      for word in corpus_words:\n",
        "          try:\n",
        "              vocab[word] += 1\n",
        "          except:\n",
        "              vocab[word] = 1\n",
        "      return vocab\n",
        "\n",
        "  def get_embedding_matrix(self, embedding, embedding_dim):\n",
        "      \"\"\"\n",
        "      Returns\n",
        "      -------\n",
        "      np.ndarray\n",
        "          A 2D which each row has the corresponding embedding from the vocabulary\n",
        "      \"\"\"\n",
        "      matrix_length = len(self.vocab)\n",
        "      embedding_matrix = np.zeros((matrix_length, embedding_dim))\n",
        "      # If I use torch.zeros directly it crashes (don't know why)\n",
        "      embedding_matrix = torch.from_numpy(embedding_matrix.copy())\n",
        "      null_embedding = torch.tensor([0.0]*embedding_dim)\n",
        "      for idx, key in enumerate(self.vocab.keys()):\n",
        "          if torch.equal(embedding[key], null_embedding):\n",
        "              embedding_matrix[idx] = torch.randn(embedding_dim)\n",
        "          else:\n",
        "              embedding_matrix[idx] = embedding[key]\n",
        "              \n",
        "      return embedding_matrix\n",
        "  \n",
        "  def get_indexed_corpus(self):\n",
        "      \"\"\"\n",
        "      Returns\n",
        "      -------\n",
        "      Dictionary\n",
        "          Containing correspondences word -> index\n",
        "      \n",
        "      list(int)\n",
        "          labels associated with each document\n",
        "      \"\"\"\n",
        "      vocab = {}\n",
        "      for idx, key in enumerate(self.vocab.keys()):\n",
        "          vocab[key] = idx\n",
        "      \n",
        "      # each doc is a list of tensor which represent sentences, each sentence is a tensor of indexed words\n",
        "      indexed_corpus = [[torch.tensor([vocab[w] for w in sent], dtype=torch.int32) \n",
        "                        for sent in doc]\n",
        "                        for doc in self.processed_corpus]\n",
        "      return indexed_corpus, self.labels\n",
        "  \n",
        "  def __len__(self):\n",
        "      return len(self.processed_corpus)\n",
        "\n",
        "c = MovieReviewsCorpusLBSA()"
      ],
      "metadata": {
        "id": "n9gmVtdg_Gf1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import sentiwordnet as swn\n",
        "import pandas as pd\n",
        "import math\n",
        "import json\n",
        "\n",
        "class MovieReviewsDatasetLBSA(Dataset):\n",
        "  def __init__(self, corpus):\n",
        "    super(MovieReviewsDatasetLBSA, self).__init__()\n",
        "    self.corpus = corpus\n",
        "    indexed_corpus = self.corpus.get_indexed_corpus()\n",
        "    # Word level gold attention vector\n",
        "    self.word_lambda = 3\n",
        "    self.sentence_lambda = 3\n",
        "    self.sentiment_degree = self._compute_sentiment_degree()\n",
        "    self.wl_gold_av = self._compute_gold_words()\n",
        "    self.sl_gold_av = self._compute_gold_sents()\n",
        "    self.data = indexed_corpus[0]\n",
        "    self.targets = indexed_corpus[1]\n",
        "  \n",
        "  def _compute_sentiment_degree(self):\n",
        "    senti_vocab = self._build_senti_vocab(self.corpus.vocab)\n",
        "    path = '/content/gdrive/My Drive/nlu-project/lexicons/'\n",
        "    mpqa_vocab = self._build_0_1_vocab(self.corpus.vocab, path + 'mpqa/mpqa.json')\n",
        "    bingliu_vocab = self._build_0_1_vocab(self.corpus.vocab, path + 'bingliu/bingliu.json')\n",
        "    inquirer_vocab = self._build_0_1_vocab(self.corpus.vocab, path + 'inquirer/inquirer.json')\n",
        "    senticnet_vocab = self.build_sentic_net_vocab(self.corpus.vocab, path + \"sentic_net/senticnet.txt\")\n",
        "    res = self._compute_average_sentiment_degree(senti_vocab,\n",
        "                                                 mpqa_vocab,\n",
        "                                                 bingliu_vocab,\n",
        "                                                 inquirer_vocab,\n",
        "                                                 senticnet_vocab\n",
        "                                                 )\n",
        "    \n",
        "    corpus = self.corpus.processed_corpus\n",
        "    scores = [[[res[word] for word in sent] for sent in doc] for doc in corpus]\n",
        "    return scores\n",
        "\n",
        "  def _compute_gold_sents(self):\n",
        "    sentence_sentiment_degree  = [[sum(sent)/len(sent) for sent in doc] for doc in self.sentiment_degree]\n",
        "    gold = [self._normalized_softmax(doc, self.sentence_lambda) for doc in sentence_sentiment_degree]\n",
        "    return gold\n",
        "\n",
        "\n",
        "  def _compute_gold_words(self):\n",
        "    gold = [[self._normalized_softmax(sent_scores, self.word_lambda) for sent_scores in doc] for doc in self.sentiment_degree]\n",
        "    return gold\n",
        "\n",
        "  def _normalized_softmax(self, sequence, lam):\n",
        "    multiplied_sequence = [lam * el for el in sequence]\n",
        "    total = sum([math.exp(el) for el in sequence])\n",
        "    res = torch.tensor([math.exp(lam * el)/total for el in sequence])\n",
        "    return res\n",
        "\n",
        "  def _build_0_1_vocab(self, vocab, path):\n",
        "    \"\"\"\n",
        "    Taken from https://github.com/williamleif/socialsent/blob/master/socialsent/data/lexicons/mpqa.json\n",
        "\n",
        "    Values:\n",
        "    - 1 = positive\n",
        "    - 0 = neutral\n",
        "    - -1 = negative\n",
        "    \n",
        "    The absolute value will be taken\n",
        "    \"\"\"\n",
        "    with open(path, 'r') as f:\n",
        "      lexicon = json.load(f)\n",
        "    \n",
        "    res_vocab = {}\n",
        "    for key in vocab.keys():\n",
        "      res_vocab[key] = 0\n",
        "    \n",
        "    for key in res_vocab.keys():\n",
        "      try:\n",
        "        value = lexicon[key]\n",
        "        res_vocab[key] = abs(value)\n",
        "      except KeyError:\n",
        "        pass\n",
        "    \n",
        "    return res_vocab\n",
        "\n",
        "\n",
        "  def _build_senti_vocab(self, vocab):\n",
        "    \"\"\"\n",
        "    builds a vocab using senti-wordnet\n",
        "    \"\"\"\n",
        "    senti_vocab = {}\n",
        "    for key in vocab.keys():\n",
        "      senti_vocab[key] = 0\n",
        "\n",
        "    max_value = 0\n",
        "    for key in senti_vocab.keys():\n",
        "      senses = list(swn.senti_synsets(key))\n",
        "      pos = 0\n",
        "      neg = 0\n",
        "      for sense in senses:\n",
        "        if sense.synset.name().split(\".\")[0] == key:\n",
        "          pos += sense.pos_score()\n",
        "          neg += sense.neg_score()\n",
        "      if (pos != 0) or (neg != 0):\n",
        "        senti_vocab[key] = max(pos, neg)\n",
        "      if senti_vocab[key] > max_value:\n",
        "        max_value = senti_vocab[key]\n",
        "\n",
        "    for key in senti_vocab.keys():\n",
        "      senti_vocab[key] = self.maprange((0, max_value), (0, 1), senti_vocab[key])\n",
        "\n",
        "    return senti_vocab\n",
        "  \n",
        "  def build_sentic_net_vocab(self, vocab, path):\n",
        "\n",
        "    df = pd.read_csv(path, sep=\"\\t+\")\n",
        "\n",
        "    df.replace([\"negative\", \"positive\"], 1, inplace = True)\n",
        "    # df.set_index([\"CONCEPT\"], inplace = True)\n",
        "\n",
        "    df = dict(zip(df.CONCEPT, df.POLARITY))\n",
        "\n",
        "    res_vocab = {}\n",
        "    for key in vocab.keys():\n",
        "      res_vocab[\"key\"] = 0\n",
        "\n",
        "    for key in res_vocab.keys():\n",
        "      try:\n",
        "        value = df[key]\n",
        "        res_vocab[key] = value\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "    return res_vocab\n",
        "  \n",
        "  def maprange(self, a, b, s):\n",
        "    \"\"\"\n",
        "    Maps the number s from range a = [a1, a2] to range b = [b1, b2]\n",
        "    \"\"\"\n",
        "    # Source: https://rosettacode.org/wiki/Map_range#Python\n",
        "    (a1, a2), (b1, b2) = a, b\n",
        "    return  b1 + ((s - a1) * (b2 - b1) / (a2 - a1))\n",
        "  \n",
        "  def _compute_average_sentiment_degree(self, *args):\n",
        "    \"\"\"\n",
        "    Assumption: all arguments in args are dictionaries containing the same keys\n",
        "    and a numbers as value.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Dict\n",
        "      average of the sentiment degree across dictionaries for each word\n",
        "    \n",
        "    Example\n",
        "    -------\n",
        "    we have two dictionaries that give a sentiment degree to words:\n",
        "    a = {\"good\": 0.9, \"bad\": 0.7}\n",
        "    b = {\"good\": 0.5, \"bad\": 0.1}\n",
        "\n",
        "    result = {\"good\": 0.7, \"bad\": 0.4}\n",
        "    \"\"\"\n",
        "    n_args = len(args)\n",
        "    res = {}\n",
        "    for arg in args:\n",
        "      for key in arg.keys():\n",
        "        try:\n",
        "          res[key] += arg[key] # / n_args\n",
        "        except KeyError:\n",
        "          res[key] = arg[key] # / n_args\n",
        "    \n",
        "    return res\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    item = self.data[index]\n",
        "    label = self.targets[index]\n",
        "    gold_word = self.wl_gold_av[index]\n",
        "    gold_sent = self.sl_gold_av[index]\n",
        "    return (item, label, gold_word, gold_sent)\n",
        "\n",
        "corpus = MovieReviewsCorpusLBSA()\n",
        "ds = MovieReviewsDatasetLBSA(corpus)\n",
        "print(type(ds.sl_gold_av[1]))"
      ],
      "metadata": {
        "id": "8lGBLNBxo4Jv",
        "outputId": "ecb29957-55b8-4d72-83e2-3a7730415f9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  return func(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand:\n",
        "- If it is better to introduce intermediate supervision\n",
        "\n",
        "- If it is better to use one hot encoding for the output\n",
        "\n",
        "- If I intepreted well the word-loss"
      ],
      "metadata": {
        "id": "IT_UVsevkmNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLBSA(BiLSTMAttention):\n",
        "    # Lexicon Based Supervised Attention model (LBSA) inspired by the following paper: https://aclanthology.org/C18-1074.pdf\n",
        "    def __init__(self, embedding_matrix, device=\"cuda\", input_size=300,\n",
        "                 hidden_size=128, context_size = 150, output_size=2):\n",
        "\n",
        "        super(EncoderLBSA, self).__init__(embedding_matrix, device, input_size, hidden_size, context_size, output_size)\n",
        "\n",
        "    # TODO: Pass the part inside for to super.forward()  \n",
        "    def forward(self, x):\n",
        "      att = []\n",
        "      res = []\n",
        "      for i, doc in enumerate(x):\n",
        "        doc = doc.to(self.device)\n",
        "        batch_size = doc.batch_sizes[0].item()\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        doc = self.simple_elementwise_apply(self.embedding, doc)\n",
        "\n",
        "        out, _ = self.lstm(doc, hidden)\n",
        "        out, input_sizes = pad_packed_sequence(out, batch_first=True)\n",
        "        # n_sents, n_words_per_sent, hidden_size * 2 (since is bilstm)\n",
        "\n",
        "\n",
        "        attention_values = torch.tanh(self.attention(out))\n",
        "        # n_sents, n_words_per_sent, context_size\n",
        "\n",
        "        attention_weights = torch.softmax(attention_values.matmul(self.history), dim = 1).unsqueeze(1)\n",
        "        # n_sents, n_words_per_sent\n",
        "\n",
        "        out = torch.sum(attention_weights.matmul(out), dim = 1)\n",
        "        # n_sents, hidden*2\n",
        "        \n",
        "        attention_weights = attention_weights.squeeze(dim=1)\n",
        "\n",
        "        att.append([sent[:input_sizes[idx]] for idx, sent in enumerate(attention_weights)])\n",
        "\n",
        "        res.append(out)\n",
        "      # n_doc, seq_lengths, hidden * 2\n",
        "      return res, att"
      ],
      "metadata": {
        "id": "k_dniRPY5q2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sortLBSA(X, w_gold, s_gold):\n",
        "\n",
        "  sentence_lengths = [np.array([sent.size(dim=0) for sent in doc]) for doc in X]\n",
        "  indexes = [np.argsort(doc) for doc in sentence_lengths]\n",
        "  indexes = [el.tolist() for el in indexes]\n",
        "\n",
        "  X_sorted = [[doc[idx2] for idx2 in indexes[idx]][::-1] for idx, doc in enumerate(X)]\n",
        "  w_gold = [[doc[idx2] for idx2 in indexes[idx]][::-1] for idx, doc in enumerate(w_gold)]\n",
        "  s_gold = [torch.tensor([doc[idx2] for idx2 in indexes[idx]][::-1]) for idx, doc in enumerate(s_gold)]\n",
        "  sentence_lengths = [[doc[idx2] for idx2 in indexes[idx]][::-1] for idx, doc in enumerate(sentence_lengths)]\n",
        "\n",
        "  return X_sorted, w_gold, s_gold, sentence_lengths, indexes\n",
        "\n",
        "def padLBSA(batch, max_sizes):\n",
        "    pad = torch.tensor([-1])\n",
        "    for idx1, doc in enumerate(batch):\n",
        "      for idx2, sent in enumerate(doc):\n",
        "        remaining = max_sizes[idx1] - sent.size(dim = 0)\n",
        "        batch[idx1][idx2] = torch.cat((sent, pad.repeat(remaining)), dim = 0)\n",
        "    return batch\n",
        "\n",
        "def to_tensorLBSA(batch, max_sizes):\n",
        "  res = []\n",
        "  for idx, doc in enumerate(batch):\n",
        "    buff = torch.zeros(len(doc), max_sizes[idx], dtype=torch.int32)\n",
        "    for idx2, sent in enumerate(doc):\n",
        "      buff[idx2] = sent\n",
        "\n",
        "    res.append(buff)\n",
        "  return res\n",
        "\n",
        "def collateLBSA(batch):\n",
        "  X, Y, w_gold, s_gold = list(zip(*batch))\n",
        "\n",
        "  X, w_gold, s_gold, sentence_lengths, indexes = sortLBSA(X, w_gold, s_gold)\n",
        "  # can take doc[0] since senetence_lengths is sorted\n",
        "  max_sizes = [doc[0] for doc in sentence_lengths]\n",
        "\n",
        "  # Pad tensor each element\n",
        "  X = padLBSA(X, max_sizes)\n",
        "  # Transform the batch to a tensor\n",
        "  X = to_tensorLBSA(X, max_sizes)\n",
        "\n",
        "  # Return the padded sequence object\n",
        "  X = [pack_padded_sequence(doc, sentence_lengths[idx], batch_first=True) for idx, doc in enumerate(X)]\n",
        "  return X, Y, w_gold, s_gold, indexes"
      ],
      "metadata": {
        "id": "JyjRmkGAIu94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def element_wise_log_loss(out, labels):\n",
        "  res = - out.log().mul(labels).sum(dim=0)\n",
        "  return res\n",
        "\n",
        "def loss_LBSA(outputs, targets, mu_w = 0.001, mu_s = 0.05):\n",
        "  dec_output, w_att, s_att = outputs\n",
        "  target, w_gold, s_gold = targets\n",
        "\n",
        "  total_loss = 0\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "\n",
        "  total_loss += ce(dec_output, target)\n",
        "\n",
        "  w_loss = torch.mean(torch.tensor([\n",
        "    torch.sum(torch.tensor([\n",
        "        element_wise_log_loss(w_att[idx1][idx2], sent) for idx2, sent in enumerate(doc)\n",
        "    ])) * mu_w for idx1, doc in enumerate(w_gold)\n",
        "  ]))\n",
        "  total_loss += w_loss\n",
        "\n",
        "  s_loss = torch.mean(torch.tensor([\n",
        "      element_wise_log_loss(s_att[idx], doc) * mu_s for idx, doc in enumerate(s_gold)\n",
        "  ]))\n",
        "  total_loss += s_loss\n",
        "\n",
        "  return total_loss"
      ],
      "metadata": {
        "id": "VXw9lvmaWM3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_step_LBSA(encoder, decoder, data_loader, optimizer, cost_function, device = 'cuda'):\n",
        "  cumulative_loss = 0\n",
        "  cumulative_accuracy = 0\n",
        "  samples = 0\n",
        "\n",
        "  encoder.train()\n",
        "  decoder.train()\n",
        "\n",
        "  for batch_idx, (inputs, target, w_gold, s_gold, _) in enumerate(data_loader):\n",
        "    \n",
        "    in_size = len(target)\n",
        "\n",
        "    enc_output, w_att = encoder(inputs)\n",
        "    \n",
        "    batch = [(el, target[idx]) for idx, el in enumerate(enc_output)]\n",
        "\n",
        "    dec_input, target, indexes = collate(batch)\n",
        "    \n",
        "    s_gold = [s_gold[idx] for idx in indexes][::-1]\n",
        "\n",
        "    target = target.to(device)\n",
        "    for idx1, doc in enumerate(w_gold):\n",
        "      for idx2, sent in enumerate(doc):\n",
        "        w_gold[idx1][idx2] = sent.to(device)\n",
        "    \n",
        "    for idx, doc in enumerate(s_gold):\n",
        "       s_gold[idx] = doc.to(device)\n",
        "    \n",
        "\n",
        "    dec_output, s_att = decoder(dec_input)\n",
        "\n",
        "    outputs = (dec_output, w_att, s_att)\n",
        "    targets = (target, w_gold, s_gold)\n",
        "\n",
        "    loss = cost_function(outputs, targets)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    samples += in_size\n",
        "    cumulative_loss += loss.item()\n",
        "    _, predicted = dec_output.max(dim=1)\n",
        "\n",
        "    cumulative_accuracy += predicted.eq(target).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, (cumulative_accuracy/samples)*100"
      ],
      "metadata": {
        "id": "yZF4uo99VKsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step_LBSA(encoder, decoder, data_loader, cost_function, device = 'cuda'):\n",
        "  cumulative_loss = 0\n",
        "  cumulative_accuracy = 0\n",
        "  samples = 0\n",
        "\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for batch_idx, (inputs, target, w_gold, s_gold, _) in enumerate(data_loader):\n",
        "      in_size = len(target)\n",
        "\n",
        "      enc_output, w_att = encoder(inputs)\n",
        "      \n",
        "      batch = [(el, target[idx]) for idx, el in enumerate(enc_output)]\n",
        "\n",
        "      dec_input, target, indexes = collate(batch)\n",
        "\n",
        "      s_gold = [s_gold[idx] for idx in indexes][::-1]\n",
        "      # Not sorting also w_gold becuse in the encoder, documents don't get shuffled\n",
        "\n",
        "      target = target.to(device)\n",
        "      for idx1, doc in enumerate(w_gold):\n",
        "        for idx2, sent in enumerate(doc):\n",
        "          w_gold[idx1][idx2] = sent.to(device)\n",
        "    \n",
        "      for idx, doc in enumerate(s_gold):\n",
        "        s_gold[idx] = doc.to(device)\n",
        "\n",
        "      dec_output, s_att = decoder(dec_input)\n",
        "\n",
        "      outputs = (dec_output, w_att, s_att)\n",
        "      targets = (target, w_gold, s_gold)\n",
        "\n",
        "      loss = cost_function(outputs, targets)\n",
        "      \n",
        "      samples += in_size\n",
        "      cumulative_loss += loss.item()\n",
        "      _, predicted = dec_output.max(dim=1)\n",
        "\n",
        "      cumulative_accuracy += predicted.eq(target).sum().item()\n",
        "\n",
        "    return cumulative_loss/samples, (cumulative_accuracy/samples)*100"
      ],
      "metadata": {
        "id": "RpyI0qRvC0cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sorting must be a problem, otherwise word_level attention doesn't get the correct supervision.\n",
        "Same goes for sentences"
      ],
      "metadata": {
        "id": "ntMCKJDtuEnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_step_LBSA_new(encoder, decoder, data_loader, optimizer, cost_function, device = 'cuda'):\n",
        "  cumulative_loss = 0\n",
        "  cumulative_accuracy = 0\n",
        "  samples = 0\n",
        "\n",
        "  encoder.train()\n",
        "  decoder.train()\n",
        "\n",
        "  for batch_idx, (inputs, target, w_gold, s_gold, sent_indexes) in enumerate(data_loader):\n",
        "    \n",
        "    in_size = len(target)\n",
        "\n",
        "    enc_output, w_att = encoder(inputs)\n",
        "    # Sorting the sentences of the encoder to their original position\n",
        "    # Inverting the output because indexes are in ascending order, output is in descending\n",
        "    enc_output = [torch.flip(enc_output[doc_idx], dims = [0]) for doc_idx, _ in enumerate(enc_output)]\n",
        "    w_att = [w_att[doc_idx][::-1] for doc_idx, _ in enumerate(w_att)]\n",
        "    # Using argsort on the indexes reverses the previous argsort\n",
        "    inverted_indexes = [np.argsort(np.array(doc)) for doc in sent_indexes]\n",
        "    inverted_indexes = [el.tolist() for el in inverted_indexes]\n",
        "    # Sort the sentences with original sorting:\n",
        "    # n_doc, n_sents, hidden*2\n",
        "\n",
        "    enc_output = [enc_output[doc_idx][sent_idx] for doc_idx, sent_idx in enumerate(inverted_indexes)]\n",
        "    w_att = [[doc[idx2] for idx2 in inverted_indexes[idx]] for idx, doc in enumerate(w_att)]\n",
        "\n",
        "\n",
        "    # for i, doc in enumerate(enc_output):\n",
        "        # for j, sent in enumerate(doc):\n",
        "          # enc_output[i][j] = sent.cpu()\n",
        "    \n",
        "    batch = [(el, target[idx]) for idx, el in enumerate(enc_output)]\n",
        "\n",
        "    dec_input, target, indexes = collate(batch)\n",
        "    \n",
        "    # s_gold = [s_gold[idx] for idx in indexes][::-1]\n",
        "    target = target.to(device)\n",
        "    for idx1, doc in enumerate(w_gold):\n",
        "      for idx2, sent in enumerate(doc):\n",
        "        w_gold[idx1][idx2] = sent.to(device)\n",
        "    \n",
        "    for idx, doc in enumerate(s_gold):\n",
        "       s_gold[idx] = doc.to(device)\n",
        "    \n",
        "\n",
        "    dec_output, s_att = decoder(dec_input)\n",
        "\n",
        "    dec_output = torch.flip(dec_output, dims = [0])\n",
        "    s_att = s_att[::-1]\n",
        "    target = torch.flip(target, dims = [0])\n",
        "\n",
        "\n",
        "    inverted_indexes = np.argsort(np.array(indexes))\n",
        "    inverted_indexes = inverted_indexes.tolist()\n",
        "    # Sort the sentences with original sorting:\n",
        "    # n_doc, n_sents, hidden*2\n",
        "    dec_output = dec_output[inverted_indexes]\n",
        "    s_att = [s_att[idx] for idx in inverted_indexes]\n",
        "    target = target[inverted_indexes]\n",
        "\n",
        "\n",
        "    outputs = (dec_output, w_att, s_att)\n",
        "    targets = (target, w_gold, s_gold)\n",
        "    \n",
        "    loss = cost_function(outputs, targets)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    samples += in_size\n",
        "    cumulative_loss += loss.item()\n",
        "    _, predicted = dec_output.max(dim=1)\n",
        "\n",
        "    cumulative_accuracy += predicted.eq(target).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, (cumulative_accuracy/samples)*100"
      ],
      "metadata": {
        "id": "RN2AM7tLgIDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step_LBSA_new(encoder, decoder, data_loader, cost_function, device = 'cuda'):\n",
        "  cumulative_loss = 0\n",
        "  cumulative_accuracy = 0\n",
        "  samples = 0\n",
        "\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for batch_idx, (inputs, target, w_gold, s_gold, sent_indexes) in enumerate(data_loader):\n",
        "      in_size = len(target)\n",
        "\n",
        "      enc_output, w_att = encoder(inputs)\n",
        "\n",
        "      # First flip (go to ascending order)\n",
        "      enc_output = [torch.flip(enc_output[doc_idx], dims = [0]) for doc_idx, _ in enumerate(enc_output)]\n",
        "      w_att = [w_att[doc_idx][::-1] for doc_idx, _ in enumerate(w_att)]\n",
        "\n",
        "      # Second take indexes for getting the original positions\n",
        "      # Using argsort on the indexes reverses the previous argsort\n",
        "      inverted_indexes = [np.argsort(np.array(doc)) for doc in sent_indexes]\n",
        "      inverted_indexes = [el.tolist() for el in inverted_indexes]\n",
        "\n",
        "      # Third Sort the sentences with original sorting:\n",
        "      # n_doc, n_sents, hidden*2\n",
        "      enc_output = [enc_output[doc_idx][sent_idx] for doc_idx, sent_idx in enumerate(inverted_indexes)]\n",
        "      w_att = [[doc[idx2] for idx2 in inverted_indexes[idx]] for idx, doc in enumerate(w_att)]\n",
        "      \n",
        "      batch = [(el, target[idx]) for idx, el in enumerate(enc_output)]\n",
        "\n",
        "      dec_input, target, indexes = collate(batch)\n",
        "\n",
        "      # s_gold = [s_gold[idx] for idx in indexes][::-1]\n",
        "      # Not sorting also w_gold becuse in the encoder, documents don't get shuffled inside\n",
        "\n",
        "      target = target.to(device)\n",
        "      for idx1, doc in enumerate(w_gold):\n",
        "        for idx2, sent in enumerate(doc):\n",
        "          w_gold[idx1][idx2] = sent.to(device)\n",
        "    \n",
        "      for idx, doc in enumerate(s_gold):\n",
        "        s_gold[idx] = doc.to(device)\n",
        "\n",
        "      dec_output, s_att = decoder(dec_input)\n",
        "\n",
        "\n",
        "      dec_output = torch.flip(dec_output, dims = [0])\n",
        "      s_att = s_att[::-1]\n",
        "      target = torch.flip(target, dims = [0])\n",
        "\n",
        "      inverted_indexes = np.argsort(np.array(indexes))\n",
        "      inverted_indexes = inverted_indexes.tolist()\n",
        "      # Sort the sentences with original sorting:\n",
        "      # n_doc, n_sents, hidden*2\n",
        "      dec_output = dec_output[inverted_indexes]\n",
        "      s_att = [s_att[idx] for idx in inverted_indexes]\n",
        "      target = target[inverted_indexes]\n",
        "\n",
        "      outputs = (dec_output, w_att, s_att)\n",
        "      targets = (target, w_gold, s_gold)\n",
        "\n",
        "      loss = cost_function(outputs, targets)\n",
        "      \n",
        "      samples += in_size\n",
        "      cumulative_loss += loss.item()\n",
        "      _, predicted = dec_output.max(dim=1)\n",
        "\n",
        "      cumulative_accuracy += predicted.eq(target).sum().item()\n",
        "\n",
        "    return cumulative_loss/samples, (cumulative_accuracy/samples)*100"
      ],
      "metadata": {
        "id": "kEf6kIOghmBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "from torch.optimlr_scheduler import ExponentialLR\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def main_LBSA(train_loader, test_loader, embedding_matrix, device = \"cuda\", epochs = 10):\n",
        "\n",
        "  encoder = EncoderLBSA(embedding_matrix = embedding_matrix, device = device, input_size=300, hidden_size=100).to(device)\n",
        "  decoder = BiLSTMAttention(device = device, input_size=100*2, context_size = 150).to(device)\n",
        "\n",
        "  optimizer = Adam(list(encoder.parameters()) + list(decoder.parameters()), 0.001, betas = (0.9, 0.999), amsgrad=True)\n",
        "  scheduler = ExponentialLR(optimizer, 0.8)\n",
        "\n",
        "  cost_function = loss_LBSA\n",
        "\n",
        "  for e in range(epochs):\n",
        "    print(f\"epoch {e}:\")\n",
        "    train_loss, train_accuracy = training_step_LBSA(encoder, decoder, train_loader, optimizer, cost_function, device)\n",
        "    print(f\"Training loss: {train_loss} \\n Training accuracy: {train_accuracy}\")\n",
        "    test_loss, test_accuracy = test_step_LBSA(encoder, decoder, test_loader, cost_function, device)\n",
        "    print(f\"Test loss: {test_loss} \\n Test accuracy: {test_accuracy}\")\n",
        "    print(\"------------------------------------------------------------------\")\n",
        "    scheduler.step()\n",
        "  \n",
        "  _, test_accuracy = test_step(encoder, decoder, test_loader, cost_function, device)\n",
        "\n",
        "  return test_accuracy\n"
      ],
      "metadata": {
        "id": "3Xzpaa7IDN9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_vectors = GloVe(name='840B', dim=300, cache = \"/content/gdrive/My Drive/nlu-project/.vector_cache\")"
      ],
      "metadata": {
        "id": "hgNE3lxXrW4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mr_pipeline = MRPipelineLBSA()\n",
        "corpus = MovieReviewsCorpusLBSA(mr_pipeline)"
      ],
      "metadata": {
        "id": "Xu7rZw-mrqke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = corpus.get_embedding_matrix(global_vectors, 300)\n",
        "# ds = corpus.get_indexed_corpus()"
      ],
      "metadata": {
        "id": "0TtoFzYDsGHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MovieReviewsDatasetLBSA(corpus)\n",
        "train_loader, test_loader = get_data(128, dataset, collate_fn=collateLBSA)"
      ],
      "metadata": {
        "id": "QQf9eKAqsIfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eDrwHvOIEsl2",
        "outputId": "18695025-5e66-4ee4-dc80-7d920ea160ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0:\n",
            "Training loss: 0.007855756767094135 \n",
            " Training accuracy: 71.375\n",
            "Test loss: 0.011151814460754394 \n",
            " Test accuracy: 64.5\n",
            "------------------------------------------------------------------\n",
            "epoch 1:\n",
            "Training loss: 0.0061226640641689305 \n",
            " Training accuracy: 86.4375\n",
            "Test loss: 0.011029932498931885 \n",
            " Test accuracy: 83.5\n",
            "------------------------------------------------------------------\n",
            "epoch 2:\n",
            "Training loss: 0.004967164918780327 \n",
            " Training accuracy: 94.625\n",
            "Test loss: 0.010530393123626709 \n",
            " Test accuracy: 65.5\n",
            "------------------------------------------------------------------\n",
            "epoch 3:\n",
            "Training loss: 0.004253526143729687 \n",
            " Training accuracy: 99.1875\n",
            "Test loss: 0.009678695350885391 \n",
            " Test accuracy: 76.25\n",
            "------------------------------------------------------------------\n",
            "epoch 4:\n",
            "Training loss: 0.0039981334283947945 \n",
            " Training accuracy: 99.9375\n",
            "Test loss: 0.008642805218696594 \n",
            " Test accuracy: 83.0\n",
            "------------------------------------------------------------------\n",
            "epoch 5:\n",
            "Training loss: 0.00396275719627738 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.008724945336580277 \n",
            " Test accuracy: 83.5\n",
            "------------------------------------------------------------------\n",
            "epoch 6:\n",
            "Training loss: 0.004001382309943438 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.008569831550121308 \n",
            " Test accuracy: 86.25\n",
            "------------------------------------------------------------------\n",
            "epoch 7:\n",
            "Training loss: 0.004018882885575294 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.008886046409606933 \n",
            " Test accuracy: 86.5\n",
            "------------------------------------------------------------------\n",
            "epoch 8:\n",
            "Training loss: 0.004022521916776895 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.008938222825527191 \n",
            " Test accuracy: 86.5\n",
            "------------------------------------------------------------------\n",
            "epoch 9:\n",
            "Training loss: 0.004025476649403572 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.009016947448253631 \n",
            " Test accuracy: 86.25\n",
            "------------------------------------------------------------------\n",
            "epoch 10:\n",
            "Training loss: 0.004029160048812628 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.0090603107213974 \n",
            " Test accuracy: 86.25\n",
            "------------------------------------------------------------------\n",
            "epoch 11:\n",
            "Training loss: 0.004033114183694124 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.009106426388025285 \n",
            " Test accuracy: 86.25\n",
            "------------------------------------------------------------------\n",
            "epoch 12:\n",
            "Training loss: 0.004038411937654018 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.009149345010519028 \n",
            " Test accuracy: 86.25\n",
            "------------------------------------------------------------------\n",
            "epoch 13:\n",
            "Training loss: 0.004043450467288494 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.009198010116815567 \n",
            " Test accuracy: 86.0\n",
            "------------------------------------------------------------------\n",
            "epoch 14:\n",
            "Training loss: 0.004046990908682347 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.009237817376852036 \n",
            " Test accuracy: 86.25\n",
            "------------------------------------------------------------------\n",
            "epoch 15:\n",
            "Training loss: 0.004049482215195894 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.00928129643201828 \n",
            " Test accuracy: 86.0\n",
            "------------------------------------------------------------------\n",
            "epoch 16:\n",
            "Training loss: 0.00405236553400755 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.00930849924683571 \n",
            " Test accuracy: 86.25\n",
            "------------------------------------------------------------------\n",
            "epoch 17:\n",
            "Training loss: 0.004056372959166765 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.009334184378385544 \n",
            " Test accuracy: 86.25\n",
            "------------------------------------------------------------------\n",
            "epoch 18:\n",
            "Training loss: 0.004059367571026087 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.00936876878142357 \n",
            " Test accuracy: 86.0\n",
            "------------------------------------------------------------------\n",
            "epoch 19:\n",
            "Training loss: 0.0040619662590324875 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.009404010772705078 \n",
            " Test accuracy: 86.0\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-10b4e8fb183a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Da fare una collate nuova direttamente che non vada a toccare i tensori esistenti.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Oppure ragionare un attimo.... servono davvero i gradient per l'input? O posso fare il detach?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_LBSA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Overall accuracy: {accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Folds statistics:\\n----------------\\n - mean: {mean} \\n - standard deviation: {std}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-92c789ad4d20>\u001b[0m in \u001b[0;36mmain_LBSA\u001b[0;34m(train_loader, test_loader, embedding_matrix, device, epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------------------------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: test_step() takes from 3 to 4 positional arguments but 5 were given"
          ]
        }
      ],
      "source": [
        "# 87.3, 86.75 e qualcosa - 88.25\n",
        "# TODO: linear layer nel decoder,\n",
        "#       Sentiment degree come sommatoria invece che somma\n",
        "train_loader, test_loader = get_data(128, dataset, collate_fn=collateLBSA)\n",
        "# Da fare una collate nuova direttamente che non vada a toccare i tensori esistenti.\n",
        "# Oppure ragionare un attimo.... servono davvero i gradient per l'input? O posso fare il detach?\n",
        "accuracy, mean, std = main_LBSA(train_loader, test_loader, embedding_matrix, device = \"cuda\", epochs = 20)\n",
        "print(f\"Overall accuracy: {accuracy}\")\n",
        "print(f\"Folds statistics:\\n----------------\\n - mean: {mean} \\n - standard deviation: {std}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pBBa_vvYSnL"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "tensor([1315, 1222, 1011, 1010,  936,  862,  814,  807,  807,  764,  718,  515,\n",
        "         495,  388,  344,  323])\n",
        "tensor([1617, 1361, 1311, 1178, 1081, 1068,  958,  941,  925,  768,  688,  619,\n",
        "         604,  573,  484,  405])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Af9ORg9pFKe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P67fhfYpSZA"
      },
      "source": [
        "# First try to parse phrases documet-wise, then try to parse each phrase of a document separately, and then aggregate the result (if there are more positive phrases then positive, otherwise negative). (Try also to give a weight depending on the number of sentiment lexemes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mK4Rmfr4ziT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('nlu')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "e0262c2e7a08424d65c968f8ecfc5afb6b5a99089f86fd0fa27478ea619b0ef2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}