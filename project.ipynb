{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zinni98/Sentiment-analysis-project/blob/lbsa/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NBg5KtW5AMy"
      },
      "source": [
        "## Polarity Classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8msH_nw3rf39",
        "outputId": "74e515ea-2e3f-4611-ed52-10329c954b12"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/gdrive/My Drive/nlu-project\")"
      ],
      "metadata": {
        "id": "vdSs1gS1rgh_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oGXvFNN46OT"
      },
      "source": [
        "### Get the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvHgFZJe4_Xq",
        "outputId": "3b8ff4e4-b986-409f-8f10-934d0995f5bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data] Downloading package subjectivity to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "import torch\n",
        "from nltk.corpus import movie_reviews\n",
        "import numpy as np\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "nltk.download(\"movie_reviews\")\n",
        "nltk.download(\"subjectivity\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"sentiwordnet\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fglEQLVLtc9C"
      },
      "source": [
        "## Exploratory analysis\n",
        "\n",
        "Firstly let's explore the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dKetqTKrZFE",
        "outputId": "bb903a72-4165-4671-9ee3-d5c2dfad8106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of each part of the dataset:\n",
            " - pos: 1000 \n",
            " - neg: 1000\n",
            "[[['films', 'adapted', 'from', 'comic', 'books', 'have', 'had', 'plenty', 'of', 'success', ',', 'whether', 'they', \"'\", 're', 'about', 'superheroes', '(', 'batman', ',', 'superman', ',', 'spawn', ')', ',', 'or', 'geared', 'toward', 'kids', '(', 'casper', ')', 'or', 'the', 'arthouse', 'crowd', '(', 'ghost', 'world', ')', ',', 'but', 'there', \"'\", 's', 'never', 'really', 'been', 'a', 'comic', 'book', 'like', 'from', 'hell', 'before', '.'], ['for', 'starters', ',', 'it', 'was', 'created', 'by', 'alan', 'moore', '(', 'and', 'eddie', 'campbell', ')', ',', 'who', 'brought', 'the', 'medium', 'to', 'a', 'whole', 'new', 'level', 'in', 'the', 'mid', \"'\", '80s', 'with', 'a', '12', '-', 'part', 'series', 'called', 'the', 'watchmen', '.'], ['to', 'say', 'moore', 'and', 'campbell', 'thoroughly', 'researched', 'the', 'subject', 'of', 'jack', 'the', 'ripper', 'would', 'be', 'like', 'saying', 'michael', 'jackson', 'is', 'starting', 'to', 'look', 'a', 'little', 'odd', '.'], ['the', 'book', '(', 'or', '\"', 'graphic', 'novel', ',', '\"', 'if', 'you', 'will', ')', 'is', 'over', '500', 'pages', 'long', 'and', 'includes', 'nearly', '30', 'more', 'that', 'consist', 'of', 'nothing', 'but', 'footnotes', '.'], ['in', 'other', 'words', ',', 'don', \"'\", 't', 'dismiss', 'this', 'film', 'because', 'of', 'its', 'source', '.'], ['if', 'you', 'can', 'get', 'past', 'the', 'whole', 'comic', 'book', 'thing', ',', 'you', 'might', 'find', 'another', 'stumbling', 'block', 'in', 'from', 'hell', \"'\", 's', 'directors', ',', 'albert', 'and', 'allen', 'hughes', '.'], ['getting', 'the', 'hughes', 'brothers', 'to', 'direct', 'this', 'seems', 'almost', 'as', 'ludicrous', 'as', 'casting', 'carrot', 'top', 'in', ',', 'well', ',', 'anything', ',', 'but', 'riddle', 'me', 'this', ':', 'who', 'better', 'to', 'direct', 'a', 'film', 'that', \"'\", 's', 'set', 'in', 'the', 'ghetto', 'and', 'features', 'really', 'violent', 'street', 'crime', 'than', 'the', 'mad', 'geniuses', 'behind', 'menace', 'ii', 'society', '?'], ['the', 'ghetto', 'in', 'question', 'is', ',', 'of', 'course', ',', 'whitechapel', 'in', '1888', 'london', \"'\", 's', 'east', 'end', '.'], ['it', \"'\", 's', 'a', 'filthy', ',', 'sooty', 'place', 'where', 'the', 'whores', '(', 'called', '\"', 'unfortunates', '\"', ')', 'are', 'starting', 'to', 'get', 'a', 'little', 'nervous', 'about', 'this', 'mysterious', 'psychopath', 'who', 'has', 'been', 'carving', 'through', 'their', 'profession', 'with', 'surgical', 'precision', '.'], ['when', 'the', 'first', 'stiff', 'turns', 'up', ',', 'copper', 'peter', 'godley', '(', 'robbie', 'coltrane', ',', 'the', 'world', 'is', 'not', 'enough', ')', 'calls', 'in', 'inspector', 'frederick', 'abberline', '(', 'johnny', 'depp', ',', 'blow', ')', 'to', 'crack', 'the', 'case', '.'], ['abberline', ',', 'a', 'widower', ',', 'has', 'prophetic', 'dreams', 'he', 'unsuccessfully', 'tries', 'to', 'quell', 'with', 'copious', 'amounts', 'of', 'absinthe', 'and', 'opium', '.'], ['upon', 'arriving', 'in', 'whitechapel', ',', 'he', 'befriends', 'an', 'unfortunate', 'named', 'mary', 'kelly', '(', 'heather', 'graham', ',', 'say', 'it', 'isn', \"'\", 't', 'so', ')', 'and', 'proceeds', 'to', 'investigate', 'the', 'horribly', 'gruesome', 'crimes', 'that', 'even', 'the', 'police', 'surgeon', 'can', \"'\", 't', 'stomach', '.'], ['i', 'don', \"'\", 't', 'think', 'anyone', 'needs', 'to', 'be', 'briefed', 'on', 'jack', 'the', 'ripper', ',', 'so', 'i', 'won', \"'\", 't', 'go', 'into', 'the', 'particulars', 'here', ',', 'other', 'than', 'to', 'say', 'moore', 'and', 'campbell', 'have', 'a', 'unique', 'and', 'interesting', 'theory', 'about', 'both', 'the', 'identity', 'of', 'the', 'killer', 'and', 'the', 'reasons', 'he', 'chooses', 'to', 'slay', '.'], ['in', 'the', 'comic', ',', 'they', 'don', \"'\", 't', 'bother', 'cloaking', 'the', 'identity', 'of', 'the', 'ripper', ',', 'but', 'screenwriters', 'terry', 'hayes', '(', 'vertical', 'limit', ')', 'and', 'rafael', 'yglesias', '(', 'les', 'mis', '?'], ['rables', ')', 'do', 'a', 'good', 'job', 'of', 'keeping', 'him', 'hidden', 'from', 'viewers', 'until', 'the', 'very', 'end', '.'], ['it', \"'\", 's', 'funny', 'to', 'watch', 'the', 'locals', 'blindly', 'point', 'the', 'finger', 'of', 'blame', 'at', 'jews', 'and', 'indians', 'because', ',', 'after', 'all', ',', 'an', 'englishman', 'could', 'never', 'be', 'capable', 'of', 'committing', 'such', 'ghastly', 'acts', '.'], ['and', 'from', 'hell', \"'\", 's', 'ending', 'had', 'me', 'whistling', 'the', 'stonecutters', 'song', 'from', 'the', 'simpsons', 'for', 'days', '(', '\"', 'who', 'holds', 'back', 'the', 'electric', 'car', '/', 'who', 'made', 'steve', 'guttenberg', 'a', 'star', '?', '\"'], [')', '.'], ['don', \"'\", 't', 'worry', '-', 'it', \"'\", 'll', 'all', 'make', 'sense', 'when', 'you', 'see', 'it', '.'], ['now', 'onto', 'from', 'hell', \"'\", 's', 'appearance', ':', 'it', \"'\", 's', 'certainly', 'dark', 'and', 'bleak', 'enough', ',', 'and', 'it', \"'\", 's', 'surprising', 'to', 'see', 'how', 'much', 'more', 'it', 'looks', 'like', 'a', 'tim', 'burton', 'film', 'than', 'planet', 'of', 'the', 'apes', 'did', '(', 'at', 'times', ',', 'it', 'seems', 'like', 'sleepy', 'hollow', '2', ')', '.'], ['the', 'print', 'i', 'saw', 'wasn', \"'\", 't', 'completely', 'finished', '(', 'both', 'color', 'and', 'music', 'had', 'not', 'been', 'finalized', ',', 'so', 'no', 'comments', 'about', 'marilyn', 'manson', ')', ',', 'but', 'cinematographer', 'peter', 'deming', '(', 'don', \"'\", 't', 'say', 'a', 'word', ')', 'ably', 'captures', 'the', 'dreariness', 'of', 'victorian', '-', 'era', 'london', 'and', 'helped', 'make', 'the', 'flashy', 'killing', 'scenes', 'remind', 'me', 'of', 'the', 'crazy', 'flashbacks', 'in', 'twin', 'peaks', ',', 'even', 'though', 'the', 'violence', 'in', 'the', 'film', 'pales', 'in', 'comparison', 'to', 'that', 'in', 'the', 'black', '-', 'and', '-', 'white', 'comic', '.'], ['oscar', 'winner', 'martin', 'childs', \"'\", '(', 'shakespeare', 'in', 'love', ')', 'production', 'design', 'turns', 'the', 'original', 'prague', 'surroundings', 'into', 'one', 'creepy', 'place', '.'], ['even', 'the', 'acting', 'in', 'from', 'hell', 'is', 'solid', ',', 'with', 'the', 'dreamy', 'depp', 'turning', 'in', 'a', 'typically', 'strong', 'performance', 'and', 'deftly', 'handling', 'a', 'british', 'accent', '.'], ['ians', 'holm', '(', 'joe', 'gould', \"'\", 's', 'secret', ')', 'and', 'richardson', '(', '102', 'dalmatians', ')', 'log', 'in', 'great', 'supporting', 'roles', ',', 'but', 'the', 'big', 'surprise', 'here', 'is', 'graham', '.'], ['i', 'cringed', 'the', 'first', 'time', 'she', 'opened', 'her', 'mouth', ',', 'imagining', 'her', 'attempt', 'at', 'an', 'irish', 'accent', ',', 'but', 'it', 'actually', 'wasn', \"'\", 't', 'half', 'bad', '.'], ['the', 'film', ',', 'however', ',', 'is', 'all', 'good', '.'], ['2', ':', '00', '-', 'r', 'for', 'strong', 'violence', '/', 'gore', ',', 'sexuality', ',', 'language', 'and', 'drug', 'content']], [['every', 'now', 'and', 'then', 'a', 'movie', 'comes', 'along', 'from', 'a', 'suspect', 'studio', ',', 'with', 'every', 'indication', 'that', 'it', 'will', 'be', 'a', 'stinker', ',', 'and', 'to', 'everybody', \"'\", 's', 'surprise', '(', 'perhaps', 'even', 'the', 'studio', ')', 'the', 'film', 'becomes', 'a', 'critical', 'darling', '.'], ['mtv', 'films', \"'\", '_election', ',', 'a', 'high', 'school', 'comedy', 'starring', 'matthew', 'broderick', 'and', 'reese', 'witherspoon', ',', 'is', 'a', 'current', 'example', '.'], ['did', 'anybody', 'know', 'this', 'film', 'existed', 'a', 'week', 'before', 'it', 'opened', '?'], ['the', 'plot', 'is', 'deceptively', 'simple', '.'], ['george', 'washington', 'carver', 'high', 'school', 'is', 'having', 'student', 'elections', '.'], ['tracy', 'flick', '(', 'reese', 'witherspoon', ')', 'is', 'an', 'over', '-', 'achiever', 'with', 'her', 'hand', 'raised', 'at', 'nearly', 'every', 'question', ',', 'way', ',', 'way', ',', 'high', '.'], ['mr', '.', '\"', 'm', '\"', '(', 'matthew', 'broderick', ')', ',', 'sick', 'of', 'the', 'megalomaniac', 'student', ',', 'encourages', 'paul', ',', 'a', 'popular', '-', 'but', '-', 'slow', 'jock', 'to', 'run', '.'], ['and', 'paul', \"'\", 's', 'nihilistic', 'sister', 'jumps', 'in', 'the', 'race', 'as', 'well', ',', 'for', 'personal', 'reasons', '.'], ['the', 'dark', 'side', 'of', 'such', 'sleeper', 'success', 'is', 'that', ',', 'because', 'expectations', 'were', 'so', 'low', 'going', 'in', ',', 'the', 'fact', 'that', 'this', 'was', 'quality', 'stuff', 'made', 'the', 'reviews', 'even', 'more', 'enthusiastic', 'than', 'they', 'have', 'any', 'right', 'to', 'be', '.'], ['you', 'can', \"'\", 't', 'help', 'going', 'in', 'with', 'the', 'baggage', 'of', 'glowing', 'reviews', ',', 'which', 'is', 'in', 'contrast', 'to', 'the', 'negative', 'baggage', 'that', 'the', 'reviewers', 'were', 'likely', 'to', 'have', '.'], ['_election', ',', 'a', 'good', 'film', ',', 'does', 'not', 'live', 'up', 'to', 'its', 'hype', '.'], ['what', 'makes', '_election_', 'so', 'disappointing', 'is', 'that', 'it', 'contains', 'significant', 'plot', 'details', 'lifted', 'directly', 'from', '_rushmore_', ',', 'released', 'a', 'few', 'months', 'earlier', '.'], ['the', 'similarities', 'are', 'staggering', ':', 'tracy', 'flick', '(', '_election_', ')', 'is', 'the', 'president', 'of', 'an', 'extraordinary', 'number', 'of', 'clubs', ',', 'and', 'is', 'involved', 'with', 'the', 'school', 'play', '.'], ['max', 'fischer', '(', '_rushmore_', ')', 'is', 'the', 'president', 'of', 'an', 'extraordinary', 'number', 'of', 'clubs', ',', 'and', 'is', 'involved', 'with', 'the', 'school', 'play', '.'], ['the', 'most', 'significant', 'tension', 'of', '_election_', 'is', 'the', 'potential', 'relationship', 'between', 'a', 'teacher', 'and', 'his', 'student', '.'], ['the', 'most', 'significant', 'tension', 'of', '_rushmore_', 'is', 'the', 'potential', 'relationship', 'between', 'a', 'teacher', 'and', 'his', 'student', '.'], ['tracy', 'flick', 'is', 'from', 'a', 'single', 'parent', 'home', ',', 'which', 'has', 'contributed', 'to', 'her', 'drive', '.'], ['max', 'fischer', 'is', 'from', 'a', 'single', 'parent', 'home', ',', 'which', 'has', 'contributed', 'to', 'his', 'drive', '.'], ['the', 'male', 'bumbling', 'adult', 'in', '_election_', '(', 'matthew', 'broderick', ')', 'pursues', 'an', 'extramarital', 'affair', ',', 'gets', 'caught', ',', 'and', 'his', 'whole', 'life', 'is', 'ruined', '.'], ['he', 'even', 'gets', 'a', 'bee', 'sting', '.'], ['the', 'male', 'bumbling', 'adult', 'in', '_rushmore_', '(', 'bill', 'murray', ')', 'pursues', 'an', 'extramarital', 'affair', ',', 'gets', 'caught', ',', 'and', 'his', 'whole', 'life', 'is', 'ruined', '.'], ['he', 'gets', 'several', 'bee', 'stings', '.'], ['and', 'so', 'on', '.'], ['what', 'happened', '?'], ['how', 'is', 'it', 'that', 'an', 'individual', 'screenplay', '(', '_rushmore_', ')', 'and', 'a', 'novel', '(', '_election_', ')', 'contain', 'so', 'many', 'significant', 'plot', 'points', ',', 'and', 'yet', 'both', 'films', 'were', 'probably', 'not', 'even', 'aware', 'of', 'each', 'other', ',', 'made', 'from', 'two', 'different', 'studios', ',', 'from', 'a', 'genre', '(', 'the', 'high', 'school', 'geeks', 'revenge', 'movie', ')', 'that', 'hadn', \"'\", 't', 'been', 'fully', 'formed', 'yet', '?'], ['even', 'so', ',', 'the', 'strengths', 'of', '_election_', 'rely', 'upon', 'its', 'fantastic', 'performances', 'from', 'broderick', ',', 'witherspoon', ',', 'and', 'newcomer', 'jessica', 'campbell', ',', 'as', 'paul', \"'\", 's', 'anti', '-', 'social', 'sister', ',', 'tammy', '.'], ['broderick', 'here', 'is', 'playing', 'the', 'mr', '.', 'rooney', 'role', 'from', '_ferris', 'bueller_', ',', 'and', 'he', 'seems', 'to', 'be', 'having', 'the', 'most', 'fun', 'he', \"'\", 's', 'had', 'since', 'then', '.'], ['witherspoon', 'is', 'a', 'revelation', '.'], ['it', \"'\", 's', 'early', 'in', 'the', 'year', ',', 'it', \"'\", 's', 'a', 'comedy', ',', 'and', 'teenagers', 'have', 'little', 'clout', ',', 'but', 'for', 'my', 'money', ',', 'witherspoon', 'deserves', 'an', 'oscar', 'nomination', '.'], ['and', 'once', 'campbell', \"'\", 's', 'character', 'gets', 'going', ',', 'like', 'in', 'her', 'fantastic', 'speech', 'in', 'the', 'gymnasium', ',', 'then', 'you', \"'\", 're', 'won', 'over', '.'], ['one', 'thing', 'that', \"'\", 's', 'been', 'bothering', 'me', 'since', 'i', \"'\", 've', 'seen', 'it', '.'], ['there', 'is', 'an', 'extraordinary', 'amount', 'of', 'sexuality', 'in', 'this', 'film', '.'], ['i', 'suppose', 'that', ',', 'coming', 'from', 'mtv', 'films', ',', 'i', 'should', 'expect', 'no', 'less', '.'], ['.', '.', 'but', 'the', 'film', 'starts', 'off', 'light', 'and', 'airy', ',', 'like', 'a', 'sitcom', '.'], ['as', 'the', 'screws', 'tighten', ',', 'and', 'the', 'tensions', 'mount', ',', 'alexander', 'payne', 'decides', 'to', 'add', 'elements', 'that', ',', 'frankly', ',', 'distract', 'from', 'the', 'story', '.'], ['it', 'is', 'bad', 'enough', 'that', 'mr', '.', 'm', 'doesn', \"'\", 't', 'like', 'tracy', \"'\", 's', 'determination', 'to', 'win', 'at', 'all', 'costs', ',', 'but', 'did', 'they', 'have', 'to', 'throw', 'in', 'the', 'student', '/', 'teacher', 'relationship', '?'], ['even', 'so', ',', 'there', \"'\", 's', 'no', 'logical', 'reason', 'why', 'mr', '.', 'm', 'has', 'an', 'affair', 'when', 'he', 'does', '.'], ['there', \"'\", 's', 'a', 'lot', 'to', 'like', 'in', '_election_', ',', 'but', 'the', 'plot', 'similarities', 'to', '_rushmore_', ',', 'and', 'the', 'tonal', 'nosedive', 'it', 'takes', 'as', 'it', 'gets', 'explicitly', 'sex', '-', 'driven', ',', 'mark', 'this', 'as', 'a', 'disappointment', '.']], ...]\n"
          ]
        }
      ],
      "source": [
        "mr = movie_reviews\n",
        "neg = mr.paras(categories = \"neg\")\n",
        "pos = mr.paras(categories = \"pos\")\n",
        "print(f\"length of each part of the dataset:\\n - pos: {len(pos)} \\n - neg: {len(neg)}\")\n",
        "print(pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-Y4wuDNt7XW"
      },
      "source": [
        "It's easy to see that data comes in the following format:\n",
        "\n",
        "- pos = [doc1, doc2, ..., doc1000] (the same applies for negative sentiment examples)\n",
        "\n",
        "Where each doc has the following structure:\n",
        "\n",
        "- doc1 = [sentence_1, sentence_2, ..., sentence_k]\n",
        "\n",
        "Each sentence is a list of tokens, so the dataset is already tokenized.\n",
        "\n",
        "### Word embedding\n",
        "Since I'm going to use deep learning models, I'm going to choose a word embedding to transform the text into vectors.\n",
        "I'm going to start with a pretrained version of GloVe word embedding.\n",
        "Since is a pre-trained word embedding (hence basically a lookup table), I'm going to check how many words of the vocabulary are covered by the pretrained word embedding model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_SEn4EFxKTd"
      },
      "outputs": [],
      "source": [
        "def create_vocab(corpus_words):\n",
        "    vocab = dict()\n",
        "    for word in corpus_words:\n",
        "      try:\n",
        "        vocab[word] += 1\n",
        "      except:\n",
        "        vocab[word] = 1\n",
        "    return vocab\n",
        "\n",
        "def get_corpus_words(corpus) -> list:\n",
        "    return [w for doc in corpus for sent in doc for w in sent]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdofBhKWxQHx",
        "outputId": "11f33a8a-0e37-4949-eb78-3ab35ce43387"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.840B.300d.zip: 2.18GB [06:50, 5.31MB/s]                            \n",
            "100%|█████████▉| 2196016/2196017 [04:24<00:00, 8308.59it/s]\n",
            "100%|██████████| 39768/39768 [00:01<00:00, 22744.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Found embeddings for 91.93% of vocab\n",
            "Found embeddings for  99.58% of all text\n"
          ]
        }
      ],
      "source": [
        "import operator\n",
        "from tqdm import tqdm\n",
        "from torchtext.vocab import GloVe\n",
        "import torch\n",
        "\n",
        "global_vectors = GloVe(name='840B', dim=300)\n",
        "\n",
        "# function inspired by https://www.kaggle.com/code/christofhenkel/how-to-preprocessing-when-using-embeddings/notebook\n",
        "def check_coverage(vocab,embeddings_index):\n",
        "    a = {}\n",
        "    oov = {}\n",
        "    k = 0\n",
        "    i = 0\n",
        "    null_embedding = torch.tensor([0.0]*300)\n",
        "    for word in tqdm(vocab):\n",
        "        try:\n",
        "          if torch.equal(embeddings_index.get_vecs_by_tokens(word), null_embedding):\n",
        "            raise KeyError\n",
        "          a[word] = embeddings_index.get_vecs_by_tokens(word)\n",
        "          k += vocab[word]\n",
        "        except:\n",
        "\n",
        "            oov[word] = vocab[word]\n",
        "            i += vocab[word]\n",
        "            pass\n",
        "\n",
        "    print()\n",
        "    print(f'Found embeddings for {len(a) / len(vocab):.2%} of vocab')\n",
        "    print(f'Found embeddings for  {k / (k + i):.2%} of all text')\n",
        "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
        "\n",
        "    return sorted_x\n",
        "\n",
        "vocab = create_vocab(get_corpus_words(pos + neg))\n",
        "oov = check_coverage(vocab, global_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K0HUOB2-E1V"
      },
      "outputs": [],
      "source": [
        "oov"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEjIRmuG-Quz"
      },
      "source": [
        "I'm going to see which are the words that are not covered by the embedding (Out Of Vocabulary words), so I can try to see if there are some tenchniques that can be applied in order to improve coverage.\n",
        "The majority of OOV words aren't related with a praticular sentiment (they are basically nouns or some type punctuation), so they can be safely removed. That happens because unknown words are encoded as $[0] * embedding.length$, so no useful information is added.\n",
        "Others OOV words are regular words surrounded by underscores, so they are not recognized by the fixed word embedding. To avoid this problem I implemented a procedure in order to clean these words:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgvlBpnMB8EO"
      },
      "outputs": [],
      "source": [
        "def remove_underscores(corpus):\n",
        "  for doc in corpus:\n",
        "    for sent in doc:\n",
        "      for idx, word in enumerate(sent):\n",
        "        if \"_\" in word:\n",
        "          cleaned_word = _clean_word(word)\n",
        "          sent[idx] = cleaned_word\n",
        "  return corpus\n",
        "\n",
        "\n",
        "def _clean_word(word: str):\n",
        "  word = word.replace(\"_\", \" \")\n",
        "  word = word.split()\n",
        "  word = \" \".join(word)\n",
        "  return word\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUphYnDOa785",
        "outputId": "e0b314d1-9afc-4056-bcd1-d731c2fb907a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 39519/39519 [00:01<00:00, 28083.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Found embeddings for 92.48% of vocab\n",
            "Found embeddings for  99.61% of all text\n"
          ]
        }
      ],
      "source": [
        "corpus = pos + neg\n",
        "clean_corpus = remove_underscores(corpus), oov\n",
        "vocab = create_vocab(get_corpus_words(clean_corpus))\n",
        "oov = check_coverage(vocab, global_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cmath import phase\n",
        "from dis import findlabels\n",
        "from unicodedata import name\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "\n",
        "CONTRACTION_MAP =  {\"ain't\": \"is not\",\n",
        "                        \"aren't\": \"are not\",\n",
        "                        \"can't\": \"cannot\",\n",
        "                        \"can't've\": \"cannot have\",\n",
        "                        \"'cause\": \"because\",\n",
        "                        \"could've\": \"could have\",\n",
        "                        \"couldn't\": \"could not\",\n",
        "                        \"couldn't've\": \"could not have\",\n",
        "                        \"didn't\": \"did not\",\n",
        "                        \"doesn't\": \"does not\",\n",
        "                        \"don't\": \"do not\",\n",
        "                        \"hadn't\": \"had not\",\n",
        "                        \"hadn't've\": \"had not have\",\n",
        "                        \"hasn't\": \"has not\",\n",
        "                        \"haven't\": \"have not\",\n",
        "                        \"he'd\": \"he would\",\n",
        "                        \"he'd've\": \"he would have\",\n",
        "                        \"he'll\": \"he will\",\n",
        "                        \"he'll've\": \"he he will have\",\n",
        "                        \"he's\": \"he is\",\n",
        "                        \"how'd\": \"how did\",\n",
        "                        \"how'd'y\": \"how do you\",\n",
        "                        \"how'll\": \"how will\",\n",
        "                        \"how's\": \"how is\",\n",
        "                        \"i'd\": \"i would\",\n",
        "                        \"i'd've\": \"i would have\",\n",
        "                        \"i'll\": \"i will\",\n",
        "                        \"i'll've\": \"i will have\",\n",
        "                        \"i'm\": \"i am\",\n",
        "                        \"i've\": \"i have\",\n",
        "                        \"isn't\": \"is not\",\n",
        "                        \"it'd\": \"it would\",\n",
        "                        \"it'd've\": \"it would have\",\n",
        "                        \"it'll\": \"it will\",\n",
        "                        \"it'll've\": \"it will have\",\n",
        "                        \"it's\": \"it is\",\n",
        "                        \"let's\": \"let us\",\n",
        "                        \"ma'am\": \"madam\",\n",
        "                        \"mayn't\": \"may not\",\n",
        "                        \"might've\": \"might have\",\n",
        "                        \"mightn't\": \"might not\",\n",
        "                        \"mightn't've\": \"might not have\",\n",
        "                        \"must've\": \"must have\",\n",
        "                        \"mustn't\": \"must not\",\n",
        "                        \"mustn't've\": \"must not have\",\n",
        "                        \"needn't\": \"need not\",\n",
        "                        \"needn't've\": \"need not have\",\n",
        "                        \"o'clock\": \"of the clock\",\n",
        "                        \"oughtn't\": \"ought not\",\n",
        "                        \"oughtn't've\": \"ought not have\",\n",
        "                        \"shan't\": \"shall not\",\n",
        "                        \"sha'n't\": \"shall not\",\n",
        "                        \"shan't've\": \"shall not have\",\n",
        "                        \"she'd\": \"she would\",\n",
        "                        \"she'd've\": \"she would have\",\n",
        "                        \"she'll\": \"she will\",\n",
        "                        \"she'll've\": \"she will have\",\n",
        "                        \"she's\": \"she is\",\n",
        "                        \"should've\": \"should have\",\n",
        "                        \"shouldn't\": \"should not\",\n",
        "                        \"shouldn't've\": \"should not have\",\n",
        "                        \"so've\": \"so have\",\n",
        "                        \"so's\": \"so as\",\n",
        "                        \"that'd\": \"that would\",\n",
        "                        \"that'd've\": \"that would have\",\n",
        "                        \"that's\": \"that is\",\n",
        "                        \"there'd\": \"there would\",\n",
        "                        \"there'd've\": \"there would have\",\n",
        "                        \"there's\": \"there is\",\n",
        "                        \"they'd\": \"they would\",\n",
        "                        \"they'd've\": \"they would have\",\n",
        "                        \"they'll\": \"they will\",\n",
        "                        \"they'll've\": \"they will have\",\n",
        "                        \"they're\": \"they are\",\n",
        "                        \"they've\": \"they have\",\n",
        "                        \"to've\": \"to have\",\n",
        "                        \"wasn't\": \"was not\",\n",
        "                        \"we'd\": \"we would\",\n",
        "                        \"we'd've\": \"we would have\",\n",
        "                        \"we'll\": \"we will\",\n",
        "                        \"we'll've\": \"we will have\",\n",
        "                        \"we're\": \"we are\",\n",
        "                        \"we've\": \"we have\",\n",
        "                        \"weren't\": \"were not\",\n",
        "                        \"what'll\": \"what will\",\n",
        "                        \"what'll've\": \"what will have\",\n",
        "                        \"what're\": \"what are\",\n",
        "                        \"what's\": \"what is\",\n",
        "                        \"what've\": \"what have\",\n",
        "                        \"when's\": \"when is\",\n",
        "                        \"when've\": \"when have\",\n",
        "                        \"where'd\": \"where did\",\n",
        "                        \"where's\": \"where is\",\n",
        "                        \"where've\": \"where have\",\n",
        "                        \"who'll\": \"who will\",\n",
        "                        \"who'll've\": \"who will have\",\n",
        "                        \"who's\": \"who is\",\n",
        "                        \"who've\": \"who have\",\n",
        "                        \"why's\": \"why is\",\n",
        "                        \"why've\": \"why have\",\n",
        "                        \"will've\": \"will have\",\n",
        "                        \"won't\": \"will not\",\n",
        "                        \"won't've\": \"will not have\",\n",
        "                        \"would've\": \"would have\",\n",
        "                        \"wouldn't\": \"would not\",\n",
        "                        \"wouldn't've\": \"would not have\",\n",
        "                        \"y'all\": \"you all\",\n",
        "                        \"y'all'd\": \"you all would\",\n",
        "                        \"y'all'd've\": \"you all would have\",\n",
        "                        \"y'all're\": \"you all are\",\n",
        "                        \"y'all've\": \"you all have\",\n",
        "                        \"you'd\": \"you would\",\n",
        "                        \"you'd've\": \"you would have\",\n",
        "                        \"you'll\": \"you will\",\n",
        "                        \"you'll've\": \"you will have\",\n",
        "                        \"you're\": \"you are\",\n",
        "                        \"you've\": \"you have\",\n",
        "                    }\n",
        "class MRAbstractPipeline():\n",
        "    def __init__(self):\n",
        "        self.pipeline = []\n",
        "    \n",
        "    def pipe(self, corpus):\n",
        "        for el in self.pipeline:\n",
        "            corpus = el(corpus)\n",
        "        return corpus\n",
        "    \n",
        "    def __call__(self, *args, **kwds):\n",
        "        if args[0] == None:\n",
        "            raise ValueError(\"Need a corpus as argument\")\n",
        "        corpus = args[0]\n",
        "        return self.pipe(corpus)\n",
        "        \n",
        "\n",
        "class MRPipelineTokens(MRAbstractPipeline):\n",
        "    \"\"\"\n",
        "    Pipeline for documents represented as list of tokens\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(MRPipelineTokens, self).__init__()\n",
        "        self.pipeline = [self.remove_underscores, \n",
        "                         self.reducing_character_repetitions,\n",
        "                         #self.unite_ts,\n",
        "                         self.clean_contractions,\n",
        "                         self.clean_special_chars,\n",
        "                         self.remove_stop_words]\n",
        "\n",
        "    def remove_underscores(self, corpus):\n",
        "        \"\"\"\n",
        "        Solves the problem where some of the words are surrounded by underscores\n",
        "        (e.g. \"_hello_\")\n",
        "        \"\"\"\n",
        "        for doc in corpus:\n",
        "            for idx, word in enumerate(doc):\n",
        "                if \"_\" in word:\n",
        "                    cleaned_word = self._clean_word(word)\n",
        "                    doc[idx] = cleaned_word\n",
        "        return corpus\n",
        "\n",
        "\n",
        "    def _clean_word(self, word: str):\n",
        "        word = word.replace(\"_\", \" \")\n",
        "        # remove spaces before and after the word\n",
        "        word = word.split()\n",
        "        word = \" \".join(word)\n",
        "        return word\n",
        "    \n",
        "    def reducing_character_repetitions(self, corpus):\n",
        "        \n",
        "        new_corpus = []\n",
        "        for doc in corpus:\n",
        "            new_doc = [self._clean_repetitions(w) for w in doc]\n",
        "            new_corpus.append(new_doc)\n",
        "        return new_corpus\n",
        "\n",
        "    # inspired by https://towardsdatascience.com/cleaning-preprocessing-text-data-by-building-nlp-pipeline-853148add68a\n",
        "    def _clean_repetitions(self, word):\n",
        "        \"\"\"\n",
        "        This Function will reduce repetition to two characters \n",
        "        for alphabets and to one character for punctuations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "            word: str                \n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            Finally formatted text with alphabets repeating to \n",
        "            one characters & punctuations limited to one repetition \n",
        "            \n",
        "        Example:\n",
        "        Input : Realllllllllyyyyy,        Greeeeaaaatttt   !!!!?....;;;;:)\n",
        "        Output : Really, Great !?.;:)\n",
        "\n",
        "        \"\"\"\n",
        "        # Pattern matching for all case alphabets\n",
        "        pattern_alpha = re.compile(r\"([A-Za-z])\\1{1,}\", re.DOTALL)\n",
        "\n",
        "        # Limiting all the repetitions to two characters.\n",
        "        # MODIFIED: keep only one repetition of the character\n",
        "        formatted_text = pattern_alpha.sub(r\"\\1\\1\", word) \n",
        "\n",
        "        # Pattern matching for all the punctuations that can occur\n",
        "        pattern_punct = re.compile(r'([.,/#!$%^&*?;:{}=_`~()+-])\\1{1,}')\n",
        "\n",
        "        # Limiting punctuations in previously formatted string to only one.\n",
        "        combined_formatted = pattern_punct.sub(r'\\1', formatted_text)\n",
        "\n",
        "        # The below statement is replacing repetitions of spaces that occur more than two times with that of one occurrence.\n",
        "        final_formatted = re.sub(' {2,}',' ', combined_formatted)\n",
        "        return final_formatted\n",
        "    \n",
        "    def unite_ts(self, corpus):\n",
        "      new_corpus = []\n",
        "      for doc in corpus:\n",
        "        indexes = self._get_neg_indexes(doc)\n",
        "        for el in indexes:\n",
        "          doc[el[0]:el[1]] = [\"\".join(doc[el[0]:el[1]])]\n",
        "        new_corpus.append(doc)\n",
        "      return new_corpus\n",
        "\n",
        "    def _get_neg_indexes(self, sent):\n",
        "      indexes = []\n",
        "      for idx, word in enumerate(sent):\n",
        "        # Try to avoid out of range indexes (there can be some \"'\" a the beginning or end of the phrase)\n",
        "        try:\n",
        "          if word==\"'\" and sent[idx+1]==\"t\":\n",
        "            indexes.append((idx-1,idx+2))\n",
        "        except:\n",
        "          pass\n",
        "      return indexes\n",
        "    \n",
        "    def clean_contractions(self, corpus):\n",
        "        new_corpus = []\n",
        "        for doc in corpus:\n",
        "            new_doc = []\n",
        "            for word in doc:\n",
        "                try:\n",
        "                    correct = CONTRACTION_MAP[word]\n",
        "                    correct = correct.split()\n",
        "                    new_doc += correct\n",
        "                except:\n",
        "                    new_doc.append(word)\n",
        "            new_corpus.append(new_doc)\n",
        "        return new_corpus\n",
        "\n",
        "    def clean_special_chars(self, corpus):\n",
        "        new_corpus = [[self._clean_special_word(w) for w in doc] for doc in corpus] \n",
        "        return new_corpus\n",
        "    \n",
        "    def _clean_special_word(self, word):\n",
        "        # The formatted text after removing not necessary punctuations.\n",
        "        formatted_text = re.sub(r\"[^a-zA-Z0-9:€$-,%.?!]+\", '', word) \n",
        "        # In the above regex expression,I am providing necessary set of punctuations that are frequent in this particular dataset.\n",
        "        return formatted_text\n",
        "    \n",
        "    def remove_stop_words(self, corpus):\n",
        "        stops = stopwords.words(\"english\")\n",
        "        stops = [word for word in stops if \"'t\" not in word or \"not\" not in word]\n",
        "        return [[word for word in doc if word not in stops] for doc in corpus]\n",
        "    \n",
        "\n",
        "class MRPipelinePhrases(MRAbstractPipeline):\n",
        "    \"\"\"\n",
        "    Pipeline for documents represented as list of phrases\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(MRPipelinePhrases, self).__init__()\n",
        "        self.pipeline = [self.remove_underscores, \n",
        "                         self.clean_special_chars,\n",
        "                         self.reducing_character_repetitions,\n",
        "                         self.lemmatize]\n",
        "\n",
        "    def remove_underscores(self, corpus):\n",
        "        \"\"\"\n",
        "        Solves the problem where some of the words are surrounded by underscores\n",
        "        (e.g. \"_hello_\")\n",
        "        \"\"\"\n",
        "        new_corpus = [self._clean_word(doc) for doc in corpus]\n",
        "        return new_corpus\n",
        "\n",
        "\n",
        "    def _clean_word(self, doc: str):\n",
        "        doc = doc.replace(\"_\", \" \")\n",
        "        return doc\n",
        "    \n",
        "    def reducing_character_repetitions(self, corpus):\n",
        "        new_corpus = [self._clean_repetitions(doc) for doc in corpus]\n",
        "        return new_corpus\n",
        "    \n",
        "    # inspired by https://towardsdatascience.com/cleaning-preprocessing-text-data-by-building-nlp-pipeline-853148add68a\n",
        "    def _clean_repetitions(self, word):\n",
        "        \"\"\"\n",
        "        This Function will reduce repetition to two characters \n",
        "        for alphabets and to one character for punctuations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "            word: str                \n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            Finally formatted text with alphabets repeating to \n",
        "            one characters & punctuations limited to one repetition \n",
        "            \n",
        "        Example:\n",
        "        Input : Realllllllllyyyyy,        Greeeeaaaatttt   !!!!?....;;;;:)\n",
        "        Output : Realy, Great !?.;:)\n",
        "\n",
        "        \"\"\"\n",
        "        # Pattern matching for all case alphabets\n",
        "        pattern_alpha = re.compile(r\"([A-Za-z])\\1{1,}\", re.DOTALL)\n",
        "\n",
        "        # Limiting all the repetitions to two characters.\n",
        "        # MODIFIED: keep only one repetition of the character\n",
        "        formatted_text = pattern_alpha.sub(r\"\\1\\1\", word) \n",
        "\n",
        "        # Pattern matching for all the punctuations that can occur\n",
        "        pattern_punct = re.compile(r'([., /#!$%^&*?;:{}=_`~()+-])\\1{1,}')\n",
        "\n",
        "        # Limiting punctuations in previously formatted string to only one.\n",
        "        combined_formatted = pattern_punct.sub(r'\\1', formatted_text)\n",
        "\n",
        "        # The below statement is replacing repetitions of spaces that occur more than two times with that of one occurrence.\n",
        "        final_formatted = re.sub(' {2,}',' ', combined_formatted)\n",
        "        return final_formatted\n",
        "\n",
        "    def clean_special_chars(self, corpus):\n",
        "        new_corpus = [self._clean_special_word(doc)  for doc in corpus]\n",
        "        return new_corpus\n",
        "    \n",
        "    def _clean_special_word(self, word):\n",
        "        # The formatted text after removing not necessary punctuations.\n",
        "        formatted_text = re.sub(r\"[^a-zA-Z0-9:€$-,%.?!]+\", ' ', word) \n",
        "        # In the above regex expression,I am providing necessary set of punctuations that are frequent in this particular dataset.\n",
        "        return formatted_text\n",
        "    \n",
        "\n",
        "    def lemmatize(self, corpus):\n",
        "        nlp = spacy.load('en_core_web_sm')\n",
        "        return [[token.lemma_ for token in nlp(doc)] for doc in corpus]\n"
      ],
      "metadata": {
        "id": "spYv4QqyqJ0H"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skv2-rEQwMtR"
      },
      "source": [
        "### Corpus class\n",
        "I'm going to create a class for the representation of the corpus in order to have a self contained way to have all the functions that may be useful for the processing of the corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "C3PyvlOV60V7"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "import numpy as np\n",
        "import torch\n",
        "import spacy\n",
        "\n",
        "\n",
        "class MovieReviewsCorpusPhrases():\n",
        "    def __init__(self, preprocess_pipeline = None):\n",
        "        \"\"\"\n",
        "        If non preprocess_pipeline is given, the text gets tokenized by default\n",
        "        using spacy tokenizer\n",
        "        \"\"\"\n",
        "        self.mr = movie_reviews\n",
        "        if preprocess_pipeline != None and not isinstance(preprocess_pipeline, MRPipelinePhrases):\n",
        "            raise ValueError(f\"preprocess_pipeline is not valid, you should pass \\\n",
        "                                a MRPipelinePhrases object or None\")\n",
        "        self.pipeline = preprocess_pipeline\n",
        "        self.raw_corpus, self.labels = self._get_raw_corpus()\n",
        "        if self.pipeline == None:\n",
        "            self.processed_corpus = self.raw_corpus\n",
        "        else:\n",
        "            # Flattened and preprocessed corpus\n",
        "            self.processed_corpus = self._preprocess()\n",
        "        \n",
        "        self.vocab = self._create_vocab()\n",
        "        \n",
        "\n",
        "    def _get_raw_corpus(self):\n",
        "        neg = [self.mr.raw(doc) for doc in self.mr.fileids()[:1000]]\n",
        "        pos = [self.mr.raw(doc) for doc in self.mr.fileids()[1000:]]\n",
        "        labels = [0]*len(neg) + [1]*len(pos)\n",
        "        return neg + pos, labels\n",
        "    \n",
        "    def _preprocess(self):\n",
        "        if self.pipeline != None:\n",
        "            return self.pipeline(self.raw_corpus)\n",
        "        else:\n",
        "            return self.raw_corpus\n",
        "        \n",
        "    def _create_vocab(self):\n",
        "        vocab = dict()\n",
        "        corpus_words = [w for doc in self.processed_corpus for w in doc]\n",
        "        for word in corpus_words:\n",
        "            try:\n",
        "                vocab[word] += 1\n",
        "            except:\n",
        "                vocab[word] = 1\n",
        "        return vocab\n",
        "\n",
        "    def get_embedding_matrix(self, embedding, embedding_dim):\n",
        "        \"\"\"\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            A 2D which each row has the corresponding embedding from the vocabulary\n",
        "        \"\"\"\n",
        "        matrix_length = len(self.vocab)\n",
        "        embedding_matrix = np.zeros((matrix_length, embedding_dim))\n",
        "        # If I use torch.zeros directly it crashes (don't know why)\n",
        "        embedding_matrix = torch.from_numpy(embedding_matrix.copy())\n",
        "        null_embedding = torch.tensor([0.0]*embedding_dim)\n",
        "        for idx, key in enumerate(self.vocab.keys()):\n",
        "            if torch.equal(embedding[key], null_embedding):\n",
        "                embedding_matrix[idx] = torch.randn(embedding_dim)\n",
        "            else:\n",
        "                embedding_matrix[idx] = embedding[key]\n",
        "                \n",
        "        return embedding_matrix\n",
        "    \n",
        "    def get_indexed_corpus(self):\n",
        "        \"\"\"\n",
        "        Returns\n",
        "        -------\n",
        "        Dictionary\n",
        "            Containing correspondences word -> index\n",
        "        \n",
        "        list(list(torch.tensor))\n",
        "            The corpus represented as indexes corresponding to each word\n",
        "        \"\"\"\n",
        "        vocab = {}\n",
        "        for idx, key in enumerate(self.vocab.keys()):\n",
        "            vocab[key] = idx\n",
        "        \n",
        "        indexed_corpus = [torch.tensor([torch.tensor(vocab[w], dtype=torch.int32) for w in doc]) for doc in self.processed_corpus]\n",
        "        return indexed_corpus, self.labels\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.processed_corpus)\n",
        "\n",
        "\n",
        "class MovieReviewsCorpus():\n",
        "    def __init__(self, preprocess_pipeline = None):\n",
        "        # list of documents, each document is a list containing words of that document\n",
        "        self.mr = movie_reviews\n",
        "        self.pipeline = preprocess_pipeline\n",
        "        # Corpus as list of documents. Documents as list of sentences. Sentences as list of tokens\n",
        "        self.unprocessed_corpus, self.labels = self._get_corpus()\n",
        "        # Corpus as list of documents. Documents as list of tokens\n",
        "        self.flattened_corpus = self._flatten()\n",
        "        if preprocess_pipeline == None:\n",
        "            self.processed_corpus = self.flattened_corpus\n",
        "        else:\n",
        "            # Flattened and preprocessed corpus\n",
        "            self.processed_corpus = self._preprocess()\n",
        "\n",
        "        self.corpus_words = self.get_corpus_words()\n",
        "        self.vocab = self._create_vocab()\n",
        "\n",
        "\n",
        "\n",
        "    def _list_to_str(self, doc) -> str:\n",
        "        \"\"\"\n",
        "        Put all elements of the list into a single string, separating each element with a space.\n",
        "        \"\"\"\n",
        "        return \" \".join([w for sent in doc for w in sent])\n",
        "\n",
        "    def _preprocess(self):\n",
        "        return self.pipeline(self.flattened_corpus)\n",
        "\n",
        "    def _flatten(self):\n",
        "        \"\"\"\n",
        "        Returns\n",
        "        -------\n",
        "        list[list[str]]\n",
        "            Each inner list represents a document. Each document is a list of tokens.\n",
        "        \"\"\"\n",
        "\n",
        "        # 3 nested list: each list contain a document, each inner list contains a phrase (until fullstop), each phrase contains words.\n",
        "\n",
        "        corpus = [[w for w in self._list_to_str(d).split(\" \")] for d in self.unprocessed_corpus]\n",
        "        return corpus\n",
        "\n",
        "    def _get_corpus(self):\n",
        "        neg = self.mr.paras(categories = \"neg\")\n",
        "        pos = self.mr.paras(categories = \"pos\")\n",
        "        labels = [0] * len(pos) + [1] * len(neg)\n",
        "        return neg + pos, labels\n",
        "\n",
        "    def movie_reviews_dataset_raw(self):\n",
        "        \"\"\"\n",
        "        Returns the dataset containing:\n",
        "\n",
        "        - A list of all the documents\n",
        "        - The corresponding label for each document\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        tuple(list, list)\n",
        "            The dataset: first element is the list of the document, the second element of the tuple is the associated label (positive or negative) for each document\n",
        "        \"\"\"\n",
        "\n",
        "        return self.flattened_corpus, self.labels\n",
        "\n",
        "    def get_sentence_ds(self):\n",
        "        neg = self.mr.paras(categories = \"neg\")\n",
        "        pos = self.mr.paras(categories = \"pos\")\n",
        "\n",
        "        pos = [phrase for doc in pos for phrase in doc]\n",
        "        neg = [phrase for doc in neg for phrase in doc]\n",
        "\n",
        "        labels = np.array([0] * len(pos) + [1] * len(neg))\n",
        "        corpus = neg+pos\n",
        "        return corpus, labels\n",
        "\n",
        "\n",
        "    def get_corpus_words(self) -> list:\n",
        "        return [w for doc in self.processed_corpus for w in doc]\n",
        "    \n",
        "    def get_embedding_matrix(self, embedding, embedding_dim):\n",
        "        \"\"\"\n",
        "        Returns\n",
        "        -------\n",
        "        np.ndarray\n",
        "            A 2D which each row has the corresponding embedding from the vocabulary\n",
        "        \"\"\"\n",
        "        matrix_length = len(self.vocab)\n",
        "        embedding_matrix = np.zeros((matrix_length, embedding_dim))\n",
        "        # If I use torch.zeros directly it crashes (don't know why)\n",
        "        embedding_matrix = torch.from_numpy(embedding_matrix.copy())\n",
        "        null_embedding = torch.tensor([0.0]*embedding_dim)\n",
        "        for idx, key in enumerate(self.vocab.keys()):\n",
        "            if torch.equal(embedding[key], null_embedding):\n",
        "                embedding_matrix[idx] = torch.randn(embedding_dim)\n",
        "            else:\n",
        "                embedding_matrix[idx] = embedding[key]\n",
        "                \n",
        "        return embedding_matrix\n",
        "    \n",
        "    def get_fasttext_embedding_matrix(self, embedding, embedding_dim):\n",
        "        matrix_length = len(self.vocab)\n",
        "        embedding_matrix = np.zeros((matrix_length, embedding_dim))\n",
        "        # If I use torch.zeros directly it crashes (don't know why)\n",
        "        embedding_matrix = torch.from_numpy(embedding_matrix.copy())\n",
        "        null_embedding = torch.tensor([0.0]*embedding_dim)\n",
        "        for idx, key in enumerate(self.vocab.keys()):\n",
        "            tensor_embedding = torch.from_numpy(embedding[key].copy())\n",
        "            if torch.equal(tensor_embedding, null_embedding):\n",
        "                embedding_matrix[idx] = torch.randn(embedding_dim)\n",
        "            else:\n",
        "                embedding_matrix[idx] = tensor_embedding\n",
        "                \n",
        "        return embedding_matrix\n",
        "    \n",
        "    def get_indexed_corpus(self):\n",
        "        \"\"\"\n",
        "        Returns\n",
        "        -------\n",
        "        Dictionary\n",
        "            Containing correspondences word -> index\n",
        "        \n",
        "        list(list(torch.tensor))\n",
        "            The corpus represented as indexes corresponding to each word\n",
        "        \"\"\"\n",
        "        vocab = {}\n",
        "        for idx, key in enumerate(self.vocab.keys()):\n",
        "            vocab[key] = idx\n",
        "        \n",
        "        indexed_corpus = [torch.tensor([torch.tensor(vocab[w], dtype=torch.int32) for w in doc]) for doc in self.processed_corpus]\n",
        "        return indexed_corpus, self.labels\n",
        "\n",
        "\n",
        "    def _create_vocab(self):\n",
        "        vocab = dict()\n",
        "        for word in self.corpus_words:\n",
        "            try:\n",
        "                vocab[word] += 1\n",
        "            except:\n",
        "                vocab[word] = 1\n",
        "        return vocab\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.flattened_corpus)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zZaF5yV9rlo-"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchtext.vocab import GloVe\n",
        "\n",
        "class MovieReviewsDataset(Dataset):\n",
        "  def __init__(self, raw_dataset):\n",
        "    super(MovieReviewsDataset, self).__init__()\n",
        "    self.corpus = np.array(raw_dataset[0], dtype = object)\n",
        "    self.targets = np.array(raw_dataset[1], dtype = np.int32)\n",
        "    self.max_element = len(max(self.corpus, key=lambda x: len(x)))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.corpus)\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    item = self.corpus[index]\n",
        "    label = self.targets[index]\n",
        "    return (item, label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cr7PPG1k4gFq"
      },
      "source": [
        "### Create the model class\n",
        "Let's first try with a simple BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bCvqaJ8-hKmT"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.utils.rnn import pad_packed_sequence\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "class BiLSTM(nn.Module):\n",
        "    def __init__(self, embedding_matrix = None, device = \"cuda\", input_size = 300, hidden_size = 128, output_size = 2):\n",
        "        super(BiLSTM, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.device = device\n",
        "        if embedding_matrix != None:\n",
        "          self.embedding = self.create_embedding_layer(embedding_matrix)\n",
        "        else:\n",
        "          self.embedding = None\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first = True, bidirectional=True)\n",
        "        self.fc = nn.Sequential(nn.ReLU(),\n",
        "                                nn.BatchNorm1d(hidden_size*2, eps = 1e-08),\n",
        "                                nn.Dropout(0.3),\n",
        "                                nn.Linear(hidden_size*2, output_size)\n",
        "                                )\n",
        "\n",
        "    def create_embedding_layer(self, embedding_matrix):\n",
        "        num_embeddings, embedding_dim = embedding_matrix.shape\n",
        "        emb_layer = nn.Embedding(num_embeddings, embedding_dim, -1)\n",
        "        emb_layer.load_state_dict({\"weight\": embedding_matrix})\n",
        "        return emb_layer\n",
        "\n",
        "    # function taken from https://discuss.pytorch.org/t/how-to-use-pack-sequence-if-we-are-going-to-use-word-embedding-and-bilstm/28184/4\n",
        "    def simple_elementwise_apply(self, fn, packed_sequence):\n",
        "        \"\"\"applies a pointwise function fn to each element in packed_sequence\"\"\"\n",
        "        return torch.nn.utils.rnn.PackedSequence(fn(packed_sequence.data), packed_sequence.batch_sizes)\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        if self.cuda:\n",
        "            return (torch.zeros(2, batch_size, self.hidden_size).to(self.device),\n",
        "                    torch.zeros(2, batch_size, self.hidden_size).to(self.device),)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.batch_sizes[0].item()\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        x = self.simple_elementwise_apply(self.embedding, x)\n",
        "\n",
        "        # output: batch_size, sequence_length, hidden_size * 2 (since is bilstm)\n",
        "        out, _ = self.lstm(x, hidden)\n",
        "        out, input_sizes = pad_packed_sequence(out, batch_first=True)\n",
        "        # Interested only in the last layer\n",
        "        out = out[list(range(batch_size)), input_sizes - 1, :]\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class BiLSTMAttention(BiLSTM):\n",
        "    # BiLSTM with attention inspired by the following paper: https://aclanthology.org/S18-1040.pdf\n",
        "    def __init__(self, embedding_matrix = None, device=\"cuda\", input_size=300,\n",
        "                 hidden_size=128, context_size = None, output_size=2):\n",
        "        super(BiLSTMAttention, self).__init__(embedding_matrix, device, input_size, hidden_size, output_size)\n",
        "        # Not self attention :)\n",
        "        if context_size != None:\n",
        "          self.attention = nn.Linear(self.hidden_size * 2, context_size)\n",
        "          self.history = nn.Parameter(torch.randn(context_size))\n",
        "        else:\n",
        "          self.attention = nn.Linear(self.hidden_size * 2, 1)\n",
        "          self.history = None\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        batch_size = x.batch_sizes[0].item()\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        if self.embedding != None:\n",
        "          x = self.simple_elementwise_apply(self.embedding, x)\n",
        "\n",
        "        # output: batch_size, sequence_length, hidden_size * 2 (since is bilstm)\n",
        "        out, _ = self.lstm(x, hidden)\n",
        "        out, input_sizes = pad_packed_sequence(out, batch_first=True)\n",
        "\n",
        "        if self.history == None:\n",
        "          attention_values = torch.tanh(self.attention(out)).squeeze()\n",
        "          attention_weights = torch.softmax(attention_values, dim = 1).unsqueeze(1)\n",
        "          # n_docs, sequence_length\n",
        "        else:\n",
        "          attention_values = torch.tanh(self.attention(out))\n",
        "          attention_weights = torch.softmax(attention_values.matmul(self.history), dim = 1).unsqueeze(1)\n",
        "          # n_docs, sequence_length\n",
        "\n",
        "        out = torch.sum(attention_weights.matmul(out), dim = 1)\n",
        "\n",
        "        out = self.fc(out)\n",
        "\n",
        "        attention_weights = attention_weights.squeeze()\n",
        "        att = [doc[:input_sizes[idx]] for idx, doc in enumerate(attention_weights)]\n",
        "\n",
        "        return out, att\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yZFg9BvQdZHB"
      },
      "outputs": [],
      "source": [
        "def training_step(net, data_loader, optimizer, cost_function, device = 'cuda'):\n",
        "  cumulative_loss = 0\n",
        "  cumulative_accuracy = 0\n",
        "  samples = 0\n",
        "\n",
        "  net.train()\n",
        "\n",
        "  for batch_idx, (inputs, targets, _) in enumerate(data_loader):\n",
        "\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "    in_size = targets.size(dim=0)\n",
        "\n",
        "    outputs, _ = net(inputs)\n",
        "\n",
        "    loss = cost_function(outputs, targets)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    samples += in_size\n",
        "    cumulative_loss += loss.item()\n",
        "    _, predicted = outputs.max(dim=1)\n",
        "\n",
        "    cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, (cumulative_accuracy/samples)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LJef4h1cfWym"
      },
      "outputs": [],
      "source": [
        "def test_step(net, data_loader, cost_function, device = 'cuda'):\n",
        "  cumulative_loss = 0\n",
        "  cumulative_accuracy = 0\n",
        "  samples = 0\n",
        "\n",
        "  net.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for batch_idx, (inputs, targets, _) in enumerate(data_loader):\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      in_size = targets.size(dim=0)\n",
        "\n",
        "      outputs, _ = net(inputs)\n",
        "\n",
        "      loss = cost_function(outputs, targets)\n",
        "\n",
        "      samples += in_size\n",
        "      cumulative_loss += loss.item()\n",
        "      _, predicted = outputs.max(dim=1)\n",
        "\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "    return cumulative_loss/samples, (cumulative_accuracy/samples)*100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OOeUmEHZNBvw"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "import torch.nn as nn\n",
        "\n",
        "def main(train_loader, test_loader, embedding_matrix, device = \"cuda\", epochs = 10):\n",
        "\n",
        "  net = BiLSTMAttention(embedding_matrix, device = device, input_size=300).to(device)\n",
        "\n",
        "  optimizer = Adam(net.parameters(), 0.001, betas = (0.9, 0.9), amsgrad=True)\n",
        "\n",
        "  cost_function = nn.CrossEntropyLoss()\n",
        "\n",
        "  for e in range(epochs):\n",
        "    print(f\"epoch {e}:\")\n",
        "    train_loss, train_accuracy = training_step(net, train_loader, optimizer, cost_function, device)\n",
        "    print(f\"Training loss: {train_loss} \\n Training accuracy: {train_accuracy}\")\n",
        "    test_loss, test_accuracy = test_step(net, test_loader, cost_function, device)\n",
        "    print(f\"Test loss: {test_loss} \\n Test accuracy: {test_accuracy}\")\n",
        "    print(\"------------------------------------------------------------------\")\n",
        "  \n",
        "  _, test_accuracy = test_step(net, test_loader, cost_function, device)\n",
        "\n",
        "  return test_accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GfNtrS8jmATx"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch.utils.data import Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def pad(batch, max_size):\n",
        "    # try:\n",
        "    pad = torch.tensor([-1]*batch[0].size(dim=1), dtype = torch.float).to(\"cuda\")\n",
        "    embedded = 1\n",
        "    # except:\n",
        "    #  pad = torch.tensor([-1])\n",
        "    #  embedded = 0\n",
        "    for idx in range(len(batch)):\n",
        "        remaining = max_size - batch[idx].size(dim = 0)\n",
        "        abc = pad.repeat(remaining)\n",
        "        if embedded:\n",
        "          batch[idx] = torch.cat((batch[idx], pad.repeat(remaining, 1)), dim = 0)\n",
        "        else:\n",
        "          batch[idx] = torch.cat((batch[idx], pad.repeat(remaining)), dim = 0)\n",
        "    return batch\n",
        "\n",
        "def batch_to_tensor(X: List[torch.tensor], max_size):\n",
        "    # try:\n",
        "    X_tensor = torch.zeros((len(X), max_size, X[0].size(dim=1)), dtype=torch.float).to(\"cuda\")\n",
        "    # except:\n",
        "    #  X_tensor = torch.zeros((len(X), max_size), dtype=torch.int32)\n",
        "\n",
        "    for i, embed in enumerate(X):\n",
        "        X_tensor[i] = embed\n",
        "    return X_tensor\n",
        "\n",
        "def sort_ds(X, Y):\n",
        "    \"\"\"\n",
        "    Sort inputs by document lengths\n",
        "    \"\"\"\n",
        "    document_lengths = np.array([tens.size(dim = 0) for tens in X])\n",
        "    indexes = np.argsort(document_lengths)\n",
        "    document_lengths = document_lengths.tolist()\n",
        "\n",
        "    X_sorted = [X[idx] for idx in indexes][::-1]\n",
        "    Y_sorted = [Y[idx] for idx in indexes][::-1]\n",
        "    document_lengths = torch.tensor([document_lengths[idx] for idx in indexes][::-1])\n",
        "\n",
        "    return X_sorted, Y_sorted, document_lengths, indexes\n",
        "\n",
        "\n",
        "\n",
        "def collate(batch):\n",
        "    X, Y = list(zip(*batch))\n",
        "    # Sort dataset\n",
        "    X, Y, document_lengths, indexes = sort_ds(X, Y)\n",
        "\n",
        "    # Get tensor sizes\n",
        "    max_size = torch.max(document_lengths).item()\n",
        "\n",
        "    # Pad tensor each element\n",
        "    X = pad(X, max_size)\n",
        "\n",
        "    # Transform the batch to a tensor\n",
        "    X_tensor = batch_to_tensor(X, max_size)\n",
        "    Y_tensor = torch.tensor(Y)\n",
        "    # Return the padded sequence object\n",
        "    X_final = pack_padded_sequence(X_tensor, document_lengths, batch_first=True)\n",
        "    return X_final, Y_tensor, indexes\n",
        "\n",
        "\n",
        "def get_data(batch_size: int, dataset, collate_fn, random_state = 42):\n",
        "  # Random Split\n",
        "  train_indexes, test_indexes = train_test_split(list(range(len(dataset.targets))), test_size = 0.2,\n",
        "                                                  stratify = dataset.targets, random_state = random_state)\n",
        "\n",
        "  train_ds = Subset(dataset, train_indexes)\n",
        "  test_ds = Subset(dataset, test_indexes)\n",
        "\n",
        "  train_loader = DataLoader(train_ds, batch_size = batch_size, collate_fn = collate_fn, pin_memory=True)\n",
        "  test_loader = DataLoader(test_ds, batch_size = batch_size, collate_fn = collate_fn, pin_memory=True)\n",
        "\n",
        "  return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "# Workaround in order to use .targets to access labels of the subset (doesn't work with Subset pytorch class)\n",
        "# https://discuss.pytorch.org/t/attributeerror-subset-object-has-no-attribute-targets/66564\n",
        "class CustomSubset(Dataset):\n",
        "    \"\"\"\n",
        "    Subset of a dataset at specified indices.\n",
        "\n",
        "    Arguments:\n",
        "        dataset (Dataset): The whole Dataset\n",
        "        indices (sequence): Indices in the whole set selected for subset\n",
        "        labels(sequence) : targets as required for the indices. will be the same length as indices\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, indices, labels):\n",
        "        self.dataset = torch.utils.data.Subset(dataset, indices)\n",
        "        self.targets = labels\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx][0]\n",
        "        target = self.targets[idx]\n",
        "        return (item, target)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "def to_categorical(y, num_classes):\n",
        "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
        "    return np.eye(num_classes, dtype='uint8')[y]\n",
        "\n",
        "def main_cross_validation(dataset, embedding_matrix, collate_fn,\n",
        "                          device = \"cuda\", epochs = 20, random_state = 42, batch_size = 128):\n",
        "\n",
        "\n",
        "  train_indexes, test_indexes = train_test_split(list(range(len(dataset.targets))), test_size = 0.2,\n",
        "                                                  stratify = dataset.targets, random_state = random_state)\n",
        "\n",
        "  train_targets = np.asarray(dataset.targets[train_indexes], dtype=np.int64)\n",
        "  test_targets = np.asarray(dataset.targets[test_indexes], dtype=np.int64)\n",
        "\n",
        "  # I use ds and set because the first means that the dataset should be splitted again (train + val),\n",
        "  # the latter means that it is ready to use\n",
        "  train_ds = CustomSubset(dataset, train_indexes, train_targets)\n",
        "  test_set = CustomSubset(dataset, test_indexes, test_targets)\n",
        "  test_loader = DataLoader(test_set, batch_size = batch_size, collate_fn = collate_fn, pin_memory=True)\n",
        "\n",
        "  skf = StratifiedKFold(5, shuffle = True, random_state=random_state)\n",
        "\n",
        "  fold_accuracies = []\n",
        "  \n",
        "  for fold, (train_indexes, val_indexes) in enumerate(skf.split(np.zeros(len(train_ds)),\n",
        "                                                      train_targets)):\n",
        "    \n",
        "    net = BiLSTMAttention(embedding_matrix, device = device, input_size=300).to(device)\n",
        "    optimizer = Adam(net.parameters(), 0.001, betas = (0.9, 0.9), amsgrad=True)\n",
        "    cost_function = nn.CrossEntropyLoss()\n",
        "    \n",
        "    train_set = Subset(train_ds, train_indexes)\n",
        "    val_set = Subset(train_ds, val_indexes)\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size = batch_size, collate_fn = collate_fn, pin_memory=True)\n",
        "    val_loader = DataLoader(val_set, batch_size = batch_size, collate_fn = collate_fn, pin_memory = True)\n",
        "\n",
        "\n",
        "    for e in range(epochs):\n",
        "      print(f\"epoch {e}:\")\n",
        "      train_loss, train_accuracy = training_step(net, train_loader, optimizer, cost_function, device)\n",
        "      print(f\"Training loss: {train_loss} \\n Training accuracy: {train_accuracy}\")\n",
        "      val_loss, val_accuracy = test_step(net, val_loader, cost_function, device)\n",
        "      print(f\"Val loss: {val_loss} \\n Val accuracy: {val_accuracy}\")\n",
        "      print(\"------------------------------------------------------------------\")\n",
        "    \n",
        "    fold_accuracies.append(val_accuracy)\n",
        "\n",
        "  _, test_accuracy = test_step(net, test_loader, cost_function, device)\n",
        "\n",
        "  fold_accuracies = np.array(fold_accuracies)\n",
        "\n",
        "  return test_accuracy, fold_accuracies.mean(), fold_accuracies.std()\n",
        "\n"
      ],
      "metadata": {
        "id": "FkRBKES24_0v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lexicon Based Supervised Attention Model"
      ],
      "metadata": {
        "id": "MkeZyHH15r6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MRPipelineLBSA(MRAbstractPipeline):\n",
        "    \"\"\"\n",
        "    Pipeline for documents represented as list of tokens\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(MRPipelineLBSA, self).__init__()\n",
        "        self.pipeline = [self.remove_underscores, \n",
        "                         self.reducing_character_repetitions,\n",
        "                         self.clean_contractions,\n",
        "                         self.clean_special_chars,\n",
        "                         self.remove_stop_words]\n",
        "\n",
        "    def remove_underscores(self, corpus):\n",
        "        \"\"\"\n",
        "        Solves the problem where some of the words are surrounded by underscores\n",
        "        (e.g. \"_hello_\")\n",
        "        \"\"\"\n",
        "\n",
        "        for doc in corpus:\n",
        "          for sent in doc:\n",
        "            for idx, word in enumerate(sent):\n",
        "                if \"_\" in word:\n",
        "                    cleaned_word = self._clean_word(word)\n",
        "                    sent[idx] = cleaned_word\n",
        "        return corpus\n",
        "\n",
        "\n",
        "    def _clean_word(self, word: str):\n",
        "        word = word.replace(\"_\", \" \")\n",
        "        # remove spaces before and after the word\n",
        "        word = word.split()\n",
        "        word = \" \".join(word)\n",
        "        return word\n",
        "    \n",
        "    def reducing_character_repetitions(self, corpus):\n",
        "        \n",
        "        new_corpus = [[[self._clean_repetitions(w) for w in sent] for sent in doc] for doc in corpus]\n",
        "        return new_corpus\n",
        "\n",
        "    # inspired by https://towardsdatascience.com/cleaning-preprocessing-text-data-by-building-nlp-pipeline-853148add68a\n",
        "    def _clean_repetitions(self, word):\n",
        "        \"\"\"\n",
        "        This Function will reduce repetition to two characters \n",
        "        for alphabets and to one character for punctuations.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "            word: str                \n",
        "        Returns\n",
        "        -------\n",
        "        str\n",
        "            Finally formatted text with alphabets repeating to \n",
        "            one characters & punctuations limited to one repetition \n",
        "            \n",
        "        Example:\n",
        "        Input : Realllllllllyyyyy,        Greeeeaaaatttt   !!!!?....;;;;:)\n",
        "        Output : Really, Great !?.;:)\n",
        "\n",
        "        \"\"\"\n",
        "        # Pattern matching for all case alphabets\n",
        "        pattern_alpha = re.compile(r\"([A-Za-z])\\1{1,}\", re.DOTALL)\n",
        "\n",
        "        # Limiting all the repetitions to two characters.\n",
        "        # MODIFIED: keep only one repetition of the character\n",
        "        formatted_text = pattern_alpha.sub(r\"\\1\\1\", word) \n",
        "\n",
        "        # Pattern matching for all the punctuations that can occur\n",
        "        pattern_punct = re.compile(r'([.,/#!$%^&*?;:{}=_`~()+-])\\1{1,}')\n",
        "\n",
        "        # Limiting punctuations in previously formatted string to only one.\n",
        "        combined_formatted = pattern_punct.sub(r'\\1', formatted_text)\n",
        "\n",
        "        # The below statement is replacing repetitions of spaces that occur more than two times with that of one occurrence.\n",
        "        final_formatted = re.sub(' {2,}',' ', combined_formatted)\n",
        "        return final_formatted\n",
        "    \n",
        "    def clean_contractions(self, corpus):\n",
        "        new_corpus = []\n",
        "        for doc in corpus:\n",
        "          new_doc = []\n",
        "          for sent in doc:\n",
        "            new_sent = []\n",
        "            for word in sent:\n",
        "                try:\n",
        "                    correct = CONTRACTION_MAP[word]\n",
        "                    correct = correct.split()\n",
        "                    new_sent += correct\n",
        "                except:\n",
        "                    new_sent.append(word)\n",
        "            new_doc.append(new_sent)\n",
        "          new_corpus.append(new_doc)\n",
        "        return new_corpus\n",
        "\n",
        "    def clean_special_chars(self, corpus):\n",
        "        new_corpus = [[[self._clean_special_word(w) for w in sent] for sent in doc] for doc in corpus] \n",
        "        return new_corpus\n",
        "    \n",
        "    def _clean_special_word(self, word):\n",
        "        # The formatted text after removing not necessary punctuations.\n",
        "        formatted_text = re.sub(r\"[^a-zA-Z0-9:€$-,%.?!]+\", '', word) \n",
        "        # In the above regex expression,I am providing necessary set of punctuations that are frequent in this particular dataset.\n",
        "        return formatted_text\n",
        "    \n",
        "    def remove_stop_words(self, corpus):\n",
        "      stops = stopwords.words(\"english\")\n",
        "      # We don't want to remove stop words associated with negations\n",
        "      stops = [word for word in stops if \"'t\" not in word or \"not\" not in word]\n",
        "      return [[[word for word in sent if word not in stops] for sent in doc] for doc in corpus]"
      ],
      "metadata": {
        "id": "sJQywSXpD33-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MovieReviewsCorpusLBSA():\n",
        "  def __init__(self, preprocess_pipeline = None):\n",
        "      \"\"\"\n",
        "      If non preprocess_pipeline is given, the text gets tokenized by default\n",
        "      using spacy tokenizer\n",
        "      \"\"\"\n",
        "      self.mr = movie_reviews\n",
        "      if preprocess_pipeline != None and not isinstance(preprocess_pipeline, MRPipelineLBSA):\n",
        "          raise ValueError(f\"preprocess_pipeline is not valid, you should pass \\\n",
        "                              a MRPipelineLBSA object or None\")\n",
        "      self.pipeline = preprocess_pipeline\n",
        "      self.raw_corpus, self.labels = self._get_raw_corpus()\n",
        "      if self.pipeline == None:\n",
        "          self.processed_corpus = self.raw_corpus\n",
        "      else:\n",
        "          # Flattened and preprocessed corpus\n",
        "          self.processed_corpus = self._preprocess()\n",
        "      \n",
        "      self.vocab = self._create_vocab()\n",
        "      \n",
        "\n",
        "  def _get_raw_corpus(self):\n",
        "      neg = self.mr.paras(categories = \"neg\")\n",
        "      pos = self.mr.paras(categories = \"pos\")\n",
        "      labels = [0]*len(neg) + [1]*len(pos)\n",
        "      return neg + pos, labels\n",
        "  \n",
        "  def _preprocess(self):\n",
        "      if self.pipeline != None:\n",
        "          return self.pipeline(self.raw_corpus)\n",
        "      else:\n",
        "          return self.raw_corpus\n",
        "      \n",
        "  def _create_vocab(self):\n",
        "      vocab = dict()\n",
        "      corpus_words = [w for doc in self.processed_corpus for sent in doc for w in sent]\n",
        "      for word in corpus_words:\n",
        "          try:\n",
        "              vocab[word] += 1\n",
        "          except:\n",
        "              vocab[word] = 1\n",
        "      return vocab\n",
        "\n",
        "  def get_embedding_matrix(self, embedding, embedding_dim):\n",
        "      \"\"\"\n",
        "      Returns\n",
        "      -------\n",
        "      np.ndarray\n",
        "          A 2D which each row has the corresponding embedding from the vocabulary\n",
        "      \"\"\"\n",
        "      matrix_length = len(self.vocab)\n",
        "      embedding_matrix = np.zeros((matrix_length, embedding_dim))\n",
        "      # If I use torch.zeros directly it crashes (don't know why)\n",
        "      embedding_matrix = torch.from_numpy(embedding_matrix.copy())\n",
        "      null_embedding = torch.tensor([0.0]*embedding_dim)\n",
        "      for idx, key in enumerate(self.vocab.keys()):\n",
        "          if torch.equal(embedding[key], null_embedding):\n",
        "              embedding_matrix[idx] = torch.randn(embedding_dim)\n",
        "          else:\n",
        "              embedding_matrix[idx] = embedding[key]\n",
        "              \n",
        "      return embedding_matrix\n",
        "  \n",
        "  def get_indexed_corpus(self):\n",
        "      \"\"\"\n",
        "      Returns\n",
        "      -------\n",
        "      Dictionary\n",
        "          Containing correspondences word -> index\n",
        "      \n",
        "      list(int)\n",
        "          labels associated with each document\n",
        "      \"\"\"\n",
        "      vocab = {}\n",
        "      for idx, key in enumerate(self.vocab.keys()):\n",
        "          vocab[key] = idx\n",
        "      \n",
        "      # each doc is a list of tensor which represent sentences, each sentence is a tensor of indexed words\n",
        "      indexed_corpus = [[torch.tensor([vocab[w] for w in sent], dtype=torch.int32) \n",
        "                        for sent in doc]\n",
        "                        for doc in self.processed_corpus]\n",
        "      return indexed_corpus, self.labels\n",
        "  \n",
        "  def __len__(self):\n",
        "      return len(self.processed_corpus)\n",
        "\n",
        "c = MovieReviewsCorpusLBSA()"
      ],
      "metadata": {
        "id": "n9gmVtdg_Gf1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import sentiwordnet as swn\n",
        "import math\n",
        "\n",
        "class MovieReviewsDatasetLBSA(Dataset):\n",
        "  def __init__(self, corpus):\n",
        "    super(MovieReviewsDatasetLBSA, self).__init__()\n",
        "    self.corpus = corpus\n",
        "    indexed_corpus = self.corpus.get_indexed_corpus()\n",
        "    # Word level gold attention vector\n",
        "    self.word_lambda = 3\n",
        "    self.sentence_lambda = 3\n",
        "    self.sentiment_degree = self._compute_sentiment_degree()\n",
        "    self.wl_gold_av = self._compute_gold_words()\n",
        "    self.sl_gold_av = self._compute_gold_sents()\n",
        "    self.data = indexed_corpus[0]\n",
        "    self.targets = indexed_corpus[1]\n",
        "  \n",
        "  def _compute_sentiment_degree(self):\n",
        "    vocab = self._build_senti_vocab(self.corpus.vocab)\n",
        "    corpus = self.corpus.processed_corpus\n",
        "    scores = [[[vocab[word] for word in sent] for sent in doc] for doc in corpus]\n",
        "    return scores\n",
        "\n",
        "  def _compute_gold_sents(self):\n",
        "    sentence_sentiment_degree  = [[sum(sent)/len(sent) for sent in doc] for doc in self.sentiment_degree]\n",
        "    gold = [self._normalized_softmax(doc, self.sentence_lambda) for doc in sentence_sentiment_degree]\n",
        "    return gold\n",
        "\n",
        "\n",
        "  def _compute_gold_words(self):\n",
        "    gold = [[self._normalized_softmax(sent_scores, self.word_lambda) for sent_scores in doc] for doc in self.sentiment_degree]\n",
        "    return gold\n",
        "\n",
        "  def _normalized_softmax(self, sequence, lam):\n",
        "    multiplied_sequence = [lam * el for el in sequence]\n",
        "    total = sum([math.exp(el) for el in sequence])\n",
        "    res = torch.tensor([math.exp(lam * el)/total for el in sequence])\n",
        "    return res\n",
        "\n",
        "  def _build_senti_vocab(self, vocab):\n",
        "    for key in vocab.keys():\n",
        "      vocab[key] = 0\n",
        "\n",
        "    max_value = 0\n",
        "    for key in vocab.keys():\n",
        "      senses = list(swn.senti_synsets(key))\n",
        "      pos = 0\n",
        "      neg = 0\n",
        "      for sense in senses:\n",
        "        pos += sense.pos_score()\n",
        "        neg += sense.neg_score()\n",
        "      if (pos != 0) or (neg != 0):\n",
        "        vocab[key] = max(pos, neg)\n",
        "      if vocab[key] > max_value:\n",
        "        max_value = vocab[key]\n",
        "\n",
        "    for key in vocab.keys():\n",
        "      vocab[key] = self.maprange((0, max_value), (0, 1), vocab[key])\n",
        "\n",
        "    return vocab\n",
        "  \n",
        "  def maprange(self, a, b, s):\n",
        "    \"\"\"\n",
        "    Maps the number s from range a = [a1, a2] to range b = [b1, b2]\n",
        "    \"\"\"\n",
        "    # Source: https://rosettacode.org/wiki/Map_range#Python\n",
        "    (a1, a2), (b1, b2) = a, b\n",
        "    return  b1 + ((s - a1) * (b2 - b1) / (a2 - a1))\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    item = self.data[index]\n",
        "    label = self.targets[index]\n",
        "    gold_word = self.wl_gold_av[index]\n",
        "    gold_sent = self.sl_gold_av[index]\n",
        "    return (item, label, gold_word, gold_sent)\n",
        "\n",
        "corpus = MovieReviewsCorpusLBSA()\n",
        "ds = MovieReviewsDatasetLBSA(corpus)\n",
        "print(type(ds.sl_gold_av[1]))"
      ],
      "metadata": {
        "id": "8lGBLNBxo4Jv",
        "outputId": "843c0ae3-9cb0-4ab2-cf49-a0fca4e3abce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To understand:\n",
        "- If it is better to introduce intermediate supervision\n",
        "\n",
        "- If it is better to use one hot encoding for the output\n",
        "\n",
        "- If I intepreted well the word-loss"
      ],
      "metadata": {
        "id": "IT_UVsevkmNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLBSA(BiLSTMAttention):\n",
        "    # Lexicon Based Supervised Attention model (LBSA) inspired by the following paper: https://aclanthology.org/C18-1074.pdf\n",
        "    def __init__(self, embedding_matrix, device=\"cuda\", input_size=300,\n",
        "                 hidden_size=128, context_size = 150, output_size=2):\n",
        "\n",
        "        super(EncoderLBSA, self).__init__(embedding_matrix, device, input_size, hidden_size, context_size, output_size)\n",
        "\n",
        "    # TODO: Pass the part inside for to super.forward()  \n",
        "    def forward(self, x):\n",
        "      att = []\n",
        "      res = []\n",
        "      for i, doc in enumerate(x):\n",
        "        doc = doc.to(self.device)\n",
        "        batch_size = doc.batch_sizes[0].item()\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        doc = self.simple_elementwise_apply(self.embedding, doc)\n",
        "\n",
        "        out, _ = self.lstm(doc, hidden)\n",
        "        out, input_sizes = pad_packed_sequence(out, batch_first=True)\n",
        "        # n_sents, n_words_per_sent, hidden_size * 2 (since is bilstm)\n",
        "\n",
        "\n",
        "        attention_values = torch.tanh(self.attention(out))\n",
        "        # n_sents, n_words_per_sent, context_size\n",
        "\n",
        "        attention_weights = torch.softmax(attention_values.matmul(self.history), dim = 1).unsqueeze(1)\n",
        "        # n_sents, n_words_per_sent\n",
        "\n",
        "        out = torch.sum(attention_weights.matmul(out), dim = 1)\n",
        "        # n_sents, hidden*2\n",
        "        \n",
        "        attention_weights = attention_weights.squeeze(dim=1)\n",
        "\n",
        "        att.append([sent[:input_sizes[idx]] for idx, sent in enumerate(attention_weights)])\n",
        "\n",
        "        res.append(out)\n",
        "      # n_doc, seq_lengths, hidden * 2\n",
        "      return res, att"
      ],
      "metadata": {
        "id": "k_dniRPY5q2A"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sortLBSA(X, w_gold, s_gold):\n",
        "\n",
        "  sentence_lengths = [np.array([sent.size(dim=0) for sent in doc]) for doc in X]\n",
        "  indexes = [np.argsort(doc) for doc in sentence_lengths]\n",
        "  indexes = [el.tolist() for el in indexes]\n",
        "\n",
        "  X_sorted = [[doc[idx2] for idx2 in indexes[idx]][::-1] for idx, doc in enumerate(X)]\n",
        "  w_gold = [[doc[idx2] for idx2 in indexes[idx]][::-1] for idx, doc in enumerate(w_gold)]\n",
        "  s_gold = [torch.tensor([doc[idx2] for idx2 in indexes[idx]][::-1]) for idx, doc in enumerate(s_gold)]\n",
        "  sentence_lengths = [[doc[idx2] for idx2 in indexes[idx]][::-1] for idx, doc in enumerate(sentence_lengths)]\n",
        "\n",
        "  return X_sorted, w_gold, s_gold, sentence_lengths, indexes\n",
        "\n",
        "def padLBSA(batch, max_sizes):\n",
        "    pad = torch.tensor([-1])\n",
        "    for idx1, doc in enumerate(batch):\n",
        "      for idx2, sent in enumerate(doc):\n",
        "        remaining = max_sizes[idx1] - sent.size(dim = 0)\n",
        "        batch[idx1][idx2] = torch.cat((sent, pad.repeat(remaining)), dim = 0)\n",
        "    return batch\n",
        "\n",
        "def to_tensorLBSA(batch, max_sizes):\n",
        "  res = []\n",
        "  for idx, doc in enumerate(batch):\n",
        "    buff = torch.zeros(len(doc), max_sizes[idx], dtype=torch.int32)\n",
        "    for idx2, sent in enumerate(doc):\n",
        "      buff[idx2] = sent\n",
        "\n",
        "    res.append(buff)\n",
        "  return res\n",
        "\n",
        "def collateLBSA(batch):\n",
        "  X, Y, w_gold, s_gold = list(zip(*batch))\n",
        "  X, w_gold, s_gold, sentence_lengths, indexes = sortLBSA(X, w_gold, s_gold)\n",
        "  # can take doc[0] since senetence_lengths is sorted\n",
        "  max_sizes = [doc[0] for doc in sentence_lengths]\n",
        "\n",
        "  # Pad tensor each element\n",
        "  X = padLBSA(X, max_sizes)\n",
        "  # Transform the batch to a tensor\n",
        "  X = to_tensorLBSA(X, max_sizes)\n",
        "\n",
        "  # Return the padded sequence object\n",
        "  X = [pack_padded_sequence(doc, sentence_lengths[idx], batch_first=True) for idx, doc in enumerate(X)]\n",
        "  return X, Y, w_gold, s_gold, indexes"
      ],
      "metadata": {
        "id": "JyjRmkGAIu94"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_LBSA(outputs, targets, mu_w = 0.001, mu_s = 0.05):\n",
        "  dec_output, w_att, s_att = outputs\n",
        "  target, w_gold, s_gold = targets\n",
        "\n",
        "  total_loss = 0\n",
        "  ce = nn.CrossEntropyLoss()\n",
        "\n",
        "  total_loss += ce(dec_output, target)\n",
        "\n",
        "  w_loss = torch.mean(torch.tensor([\n",
        "    torch.sum(torch.tensor([\n",
        "        ce(w_att[idx1][idx2], sent) for idx2, sent in enumerate(doc)\n",
        "    ])) * mu_w for idx1, doc in enumerate(w_gold)\n",
        "  ]))\n",
        "  total_loss += w_loss\n",
        "\n",
        "  s_loss = torch.mean(torch.tensor([\n",
        "      ce(s_att[idx], doc) * mu_s for idx, doc in enumerate(s_gold)\n",
        "  ]))\n",
        "  total_loss += s_loss\n",
        "\n",
        "  return total_loss"
      ],
      "metadata": {
        "id": "VXw9lvmaWM3B"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_step_LBSA(encoder, decoder, data_loader, optimizer, cost_function, device = 'cuda'):\n",
        "  cumulative_loss = 0\n",
        "  cumulative_accuracy = 0\n",
        "  samples = 0\n",
        "\n",
        "  encoder.train()\n",
        "  decoder.train()\n",
        "\n",
        "  for batch_idx, (inputs, target, w_gold, s_gold, _) in enumerate(data_loader):\n",
        "    \n",
        "    in_size = len(target)\n",
        "\n",
        "    enc_output, w_att = encoder(inputs)\n",
        "\n",
        "    # for i, doc in enumerate(enc_output):\n",
        "        # for j, sent in enumerate(doc):\n",
        "          # enc_output[i][j] = sent.cpu()\n",
        "    \n",
        "    batch = [(el, target[idx]) for idx, el in enumerate(enc_output)]\n",
        "\n",
        "    dec_input, target, indexes = collate(batch)\n",
        "    \n",
        "    s_gold = [s_gold[idx] for idx in indexes][::-1]\n",
        "    # dec_input = dec_input.to(device)\n",
        "    target = target.to(device)\n",
        "    for idx1, doc in enumerate(w_gold):\n",
        "      for idx2, sent in enumerate(doc):\n",
        "        w_gold[idx1][idx2] = sent.to(device)\n",
        "    \n",
        "    for idx, doc in enumerate(s_gold):\n",
        "       s_gold[idx] = doc.to(device)\n",
        "    \n",
        "\n",
        "    dec_output, s_att = decoder(dec_input)\n",
        "\n",
        "    outputs = (dec_output, w_att, s_att)\n",
        "    targets = (target, w_gold, s_gold)\n",
        "\n",
        "    loss = cost_function(outputs, targets)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    samples += in_size\n",
        "    cumulative_loss += loss.item()\n",
        "    _, predicted = dec_output.max(dim=1)\n",
        "\n",
        "    cumulative_accuracy += predicted.eq(target).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, (cumulative_accuracy/samples)*100"
      ],
      "metadata": {
        "id": "yZF4uo99VKsh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step_LBSA(encoder, decoder, data_loader, cost_function, device = 'cuda'):\n",
        "  cumulative_loss = 0\n",
        "  cumulative_accuracy = 0\n",
        "  samples = 0\n",
        "\n",
        "  encoder.eval()\n",
        "  decoder.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for batch_idx, (inputs, target, w_gold, s_gold, _) in enumerate(data_loader):\n",
        "      in_size = len(target)\n",
        "\n",
        "      enc_output, w_att = encoder(inputs)\n",
        "      \n",
        "      batch = [(el, target[idx]) for idx, el in enumerate(enc_output)]\n",
        "\n",
        "      dec_input, target, indexes = collate(batch)\n",
        "\n",
        "      s_gold = [s_gold[idx] for idx in indexes][::-1]\n",
        "      # Not sorting also w_gold becuse in the encoder, documents don't get shuffled\n",
        "\n",
        "      target = target.to(device)\n",
        "      for idx1, doc in enumerate(w_gold):\n",
        "        for idx2, sent in enumerate(doc):\n",
        "          w_gold[idx1][idx2] = sent.to(device)\n",
        "    \n",
        "      for idx, doc in enumerate(s_gold):\n",
        "        s_gold[idx] = doc.to(device)\n",
        "\n",
        "      dec_output, s_att = decoder(dec_input)\n",
        "\n",
        "      outputs = (dec_output, w_att, s_att)\n",
        "      targets = (target, w_gold, s_gold)\n",
        "\n",
        "      loss = cost_function(outputs, targets)\n",
        "      \n",
        "      samples += in_size\n",
        "      cumulative_loss += loss.item()\n",
        "      _, predicted = dec_output.max(dim=1)\n",
        "\n",
        "      cumulative_accuracy += predicted.eq(target).sum().item()\n",
        "\n",
        "    return cumulative_loss/samples, (cumulative_accuracy/samples)*100"
      ],
      "metadata": {
        "id": "RpyI0qRvC0cF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_step_LBSA_new(encoder, decoder, data_loader, optimizer, cost_function, device = 'cuda'):\n",
        "  cumulative_loss = 0\n",
        "  cumulative_accuracy = 0\n",
        "  samples = 0\n",
        "\n",
        "  encoder.train()\n",
        "  decoder.train()\n",
        "\n",
        "  for batch_idx, (inputs, target, w_gold, s_gold, sent_indexes) in enumerate(data_loader):\n",
        "    \n",
        "    in_size = len(target)\n",
        "\n",
        "    enc_output, w_att = encoder(inputs)\n",
        "\n",
        "    #n_doc, n_sents, hidden*2\n",
        "    \n",
        "    # Sorting the output of the encoder after \n",
        "    enc_output = [enc_output[doc_idx][idx] for doc_idx in sent_indexes for idx in doc_idx ]\n",
        "\n",
        "    # for i, doc in enumerate(enc_output):\n",
        "        # for j, sent in enumerate(doc):\n",
        "          # enc_output[i][j] = sent.cpu()\n",
        "    \n",
        "    batch = [(el, target[idx]) for idx, el in enumerate(enc_output)]\n",
        "\n",
        "    dec_input, target, indexes = collate(batch)\n",
        "    \n",
        "    s_gold = [s_gold[idx] for idx in indexes][::-1]\n",
        "    # dec_input = dec_input.to(device)\n",
        "    target = target.to(device)\n",
        "    for idx1, doc in enumerate(w_gold):\n",
        "      for idx2, sent in enumerate(doc):\n",
        "        w_gold[idx1][idx2] = sent.to(device)\n",
        "    \n",
        "    for idx, doc in enumerate(s_gold):\n",
        "       s_gold[idx] = doc.to(device)\n",
        "    \n",
        "\n",
        "    dec_output, s_att = decoder(dec_input)\n",
        "\n",
        "    outputs = (dec_output, w_att, s_att)\n",
        "    targets = (target, w_gold, s_gold)\n",
        "\n",
        "    loss = cost_function(outputs, targets)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    samples += in_size\n",
        "    cumulative_loss += loss.item()\n",
        "    _, predicted = dec_output.max(dim=1)\n",
        "\n",
        "    cumulative_accuracy += predicted.eq(target).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, (cumulative_accuracy/samples)*100"
      ],
      "metadata": {
        "id": "RN2AM7tLgIDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Adam\n",
        "import torch.nn as nn\n",
        "\n",
        "def main_LBSA(train_loader, test_loader, embedding_matrix, device = \"cuda\", epochs = 10):\n",
        "\n",
        "  encoder = EncoderLBSA(embedding_matrix = embedding_matrix, device = device, input_size=300, hidden_size=100).to(device)\n",
        "  decoder = BiLSTMAttention(device = device, input_size=100*2, context_size = 150).to(device)\n",
        "\n",
        "  optimizer = Adam(list(encoder.parameters()) + list(decoder.parameters()), 0.001, betas = (0.9, 0.999), amsgrad=True)\n",
        "\n",
        "  cost_function = loss_LBSA\n",
        "\n",
        "  for e in range(epochs):\n",
        "    print(f\"epoch {e}:\")\n",
        "    train_loss, train_accuracy = training_step_LBSA_new(encoder, decoder, train_loader, optimizer, cost_function, device)\n",
        "    print(f\"Training loss: {train_loss} \\n Training accuracy: {train_accuracy}\")\n",
        "    test_loss, test_accuracy = test_step_LBSA(encoder, decoder, test_loader, cost_function, device)\n",
        "    print(f\"Test loss: {test_loss} \\n Test accuracy: {test_accuracy}\")\n",
        "    print(\"------------------------------------------------------------------\")\n",
        "  \n",
        "  _, test_accuracy = test_step(encoder, decoder, test_loader, cost_function, device)\n",
        "\n",
        "  return test_accuracy\n"
      ],
      "metadata": {
        "id": "3Xzpaa7IDN9Z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_vectors = GloVe(name='840B', dim=300, cache = \"/content/gdrive/My Drive/nlu-project/.vector_cache\")"
      ],
      "metadata": {
        "id": "hgNE3lxXrW4M"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mr_pipeline = MRPipelineLBSA()\n",
        "corpus = MovieReviewsCorpusLBSA(mr_pipeline)"
      ],
      "metadata": {
        "id": "Xu7rZw-mrqke"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = corpus.get_embedding_matrix(global_vectors, 300)\n",
        "# ds = corpus.get_indexed_corpus()"
      ],
      "metadata": {
        "id": "0TtoFzYDsGHk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MovieReviewsDatasetLBSA(corpus)\n",
        "train_loader, test_loader = get_data(128, dataset, collate_fn=collateLBSA)"
      ],
      "metadata": {
        "id": "QQf9eKAqsIfr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eDrwHvOIEsl2",
        "outputId": "a7dcbd5f-d088-47d8-a754-5ac3ba957a84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0:\n",
            "Training loss: 0.007132519111037254 \n",
            " Training accuracy: 64.9375\n",
            "Test loss: 0.009536461383104324 \n",
            " Test accuracy: 73.0\n",
            "------------------------------------------------------------------\n",
            "epoch 1:\n",
            "Training loss: 0.004899058844894171 \n",
            " Training accuracy: 85.0\n",
            "Test loss: 0.009184689819812774 \n",
            " Test accuracy: 61.75000000000001\n",
            "------------------------------------------------------------------\n",
            "epoch 2:\n",
            "Training loss: 0.0035149676539003847 \n",
            " Training accuracy: 93.9375\n",
            "Test loss: 0.008473468273878097 \n",
            " Test accuracy: 79.0\n",
            "------------------------------------------------------------------\n",
            "epoch 3:\n",
            "Training loss: 0.0026734076254069806 \n",
            " Training accuracy: 98.875\n",
            "Test loss: 0.007285471260547638 \n",
            " Test accuracy: 82.75\n",
            "------------------------------------------------------------------\n",
            "epoch 4:\n",
            "Training loss: 0.002284518387168646 \n",
            " Training accuracy: 99.875\n",
            "Test loss: 0.006816456913948059 \n",
            " Test accuracy: 81.0\n",
            "------------------------------------------------------------------\n",
            "epoch 5:\n",
            "Training loss: 0.0021992224641144277 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.006781035512685776 \n",
            " Test accuracy: 85.25\n",
            "------------------------------------------------------------------\n",
            "epoch 6:\n",
            "Training loss: 0.002178889513015747 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.0069615192711353305 \n",
            " Test accuracy: 85.25\n",
            "------------------------------------------------------------------\n",
            "epoch 7:\n",
            "Training loss: 0.002173799276351929 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.007197465300559997 \n",
            " Test accuracy: 84.75\n",
            "------------------------------------------------------------------\n",
            "epoch 8:\n",
            "Training loss: 0.0021711823530495165 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.00735708549618721 \n",
            " Test accuracy: 85.5\n",
            "------------------------------------------------------------------\n",
            "epoch 9:\n",
            "Training loss: 0.00216958723962307 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.007504106014966965 \n",
            " Test accuracy: 85.0\n",
            "------------------------------------------------------------------\n",
            "epoch 10:\n",
            "Training loss: 0.0021682733483612535 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.007535540908575058 \n",
            " Test accuracy: 85.0\n",
            "------------------------------------------------------------------\n",
            "epoch 11:\n",
            "Training loss: 0.002167390938848257 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.00759333223104477 \n",
            " Test accuracy: 85.0\n",
            "------------------------------------------------------------------\n",
            "epoch 12:\n",
            "Training loss: 0.002166586872190237 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.007648337781429291 \n",
            " Test accuracy: 84.5\n",
            "------------------------------------------------------------------\n",
            "epoch 13:\n",
            "Training loss: 0.0021662788279354574 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.007709686458110809 \n",
            " Test accuracy: 84.25\n",
            "------------------------------------------------------------------\n",
            "epoch 14:\n",
            "Training loss: 0.0021657118387520312 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.007770803272724152 \n",
            " Test accuracy: 84.0\n",
            "------------------------------------------------------------------\n",
            "epoch 15:\n",
            "Training loss: 0.0021653781086206437 \n",
            " Training accuracy: 100.0\n",
            "Test loss: 0.00782615840435028 \n",
            " Test accuracy: 84.0\n",
            "------------------------------------------------------------------\n",
            "epoch 16:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-a6ecba04f0e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Da fare una collate nuova direttamente che non vada a toccare i tensori esistenti.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Oppure ragionare un attimo.... servono davvero i gradient per l'input? O posso fare il detach?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain_LBSA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Overall accuracy: {accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Folds statistics:\\n----------------\\n - mean: {mean} \\n - standard deviation: {std}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-92c789ad4d20>\u001b[0m in \u001b[0;36mmain_LBSA\u001b[0;34m(train_loader, test_loader, embedding_matrix, device, epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch {e}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_step_LBSA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training loss: {train_loss} \\n Training accuracy: {train_accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_step_LBSA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-dc693fbd3d56>\u001b[0m in \u001b[0;36mtraining_step_LBSA\u001b[0;34m(encoder, decoder, data_loader, optimizer, cost_function, device)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_gold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_gold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-970c4d8670dd>\u001b[0m in \u001b[0;36mloss_LBSA\u001b[0;34m(outputs, targets, mu_w, mu_s)\u001b[0m\n\u001b[1;32m     11\u001b[0m     torch.sum(torch.tensor([\n\u001b[1;32m     12\u001b[0m         \u001b[0mce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_att\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     ])) * mu_w for idx1, doc in enumerate(w_gold)\n\u001b[0m\u001b[1;32m     14\u001b[0m   ]))\n\u001b[1;32m     15\u001b[0m   \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mw_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-970c4d8670dd>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m     torch.sum(torch.tensor([\n\u001b[1;32m     12\u001b[0m         \u001b[0mce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_att\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     ])) * mu_w for idx1, doc in enumerate(w_gold)\n\u001b[0m\u001b[1;32m     14\u001b[0m   ]))\n\u001b[1;32m     15\u001b[0m   \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mw_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-970c4d8670dd>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m   w_loss = torch.mean(torch.tensor([\n\u001b[1;32m     11\u001b[0m     torch.sum(torch.tensor([\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_att\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     ])) * mu_w for idx1, doc in enumerate(w_gold)\n\u001b[1;32m     14\u001b[0m   ]))\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m   1165\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3014\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 87.3, 86 e qualcosa\n",
        "train_loader, test_loader = get_data(128, dataset, collate_fn=collateLBSA)\n",
        "# Da fare una collate nuova direttamente che non vada a toccare i tensori esistenti.\n",
        "# Oppure ragionare un attimo.... servono davvero i gradient per l'input? O posso fare il detach?\n",
        "accuracy, mean, std = main_LBSA(train_loader, test_loader, embedding_matrix, device = \"cuda\", epochs = 20)\n",
        "print(f\"Overall accuracy: {accuracy}\")\n",
        "print(f\"Folds statistics:\\n----------------\\n - mean: {mean} \\n - standard deviation: {std}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pBBa_vvYSnL"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "tensor([1315, 1222, 1011, 1010,  936,  862,  814,  807,  807,  764,  718,  515,\n",
        "         495,  388,  344,  323])\n",
        "tensor([1617, 1361, 1311, 1178, 1081, 1068,  958,  941,  925,  768,  688,  619,\n",
        "         604,  573,  484,  405])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Af9ORg9pFKe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P67fhfYpSZA"
      },
      "source": [
        "# First try to parse phrases documet-wise, then try to parse each phrase of a document separately, and then aggregate the result (if there are more positive phrases then positive, otherwise negative). (Try also to give a weight depending on the number of sentiment lexemes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mK4Rmfr4ziT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "project.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.7 ('nlu')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "e0262c2e7a08424d65c968f8ecfc5afb6b5a99089f86fd0fa27478ea619b0ef2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}