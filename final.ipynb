{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corpus import MovieReviewsCorpus\n",
    "from models import BiLSTM\n",
    "from preprocess import MRPipelineTokens\n",
    "from utils import *\n",
    "from torchtext.vocab import GloVe\n",
    "from data import MovieReviewsDataset, get_data\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/alessandrozinni/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/alessandrozinni/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package subjectivity to\n",
      "[nltk_data]     /Users/alessandrozinni/nltk_data...\n",
      "[nltk_data]   Package subjectivity is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"movie_reviews\")\n",
    "nltk.download(\"subjectivity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_vectors = GloVe(name='840B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mr_pipeline = MRPipelineTokens()\n",
    "corpus = MovieReviewsCorpus(mr_pipeline)\n",
    "\n",
    "embedding_matrix = corpus.get_embedding_matrix(global_vectors, 300)\n",
    "\n",
    "ds = corpus.get_indexed_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39426/39426 [00:00<00:00, 39590.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found embeddings for 92.61% of vocab\n",
      "Found embeddings for  97.15% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(corpus.vocab, global_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MovieReviewsDataset(ds)\n",
    "train_loader, test_loader = get_data(128, dataset, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(net, data_loader, optimizer, cost_function, device = 'cuda'):\n",
    "  cumulative_loss = 0\n",
    "  cumulative_accuracy = 0\n",
    "  samples = 0\n",
    "\n",
    "  net.train()\n",
    "\n",
    "  for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.to(device)\n",
    "    in_size = targets.size(dim=0)\n",
    "\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    loss = cost_function(outputs, targets)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    samples += in_size\n",
    "    cumulative_loss += loss.item()\n",
    "    _, predicted = outputs.max(dim=1)\n",
    "\n",
    "    cumulative_accuracy += predicted.eq(targets).sum().item()\n",
    "\n",
    "  return cumulative_loss/samples, (cumulative_accuracy/samples)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(net, data_loader, cost_function, device = 'cuda'):\n",
    "  cumulative_loss = 0\n",
    "  cumulative_accuracy = 0\n",
    "  samples = 0\n",
    "\n",
    "  net.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "      in_size = targets.size(dim=0)\n",
    "\n",
    "      outputs = net(inputs)\n",
    "\n",
    "      loss = cost_function(outputs, targets)\n",
    "\n",
    "      samples += in_size\n",
    "      cumulative_loss += loss.item()\n",
    "      _, predicted = outputs.max(dim=1)\n",
    "\n",
    "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
    "\n",
    "    return cumulative_loss/samples, (cumulative_accuracy/samples)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "\n",
    "def main(train_loader, test_loader, embedding_matrix, device = \"cuda\", epochs = 10):\n",
    "\n",
    "  net = BiLSTM(embedding_matrix, device = device).to(device)\n",
    "\n",
    "  optimizer = Adam(net.parameters(), 0.001, betas = (0.9, 0.999), amsgrad=True)\n",
    "\n",
    "  cost_function = nn.CrossEntropyLoss()\n",
    "\n",
    "  for e in range(epochs):\n",
    "    print(f\"epoch {e}:\")\n",
    "    train_loss, train_accuracy = training_step(net, train_loader, optimizer, cost_function, device)\n",
    "    print(f\"Training loss: {train_loss} \\n Training accuracy: {train_accuracy}\")\n",
    "    test_loss, test_accuracy = test_step(net, test_loader, cost_function, device)\n",
    "    print(f\"Test loss: {test_loss} \\n Test accuracy: {test_accuracy}\")\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "  \n",
    "  _, test_accuracy = test_step(net, test_loader, cost_function, device)\n",
    "\n",
    "\n",
    "  return test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "The Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "main(train_loader, test_loader, embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nlu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0262c2e7a08424d65c968f8ecfc5afb6b5a99089f86fd0fa27478ea619b0ef2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
